Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fa373c48f28>, tc2=<function tc2 at 0x7fa373c59048>, tc3=<function tc3 at 0x7fa373c59158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 69.0141
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100974e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100974e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100974e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100974e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100974e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100974e0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110dd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100972e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310124d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310124c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310124d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acc88> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100626a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100628d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310124c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100acba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310124cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100717f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100717f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100717f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100419e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100979b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100717f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa310041be0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100824a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100824a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100088d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002eba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5518> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310124cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 200
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310008048> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100825c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100825c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100710f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a30b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31012c0b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100974e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100829b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa3100acdd8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7428d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6a90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7078d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7184e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 400
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100082e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100082e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8c88> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 8
Completed Iteration #9
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7072e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7072e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cbe0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6471d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6471d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6471d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6471d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6474e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31019af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6553c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa310110710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31011a2e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7076a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707668> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100acf60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100626a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100622b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707400> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100620f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100620f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100624a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6472b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 69.01408450704226
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100415f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7424e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 19
Completed Iteration #21
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3f28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6727f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6727f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6725c0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af7f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100089e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100089e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100089e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100089e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa310008828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6445c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6445c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101102b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7423c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101102b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 2
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81887b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81990f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81887b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81888d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81994e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 1100
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81888d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81887b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176e48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81768d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b81884a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81445f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6558d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81445f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655d68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81037b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 1200
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81037b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81767f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81033c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81767f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81034a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b81039b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81440b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310008c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81440b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81202b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80def28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80deba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80def28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81202b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81202b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 0.7042253521126725 5
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 0.7042253521126725 6
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 0.7042253521126725 7
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 0.7042253521126725 8
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 0.7042253521126725 9
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 0.7042253521126725 10
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 0.7042253521126725 11
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fd68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 1.408450704225345 12
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087fd0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fd68> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 1.408450704225345 13
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 1.408450704225345 14
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 1.408450704225345 15
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 1.408450704225345 16
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 1.408450704225345 17
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 1.408450704225345 9
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 1.408450704225345 18
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 1.408450704225345 19
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fd68> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 1.408450704225345 10
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 1.408450704225345 20
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80665f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 1.408450704225345 11
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 1.408450704225345 21
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 1.408450704225345 12
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 1.408450704225345 22
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066be0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056080> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 13
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 23
Completed Iteration #5
Best Reward: 0.7042253521126725
coverage_call_count 1400
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 14
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 24
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056080> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 15
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 25
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 16
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 26
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066be0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056080> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 17
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 27
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 18
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 28
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 19
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 29
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fd68> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 1.408450704225345 9
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 20
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 30
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087fd0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fd68> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 1.408450704225345 10
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 21
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 31
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 22
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 32
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fd68> 0.7042253521126725 7
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 1.408450704225345 11
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 23
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 33
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 1.408450704225345 12
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 24
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 34
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 1.408450704225345 13
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.1126760563380174 25
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.1126760563380174 35
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f32e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fd68> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 2.1126760563380174 14
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.81690140845069 26
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.81690140845069 36
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087fd0> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fd68> 1.408450704225345 9
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 2.1126760563380174 15
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 2.81690140845069 27
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 2.81690140845069 37
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa31002e978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f5c0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 2.81690140845069 16
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 3.5211267605633623 28
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 3.5211267605633623 38
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f5c0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 2.81690140845069 17
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 3.5211267605633623 29
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 3.5211267605633623 39
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f32e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fd68> 2.1126760563380174 10
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 3.5211267605633623 18
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 4.225352112676035 30
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 4.225352112676035 40
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 3.5211267605633623 19
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 4.225352112676035 31
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 4.225352112676035 41
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 4.225352112676035 20
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 4.929577464788707 32
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 4.929577464788707 42
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 4.929577464788707 21
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 5.63380281690138 33
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 5.63380281690138 43
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 5.63380281690138 22
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 6.338028169014052 34
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 6.338028169014052 44
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087630> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 6.338028169014052 23
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 7.0422535211267245 35
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 7.0422535211267245 45
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fd68> 2.1126760563380174 11
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 6.338028169014052 24
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 7.0422535211267245 36
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 7.0422535211267245 46
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f5c0> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 6.338028169014052 25
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 7.0422535211267245 37
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 7.0422535211267245 47
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->4->19
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 7.0422535211267245 26
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 7.746478873239397 38
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 7.746478873239397 48
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2b81200b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 7.746478873239397 27
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 8.45070422535207 39
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 8.45070422535207 49
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120048> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 7.746478873239397 28
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 8.45070422535207 40
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 8.45070422535207 50
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6160> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 8.45070422535207 29
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 9.154929577464742 41
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 9.154929577464742 51
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6ef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 9.154929577464742 30
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 9.859154929577414 42
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 9.859154929577414 52
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 9.859154929577414 31
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 10.563380281690087 43
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 10.563380281690087 53
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6ef0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 10.563380281690087 32
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 11.26760563380276 44
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 11.26760563380276 54
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e70b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6da0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 11.26760563380276 33
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 11.971830985915432 45
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 11.971830985915432 55
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e70b8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087748> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6da0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 11.26760563380276 34
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 11.971830985915432 46
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 11.971830985915432 56
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->4->19->5
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81200b8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1e10> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 11.26760563380276 35
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 11.971830985915432 47
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 11.971830985915432 57
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81200b8> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1e10> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 11.26760563380276 36
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 11.971830985915432 48
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 11.971830985915432 58
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1e10> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 7.0422535211267245 16
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 11.26760563380276 37
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 11.971830985915432 49
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 11.971830985915432 59
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1e10> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 7.0422535211267245 17
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 11.26760563380276 38
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 11.971830985915432 50
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 11.971830985915432 60
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81200b8> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1e10> 0.7042253521126725 7
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 7.0422535211267245 18
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 11.26760563380276 39
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 11.971830985915432 51
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 11.971830985915432 61
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 11.971830985915432 40
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 12.676056338028104 52
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 12.676056338028104 62
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 8.45070422535207 20
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 12.676056338028104 41
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 13.380281690140777 53
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 13.380281690140777 63
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->4->19->5->14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a81965f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 3.5211267605633623 11
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 9.154929577464742 21
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 13.380281690140777 42
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 14.084507042253449 54
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 14.084507042253449 64
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196160> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 3.5211267605633623 12
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 9.154929577464742 22
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 13.380281690140777 43
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 14.084507042253449 55
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 14.084507042253449 65
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 9.154929577464742 23
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 13.380281690140777 44
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 14.084507042253449 56
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 14.084507042253449 66
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 3.5211267605633623 14
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 9.154929577464742 24
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 13.380281690140777 45
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 14.084507042253449 57
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 14.084507042253449 67
Completed Iteration #6
Best Reward: 0.7042253521126725
coverage_call_count 1500
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81965f8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196358> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 3.5211267605633623 15
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 9.154929577464742 25
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 13.380281690140777 46
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 14.084507042253449 58
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 14.084507042253449 68
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 3.5211267605633623 16
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 9.154929577464742 26
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 13.380281690140777 47
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 14.084507042253449 59
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 14.084507042253449 69
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 2.1126760563380174 10
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 3.5211267605633623 17
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 9.154929577464742 27
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 13.380281690140777 48
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 14.084507042253449 60
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 14.084507042253449 70
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174be0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196160> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 4.225352112676035 18
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 9.859154929577414 28
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 14.084507042253449 49
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 14.788732394366122 61
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 14.788732394366122 71
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a81967b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dea90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 3.5211267605633623 12
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 4.929577464788707 19
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 10.563380281690087 29
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 14.788732394366122 50
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 15.492957746478794 62
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 15.492957746478794 72
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->4->19->5->14->3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81967b8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dea90> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 4.929577464788707 20
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 10.563380281690087 30
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 14.788732394366122 51
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 15.492957746478794 63
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 15.492957746478794 73
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dea90> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 4.225352112676035 14
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 5.63380281690138 21
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 11.26760563380276 31
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 15.492957746478794 52
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 16.197183098591466 64
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 16.197183098591466 74
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81967b8> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dea90> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 4.225352112676035 15
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 5.63380281690138 22
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 11.26760563380276 32
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 15.492957746478794 53
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 16.197183098591466 65
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 16.197183098591466 75
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174c50> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dea90> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 4.225352112676035 16
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 5.63380281690138 23
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 11.26760563380276 33
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 15.492957746478794 54
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 16.197183098591466 66
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 16.197183098591466 76
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa310071978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dea90> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 3.5211267605633623 10
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 4.929577464788707 17
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 6.338028169014052 24
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 11.971830985915432 34
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 16.197183098591466 55
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 16.90140845070414 67
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 16.90140845070414 77
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196358> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 3.5211267605633623 11
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 4.929577464788707 18
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 6.338028169014052 25
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 11.971830985915432 35
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 16.197183098591466 56
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 16.90140845070414 68
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 16.90140845070414 78
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174c50> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dea90> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 3.5211267605633623 12
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 4.929577464788707 19
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 6.338028169014052 26
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 11.971830985915432 36
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 16.197183098591466 57
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 16.90140845070414 69
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 16.90140845070414 79
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 4.225352112676035 13
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 5.63380281690138 20
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 7.0422535211267245 27
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 12.676056338028104 37
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 16.90140845070414 58
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 17.60563380281681 70
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 17.60563380281681 80
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196e80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196358> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 4.929577464788707 14
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 6.338028169014052 21
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 7.746478873239397 28
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 13.380281690140777 38
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 17.60563380281681 59
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 18.309859154929484 71
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 18.309859154929484 81
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 4.929577464788707 15
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 6.338028169014052 22
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 7.746478873239397 29
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 13.380281690140777 39
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 17.60563380281681 60
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 18.309859154929484 72
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 18.309859154929484 82
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 4.929577464788707 16
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 6.338028169014052 23
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 7.746478873239397 30
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 13.380281690140777 40
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 17.60563380281681 61
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 18.309859154929484 73
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 18.309859154929484 83
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->4->19->5->14->3->3
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 4.929577464788707 17
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 6.338028169014052 24
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 7.746478873239397 31
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 13.380281690140777 41
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 17.60563380281681 62
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 18.309859154929484 74
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 18.309859154929484 84
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 5.63380281690138 18
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 7.0422535211267245 25
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 8.45070422535207 32
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 14.084507042253449 42
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 18.309859154929484 63
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 19.014084507042156 75
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 19.014084507042156 85
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157550> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 5.63380281690138 19
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 7.0422535211267245 26
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 8.45070422535207 33
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 14.084507042253449 43
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 18.309859154929484 64
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 19.014084507042156 76
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 19.014084507042156 86
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->4->19->5->14->3->3->0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 5.63380281690138 20
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 7.0422535211267245 27
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 8.45070422535207 34
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 14.084507042253449 44
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 18.309859154929484 65
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 19.014084507042156 77
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 19.014084507042156 87
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 6.338028169014052 21
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 7.746478873239397 28
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 9.154929577464742 35
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 14.788732394366122 45
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 19.014084507042156 66
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 19.71830985915483 78
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 19.71830985915483 88
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f95f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90f0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196780> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 7.0422535211267245 22
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 8.45070422535207 29
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 9.859154929577414 36
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 15.492957746478794 46
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 19.71830985915483 67
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 20.4225352112675 79
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 20.4225352112675 89
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f95f8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9438> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90f0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196780> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 7.746478873239397 23
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 9.154929577464742 30
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 10.563380281690087 37
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 16.197183098591466 47
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 20.4225352112675 68
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 21.126760563380174 80
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 21.126760563380174 90
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9438> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90f0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196780> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 8.45070422535207 24
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 9.859154929577414 31
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 11.26760563380276 38
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 16.90140845070414 48
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 21.126760563380174 69
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 21.830985915492846 81
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 21.830985915492846 91
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9438> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90f0> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196780> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 8.45070422535207 25
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 9.859154929577414 32
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 11.26760563380276 39
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 16.90140845070414 49
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 21.126760563380174 70
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 21.830985915492846 82
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 21.830985915492846 92
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196780> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 9.154929577464742 26
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 10.563380281690087 33
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 11.971830985915432 40
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 17.60563380281681 50
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 21.830985915492846 71
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 22.53521126760552 83
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 22.53521126760552 93
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7860> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196780> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 9.154929577464742 27
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 10.563380281690087 34
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 11.971830985915432 41
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 17.60563380281681 51
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 21.830985915492846 72
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 22.53521126760552 84
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 22.53521126760552 94
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105160> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9438> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90f0> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196780> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 4.929577464788707 14
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 9.154929577464742 28
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 10.563380281690087 35
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 11.971830985915432 42
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 17.60563380281681 52
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 21.830985915492846 73
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 22.53521126760552 85
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 22.53521126760552 95
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b4e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bb70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 5.63380281690138 15
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 9.859154929577414 29
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 11.26760563380276 36
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 12.676056338028104 43
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 18.309859154929484 53
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 22.53521126760552 74
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 23.23943661971819 86
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 23.23943661971819 96
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81571d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ac8> 6.338028169014052 16
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174b38> 10.563380281690087 30
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 11.971830985915432 37
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079f28> 13.380281690140777 44
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120588> 19.014084507042156 54
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4e0> 23.23943661971819 75
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f4a8> 23.943661971830863 87
backprop <src.mcts.MCTS_Node object at 0x7fa2b80addd8> 23.943661971830863 97
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->4->19->5->14->3->3->0->13
Best Reward: 0.7042253521126725
iteration: 53
found coverage increase 0.7042253521126725
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 1600
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81056a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c88> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f92b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 1700
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813ba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813ba90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81746d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81746d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81746d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81746d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81debe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174518> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e72b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64e0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1800
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81deb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81deb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b60b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81deb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80deef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80add30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de400> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad7b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81ded68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81034a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81030f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 14
Completed Iteration #20
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144eb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81deb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81034a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81889b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81889b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81882e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81888d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81888d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199400> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81889e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81050b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81050b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81deb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 2100
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81885f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81885f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80795c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81743c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80795c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81444a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81743c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81032b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c60b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100085f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c65f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310008ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144128> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7aff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100625f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af2b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ec50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002ec50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 2300
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310152390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa338064198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100086d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100976a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa310082630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31019afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 2400
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100624e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31019afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e48> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101107b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6470b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6556d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6470b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100827b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa33ff671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31019af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101107b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81882e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101107b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101107b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6551d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6470b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6727b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31019af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100085f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20612e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f5f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20899b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101106a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 2600
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6722e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672860> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20289e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20287b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20287b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20896a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20896a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310110c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf74a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf74a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d160> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b964e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b962b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b966a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86ba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b860f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b860f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81744a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa33ff671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101100f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310082dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310152390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7f98> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 69.71830985915493
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6477b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6477b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100620f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa338064160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa33ffc6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa33ffec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7427f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa338064160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6449e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d56a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6440f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6440f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81883c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6ef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81882b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b98d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6c50> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81744a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100eefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100eefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103828> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31011a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 4
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 5
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 6
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 8
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 9
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80def98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80def98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80569e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80def98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80def98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d30> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80add30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80deb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80deb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80deb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80deb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157e10> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81defd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310071d30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a81960b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80565c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80565c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80565c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 7
Completed Iteration #11
Best Reward: 0
coverage_call_count 3400
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3358> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81749b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81749b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6721d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81749b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a203de10> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b960b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b960b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b960b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96940> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20286d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 3500
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3173c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e317f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061f28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6552e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20899b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5588> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a21d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ce48> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a20b8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e267390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2772e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e277588> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5c0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2947342b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29471f8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fa20> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2947342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2947345c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2947347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2947349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2947345c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3380644e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 22
Completed Iteration #23
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2947342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb38> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f5f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946545c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2675c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 14
Completed Iteration #20
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ada0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946252b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946332e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946332b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946332b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946259b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946259e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946337f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946337f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946337b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946336d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946256d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946256d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946336d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946337b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7837f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946330f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7837f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294633f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7acdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7accc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7accc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7accc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa338064208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa29e277278> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ef0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2773c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2092e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2773c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a25f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e317dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3340b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20447b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20447b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20440f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20893c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20893c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6721d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2092e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2092e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fdd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa310071710> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81052e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100713c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100713c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100713c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100713c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105f28> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3170b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 4500
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3170b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2670f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6721d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3170b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3170b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e209940> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e3177b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f91d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ded30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ded30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ded30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 4600
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81964e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81964e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310071e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81206a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81886a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81206a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 7
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 8
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 9
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310041668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7079e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100625c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101106d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31019af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310124c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101b10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101100f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101100f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101b10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101100f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3101b10b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67cf28> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc707710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 69.71830985915493
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20619b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20619b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb908> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310097080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 4900
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3101106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294654390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81766a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31002e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81766a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29471f748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2947346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2947349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2947349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e76d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e76d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2947349e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29470fda0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2947346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b965f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b965f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b965f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2947346a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294625438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946330b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ace48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ace48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db1d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5e48> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c9b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa310062320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aaa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa310062320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5eda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946657f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5edb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aada0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db978> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5481d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5481d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5068d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5481d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5069e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5481d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5481d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5481d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5211d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5481d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 5300
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5481d0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5481d0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5481d0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5481d0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2947346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5764e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d506208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5214a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5214a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d576470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4879b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4879e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7acef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7acef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946657f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946657f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ced30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448c18> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 10
Completed Iteration #8
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4709b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4709b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45eb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5767b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4483c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5767b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b965f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5767b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4225f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4225f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4223c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4225f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4227b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4376a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc71d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc71d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7550> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5065c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ceac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d422550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbbe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d437710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf905c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf905c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa06a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa08d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5065c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 5700
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5065c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf732b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf739b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf732b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf007b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf739e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf009e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf152b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf007b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf902b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaef60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b0f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceeff98> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 69.71830985915493
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4222e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4222e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4222e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4222e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce876a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cebadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cebacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73160> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cebacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87fd0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce470f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cebabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cebab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310097e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce470f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cebaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8196cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8176278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 69.71830985915493
coverage_call_count 6000
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3380d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cebae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cebada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cebac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cebac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce872e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce870b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cebac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce870b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47be0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc72e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7f28> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e128> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e860> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce872e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cebad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceba470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5217b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d576b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d521940> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7e6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310062b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6d8da0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946256a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8120fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ed5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5486a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aac50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aac50> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5215c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aac50> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 20
Completed Iteration #20
Best Reward: 0
coverage_call_count 6200
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294625da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d448f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d548048> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4872b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26d4cebe0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946653c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294734e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946658d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946653c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294665da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946335f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d487390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cebada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946335f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc67c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce87e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 6300
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d487f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633ef0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946335f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294734978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d576b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce876d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce876d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce876d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946545f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d548b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294654d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946545f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa294654080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cebad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a204fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8079898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d45e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29470fb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5211d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29470fb00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d5ede48> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce47358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d59cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294633ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b96c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5487b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946544e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5487b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c588> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8174f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8066d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc63bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31002eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7af978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa294618470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310110630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d576b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2946ebd30> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5aa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1bf76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d59c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d521e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310008d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81886a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfa08d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5db710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100417b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100417b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d521908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100eefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80add30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba655eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a90b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a203d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa38bd4b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8056630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31011a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8087e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294654400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b8103e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310041160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100417b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29470f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa31012c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294665c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 10
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 11
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 12
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7075c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d5dbcc0> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294618668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 6600
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29468ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d448d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946fc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a8157eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e209390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a813ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a814ba20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d45ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6726a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2947342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20fc2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3438> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3171d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3171d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3172e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a81e7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20284a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310082fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3347f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20284a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc655b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a1b86550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100ac6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e267d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e24fd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c400> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3340f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b81a95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100824e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3172e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3340f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3340f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2089fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3172e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2947342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e3172e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cfd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80add68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2b80add68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d548e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a22b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29468a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2a2208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7833c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294633908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2c3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfc7a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29471f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2946eb5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7835f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d783358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29471f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa294625940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba6442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2061550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf905c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a8105e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90b38> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a201c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf90128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf902e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a813ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc672358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a811a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8188080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3100713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e317e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7c52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b803fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a81b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2093c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e267cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e28c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d422780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4372b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefd68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4229e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4229e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e209470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc647780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20893c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d783c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4709b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20893c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20893c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20896d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e334b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa31012c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5060f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5062b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a814b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d506400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d783550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d7ac780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc718780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4376a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2092e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4370b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfaedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2092e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e2092e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa29e334160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4372e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4372e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e76a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 7100
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf157f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf157f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00ac8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce659b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8144550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc7075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e3347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb828> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d496630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa3100713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa28d79af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceefb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d506978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e22c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce655c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce655c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf150b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 7200
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d7acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e2093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe714e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe630f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b80dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe714e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a20896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e24f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d5067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa310071978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d470c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a2028e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d422278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa28d79aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf5b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce654e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65e80> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c50> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ddbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2946c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ddeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ceef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4db4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa29e277cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d422978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe059e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d470630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe059e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe059e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05d30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2ba644c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cfd7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7521d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2b8199128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7521d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cecfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f08d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f05c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c5c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cedb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7527f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7524e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd400> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f752c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f752c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe71b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2a80f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f71bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f730978> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf73240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa2a20e3eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26cf15fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7bde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7309e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7303c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7307b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f689390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f689470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f689828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f689320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6895c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f689e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f689b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6895c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0f98> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f09b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f689f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa2dc742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7adc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7adc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7adc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26ce655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e76a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26cf00e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f752550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f752550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f752898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f671240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f752550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f671400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f671470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b780> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f671e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f671080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe63390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d496860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26ce65518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f71bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6446a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d4e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f671c50> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f79c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f689748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7307f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f79ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f671198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f730fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f0da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f671048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f671630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f752898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6718d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f752898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6714e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c92e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ac50> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa26d437e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7128> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f63ad30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f671128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 7800
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6716a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6716a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1c90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f671198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f671278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6518d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f651470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f194c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1949e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d77b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1943c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1949e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1949e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7307f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1949e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa25f7c0fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f194f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f194f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1503c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f194898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f70b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f644a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1503c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1503c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f1507b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 7900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f194160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f194160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f671128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b22e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f150668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f150128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f150208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f194160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f689860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f150be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f150fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f150470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f17bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f150ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f125208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f125438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f125320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f125320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f125710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f125668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f125320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f125978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f125a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f125e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f125d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1255c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f125e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e7f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 302
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f125b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f6e7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f17bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7dd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25fe05780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f651cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f125b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f17bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f125eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f150128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f63a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 16
Completed Iteration #23
Best Reward: 0
coverage_call_count 8000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f67f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f125828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f150fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f1257b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 303
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6519e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f150cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6519e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f7309e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f194400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6712e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6519e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f194400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6712e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f6712e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f1d7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f194fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f6511d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 304
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f1b27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f125160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f10ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f17bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f69c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f125160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f125160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa25f0861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa25f0e7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa25f0d6518> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 305
found coverage increase 0
Current Total Coverage 69.71830985915493
initial coverage: 69.0141
time passed (minutes): 60.2117
iterations: 306
number of new inputs: 64
final coverage: 69.7183
total coverage increase: 0.704225
