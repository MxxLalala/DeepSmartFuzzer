Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f333692af28>, tc2=<function tc2 at 0x7f3336939048>, tc3=<function tc3 at 0x7f3336939158>, tfc_threshold=3300000, time_period=3600, verbose=True)
initial coverage: 69.0141
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87639e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87185c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87187f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a2e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1438> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87180f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873add8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8718780> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87632e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86631d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86561d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86631d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86564e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86569b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c869fdd8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874de10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87764a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07baba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87764a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07baf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8663c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87764a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07bac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07baa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07971d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781550> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07972b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07814a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07814a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07eff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 400
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07979b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.7042253521126725 13
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.7042253521126725 14
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07bae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.7042253521126725 15
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 1.408450704225345 16
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 2.1126760563380174 17
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 2.1126760563380174 18
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 2.1126760563380174 19
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07efa58> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ba8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 2.81690140845069 20
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 2.81690140845069 21
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 2.81690140845069 22
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06fff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efa58> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff828> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ba8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 2.81690140845069 12
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 2.81690140845069 23
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0724400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff278> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 3.5211267605633623 24
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 3.5211267605633623 14
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 3.5211267605633623 25
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 3.5211267605633623 15
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 3.5211267605633623 26
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 4.225352112676035 16
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 4.225352112676035 27
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07292e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 4.929577464788707 17
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 4.929577464788707 28
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0729860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 5.63380281690138 18
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 5.63380281690138 29
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0729ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 6.338028169014052 19
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 6.338028169014052 30
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0729b38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff278> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 7.0422535211267245 20
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 7.0422535211267245 31
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 7.0422535211267245 21
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 7.0422535211267245 32
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e82e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ba8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 7.746478873239397 22
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 7.746478873239397 33
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff9b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 8.45070422535207 23
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 8.45070422535207 34
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0729d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 9.154929577464742 24
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 9.154929577464742 35
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff4a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 9.859154929577414 25
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 9.859154929577414 36
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0724b38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07243c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729860> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 10.563380281690087 26
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 10.563380281690087 37
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07302b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 11.26760563380276 27
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 11.26760563380276 38
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724b38> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07243c8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0729860> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 11.26760563380276 28
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 11.26760563380276 39
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0724da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730a20> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07302b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 11.971830985915432 29
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 11.971830985915432 40
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0730780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729ba8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 12.676056338028104 30
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 12.676056338028104 41
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730a20> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07302b0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 9.154929577464742 17
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 12.676056338028104 31
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 12.676056338028104 42
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07302b0> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 13.380281690140777 32
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 13.380281690140777 43
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc2e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc9b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff4a8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 14.084507042253449 33
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 14.084507042253449 44
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 10.563380281690087 20
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 14.084507042253449 34
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 14.084507042253449 45
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffda0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 11.26760563380276 21
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 14.788732394366122 35
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 14.788732394366122 46
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->6->19
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656c50> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0729ba8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 11.26760563380276 22
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 14.788732394366122 36
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 14.788732394366122 47
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07300b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 11.971830985915432 23
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 15.492957746478794 37
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 15.492957746478794 48
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0730ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 12.676056338028104 24
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 16.197183098591466 38
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 16.197183098591466 49
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 13.380281690140777 25
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 16.90140845070414 39
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 16.90140845070414 50
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07309e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d82e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07300b8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 14.084507042253449 26
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 17.60563380281681 40
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 17.60563380281681 51
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07292e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 14.788732394366122 27
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 18.309859154929484 41
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 18.309859154929484 52
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729d30> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 11.971830985915432 20
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 15.492957746478794 28
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 19.014084507042156 42
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 19.014084507042156 53
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc9b0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff4a8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 15.492957746478794 29
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 19.014084507042156 43
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 19.014084507042156 54
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729ba8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 12.676056338028104 22
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 16.197183098591466 30
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 19.71830985915483 44
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 19.71830985915483 55
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef5c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 16.90140845070414 31
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 20.4225352112675 45
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 20.4225352112675 56
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0757f98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07297b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f60> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 17.60563380281681 32
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 21.126760563380174 46
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 21.126760563380174 57
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b067f208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07297b8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f60> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 14.788732394366122 25
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 18.309859154929484 33
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 21.830985915492846 47
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 21.830985915492846 58
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3304e62b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07297b8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f60> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 18.309859154929484 34
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 21.830985915492846 48
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 21.830985915492846 59
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32fc76ba90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32fc76b898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730ac8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 15.492957746478794 27
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 19.014084507042156 35
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 22.53521126760552 49
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 22.53521126760552 60
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->6->19->4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32f4062da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff9b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 16.197183098591466 28
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 19.71830985915483 36
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 23.23943661971819 50
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 23.23943661971819 61
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c87caf98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff9b0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 16.90140845070414 29
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 20.4225352112675 37
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 23.943661971830863 51
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 23.943661971830863 62
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 17.60563380281681 30
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 21.126760563380174 38
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 24.647887323943536 52
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 24.647887323943536 63
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef5c0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 17.60563380281681 31
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 21.126760563380174 39
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 24.647887323943536 53
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 24.647887323943536 64
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 18.309859154929484 32
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 21.830985915492846 40
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 25.35211267605621 54
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 25.35211267605621 65
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0757e80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076dcc0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8780> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8470> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0729d30> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 19.014084507042156 33
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 22.53521126760552 41
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 26.05633802816888 55
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 26.05633802816888 66
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8470> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0729d30> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 6.338028169014052 12
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 19.014084507042156 34
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 22.53521126760552 42
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 26.05633802816888 56
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 26.05633802816888 67
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca550> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8978> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 7.746478873239397 15
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 19.014084507042156 35
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 22.53521126760552 43
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 26.05633802816888 57
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 26.05633802816888 68
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca3c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cab38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca550> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8978> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 8.45070422535207 16
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 19.71830985915483 36
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 23.23943661971819 44
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 26.760563380281553 58
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 26.760563380281553 69
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f334eff3400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 9.154929577464742 17
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 20.4225352112675 37
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 23.943661971830863 45
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 27.464788732394226 59
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 27.464788732394226 70
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->6->19->4->12
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 9.154929577464742 18
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 20.4225352112675 38
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 23.943661971830863 46
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 27.464788732394226 60
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 27.464788732394226 71
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076dcc0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8780> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8470> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0729d30> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 20.4225352112675 39
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 23.943661971830863 47
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 27.464788732394226 61
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 27.464788732394226 72
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0781dd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 21.126760563380174 40
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 24.647887323943536 48
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 28.169014084506898 62
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 28.169014084506898 73
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729d30> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 7.746478873239397 17
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 9.859154929577414 21
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 21.126760563380174 41
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 24.647887323943536 49
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 28.169014084506898 63
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 28.169014084506898 74
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c873ab70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef5c0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 10.563380281690087 22
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 21.830985915492846 42
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 25.35211267605621 50
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 28.87323943661957 64
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 28.87323943661957 75
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0797978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8470> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0729d30> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 11.26760563380276 23
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 22.53521126760552 43
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 26.05633802816888 51
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 29.577464788732243 65
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 29.577464788732243 76
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0797710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff3400> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 11.971830985915432 24
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 23.23943661971819 44
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 26.760563380281553 52
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 30.281690140844916 66
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 30.281690140844916 77
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07a59e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 10.563380281690087 21
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 12.676056338028104 25
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 23.943661971830863 45
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 27.464788732394226 53
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 30.985915492957588 67
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 30.985915492957588 78
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c87caeb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 11.26760563380276 22
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 13.380281690140777 26
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 24.647887323943536 46
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 28.169014084506898 54
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 31.69014084507026 68
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 31.69014084507026 79
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0781390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a59e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 11.971830985915432 23
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 14.084507042253449 27
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 25.35211267605621 47
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 28.87323943661957 55
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 32.39436619718293 69
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 32.39436619718293 80
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->6->19->4->12->2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c873ab00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efb70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a59e8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 12.676056338028104 24
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 14.788732394366122 28
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 26.05633802816888 48
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 29.577464788732243 56
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 33.098591549295605 70
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 33.098591549295605 81
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffef0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff9b0> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 12.676056338028104 25
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 14.788732394366122 29
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 26.05633802816888 49
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 29.577464788732243 57
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 33.098591549295605 71
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 33.098591549295605 82
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0781c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 13.380281690140777 26
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 15.492957746478794 30
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 26.760563380281553 50
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 30.281690140844916 58
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 33.80281690140828 72
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 33.80281690140828 83
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07babe0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a55c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87caf98> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff9b0> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 14.084507042253449 27
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 16.197183098591466 31
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 27.464788732394226 51
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 30.985915492957588 59
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 34.50704225352095 73
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 34.50704225352095 84
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873ab00> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07efb70> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a59e8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 14.084507042253449 28
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 16.197183098591466 32
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 27.464788732394226 52
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 30.985915492957588 60
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 34.50704225352095 74
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 34.50704225352095 85
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 14.788732394366122 29
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 16.90140845070414 33
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 28.169014084506898 53
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 31.69014084507026 61
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 35.21126760563362 75
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 35.21126760563362 86
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c87caf28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 15.492957746478794 30
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 17.60563380281681 34
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 28.87323943661957 54
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 32.39436619718293 62
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 35.915492957746295 76
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 35.915492957746295 87
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873ab38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781c18> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 16.197183098591466 31
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 18.309859154929484 35
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 29.577464788732243 55
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 33.098591549295605 63
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 36.61971830985897 77
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 36.61971830985897 88
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0757ef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781f28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a59e8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 16.90140845070414 32
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 19.014084507042156 36
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 30.281690140844916 56
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 33.80281690140828 64
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 37.32394366197164 78
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 37.32394366197164 89
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 16.90140845070414 33
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 19.014084507042156 37
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 30.281690140844916 57
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 33.80281690140828 65
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 37.32394366197164 79
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 37.32394366197164 90
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 17.60563380281681 34
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 19.71830985915483 38
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 30.985915492957588 58
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 34.50704225352095 66
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 38.02816901408431 80
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 38.02816901408431 91
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->6->19->4->12->2->11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87caf28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 11.26760563380276 20
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 18.309859154929484 35
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 20.4225352112675 39
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 31.69014084507026 59
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 35.21126760563362 67
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 38.732394366196985 81
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 38.732394366196985 92
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c86630b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076dda0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8663588> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87caf28> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 19.014084507042156 36
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 21.126760563380174 40
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 32.39436619718293 60
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 35.915492957746295 68
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 39.43661971830966 82
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 39.43661971830966 93
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c8679898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a59e8> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 12.676056338028104 22
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 19.71830985915483 37
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 21.830985915492846 41
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 33.098591549295605 61
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 36.61971830985897 69
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 40.14084507042233 83
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 40.14084507042233 94
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8a90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ef0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 20.4225352112675 38
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 22.53521126760552 42
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 33.80281690140828 62
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 37.32394366197164 70
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 40.845070422535 84
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 40.845070422535 95
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca2b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757ef0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781f28> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07a59e8> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 21.126760563380174 39
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 23.23943661971819 43
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 34.50704225352095 63
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 38.02816901408431 71
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 41.549295774647675 85
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 41.549295774647675 96
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b0797470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b00> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 14.788732394366122 25
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 21.830985915492846 40
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 23.943661971830863 44
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 35.21126760563362 64
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 38.732394366196985 72
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 42.25352112676035 86
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 42.25352112676035 97
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c8663f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 11.971830985915432 19
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 15.492957746478794 26
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 22.53521126760552 41
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 24.647887323943536 45
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 35.915492957746295 65
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 39.43661971830966 73
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 42.95774647887302 87
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 42.95774647887302 98
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663588> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87caf28> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 11.971830985915432 20
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 15.492957746478794 27
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 22.53521126760552 42
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 24.647887323943536 46
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 35.915492957746295 66
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 39.43661971830966 74
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 42.95774647887302 88
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 42.95774647887302 99
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663588> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f32c87caf28> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 15.492957746478794 28
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 22.53521126760552 43
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 24.647887323943536 47
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 35.915492957746295 67
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 39.43661971830966 75
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 42.95774647887302 89
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 42.95774647887302 100
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663f28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 12.676056338028104 22
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 16.197183098591466 29
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 23.23943661971819 44
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 25.35211267605621 48
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 36.61971830985897 68
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 40.14084507042233 76
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 43.66197183098569 90
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 43.66197183098569 101
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->6->19->4->12->2->11->4
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c86d16d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 16.90140845070414 30
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 23.943661971830863 45
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 26.05633802816888 49
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 37.32394366197164 69
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 40.845070422535 77
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 44.366197183098365 91
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 44.366197183098365 102
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c86d10f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d16d8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 17.60563380281681 31
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 24.647887323943536 46
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 26.760563380281553 50
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 38.02816901408431 70
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 41.549295774647675 78
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 45.07042253521104 92
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 45.07042253521104 103
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07974e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781c18> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 14.788732394366122 25
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 18.309859154929484 32
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 25.35211267605621 47
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 27.464788732394226 51
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 38.732394366196985 71
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 42.25352112676035 79
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 45.77464788732371 93
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 45.77464788732371 104
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c868c550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d10f0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1898> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d16d8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 15.492957746478794 26
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 19.014084507042156 33
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 26.05633802816888 48
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 28.169014084506898 52
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 39.43661971830966 72
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 42.95774647887302 80
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 46.47887323943638 94
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 46.47887323943638 105
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32b07979e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 16.197183098591466 27
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 19.71830985915483 34
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 26.760563380281553 49
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 28.87323943661957 53
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 40.14084507042233 73
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 43.66197183098569 81
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 47.183098591549054 95
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 47.183098591549054 106
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b00> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 16.90140845070414 28
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 20.4225352112675 35
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 27.464788732394226 50
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 29.577464788732243 54
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 40.845070422535 74
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 44.366197183098365 82
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 47.88732394366173 96
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 47.88732394366173 107
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 17.60563380281681 29
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 21.126760563380174 36
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 28.169014084506898 51
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 30.281690140844916 55
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 41.549295774647675 75
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 45.07042253521104 83
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 48.5915492957744 97
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 48.5915492957744 108
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c87769b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 18.309859154929484 30
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 21.830985915492846 37
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 28.87323943661957 52
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 30.985915492957588 56
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 42.25352112676035 76
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 45.77464788732371 84
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 49.29577464788707 98
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 49.29577464788707 109
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 19.014084507042156 31
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 22.53521126760552 38
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 29.577464788732243 53
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 31.69014084507026 57
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 42.95774647887302 77
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 46.47887323943638 85
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 49.999999999999744 99
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 49.999999999999744 110
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c873ad30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87769b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 10.563380281690087 16
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 19.71830985915483 32
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 23.23943661971819 39
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 30.281690140844916 54
backprop <src.mcts.MCTS_Node object at 0x7f32b0797ac8> 32.39436619718293 58
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 43.66197183098569 78
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 47.183098591549054 86
backprop <src.mcts.MCTS_Node object at 0x7f32c86560b8> 50.70422535211242 100
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 50.70422535211242 111
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->6->19->4->12->2->11->4->18
Best Reward: 0.7042253521126725
iteration: 18
found coverage increase 0.7042253521126725
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776978> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87761d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87180f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87180f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87186d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87186d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87295f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32f4062eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc8d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07292b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87185c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87185c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f8d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 69.71830985915493
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87769e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87769e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf614a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf614a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf166a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf265f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf260b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf260b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf263c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf263c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf263c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf263c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf266d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf263c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07975c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf166d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf166d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf618d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf614e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce804a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf166a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0797780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87185c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 15
Completed Iteration #21
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87185c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5ddd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce759e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce759e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce759e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce759e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1902b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1902b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1902b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0decc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf617f0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb4a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1031d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1031d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cee2080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0426d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0426d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0426d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0084e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0084e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0088d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0361d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0461d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652584a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652583c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652584a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652584a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32652472b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1271d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1274a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1274a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1271d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1274a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3265258c18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cea2a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef36d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef36d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c136e48> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf264e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf264e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f334eff3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc77a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265247da0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32fc76ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f334eff3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32fc76ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc77a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf618d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf61f28> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1365c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1365c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32f4062dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 1900
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87294a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07304e0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07240b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07240b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07249b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07243c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86560f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 2000
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07972e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b076dbe0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652584e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b067f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1278d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1278d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07eff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07575f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 18
Completed Iteration #20
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076d6a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06fff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce805f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1031d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07240b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07bad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce808d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a86a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf378d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 2300
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1366d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07babe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05cf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce48> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0420f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce508d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce508d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce508d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0724a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06efe48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652729b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0dedd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258047390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325801fe80> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652722b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce804e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265272278> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258035940> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543faf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543faf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543995f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 8
Completed Iteration #6
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543faac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543faac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543faac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543632e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fafd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543634a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254371c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543327f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543324a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543324a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543326d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543325c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543324a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325431dfd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bdc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543999b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bdc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bdc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542d4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325431df28> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bdd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332048> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2900
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87caf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580470b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1906a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580470b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf375f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf375f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b06efd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 17
Completed Iteration #24
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d46d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32580474e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07245c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd080> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07245c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4062dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07818d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4062dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07818d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07818d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07972e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076de80> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07bad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07245c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86634e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1031d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1031d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3302bec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87294a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8656f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc77acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87294a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87768d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f334eff3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87769e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87769e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8776080> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 11
Completed Iteration #17
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1905f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07245c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1905f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f334eff30f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf267f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cef3048> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c046be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0465c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d82e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652477b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543329e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543327b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543329e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543321d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543329e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652586d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543327f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0365f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0365f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8776780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0363c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0363c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652582b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c869f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0465c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0363c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0465c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254371f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0deeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0987b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dd68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf161d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580350f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce801d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8679c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce802e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce801d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5df98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce50940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce504e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265272390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543552b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543997b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543634e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543997b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543632b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ecf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0425f8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542eccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542eccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32542ec278> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801ff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801ff98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543997b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efe10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3254399320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0981d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543992b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324efb1dd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef681d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef568d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef560b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef560b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef565c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3254355358> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef689e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef689e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254363e80> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebecf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543994e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eef45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efbdb00> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee886a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee886d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef46d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee886d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324ee880b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 12
Completed Iteration #20
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee646a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee646a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ee765c0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee882e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ea20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee64780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ee645f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3daeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 4200
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325438a780> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee647f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 4300
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368ba8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3689b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c0b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d37a470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef169e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef160b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06efef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef569b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 4400
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ecda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef16f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ece48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef565c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ecb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ecb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d35c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3687f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3687f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef163c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3687f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3687f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324d37a7b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce802e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf169b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce802e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0757588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580355f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07572e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265272358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07572e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325801fba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0981d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0980b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0980b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0981d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0980b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32543c2be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 4600
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0363c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c127630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652473c8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8679be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86797b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32543c2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543636a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543faa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1367b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543636a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543faa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543faa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8679cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f326c008710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc77acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0981d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c06ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543fac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c0462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce752b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf616d8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 4700
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf267f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0460f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf267f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf263c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc77acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86797b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32652475f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87294a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07818d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0729588> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32f4062e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f334eff3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0464e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c0464e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c05c828> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1034a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1030b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1030b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1034a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868c6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1030b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543327f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d42b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542bd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cea24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254332780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542bd3c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32f4062e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf37b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3930b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543715f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32f4062e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ef80390> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 69.71830985915493
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0797908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3931d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce75e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07972b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a36d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07972b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe42e8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebeb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee88780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 5100
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee940b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c868cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c873a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ee94978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebed30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d393f60> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbdbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eef4048> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
coverage_call_count 5200
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543327b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543327b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee649e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3136d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3135c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3135c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3daba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7828> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8220f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543324e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8224a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8224a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8226d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8381d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3dafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3136a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 5300
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef681d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef687f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef687f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef687f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3daf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c190a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7668> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c838a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c822278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1579b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eef4940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4940> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1391d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1396a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1394e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1394e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1394a8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1766d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1766d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c12f748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c05c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1645f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1645f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c12fcc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0992e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c08a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6c88> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c164128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c19e278> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c077dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c077ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c077dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c01ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0029e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 5800
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd86a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247b87630> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb908> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bceeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0440b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bceeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0440b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bce0b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b121d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b126a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b128d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b127b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b127b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b127b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b123c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b295f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b129e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b297f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b127b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b291d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ace080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac09e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ace588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b123c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b123c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b125f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ace7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b123c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247aceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247acec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247aceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ace6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a861d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a94208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a861d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a94a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a94be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247acea90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a94470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a94a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247acee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a94160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8776ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247b870f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a94668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a94390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c098208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a864a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a864a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a945c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a945c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 21
Completed Iteration #22
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8550> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a940f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c08a550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c099588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0996a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08ad68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c176d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a94eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c002e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c08ad68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324c139ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c139898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf4fb00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1649e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1649e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c157588> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f334eff3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c164160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f334eff3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a86f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffb38> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e71d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffda0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce50e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1396a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1396a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1396a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a94be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c164f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c838e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c822da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8225c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c822160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c869f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf37be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d313ba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265258470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8386d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c822588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8386d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3130f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a94b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3130f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8386d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee76d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c8386d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c19e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8386d8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3130f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324d313668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a867f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c098208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a867f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd80b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8588> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efbd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eebeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eebe898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efe4438> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c099898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1e7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef68240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eef44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee94b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1396a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1fff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c08a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247a867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee88630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c157e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eef4a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c838438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c157898> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258047400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8718eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254399ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254332eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87186a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef80748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254332ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86d1ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8718ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c044320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254371d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c103eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c103630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c103390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3130b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c07c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3dac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c869ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b4b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d313198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247a86ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee94128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d313e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d393da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef802b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bd8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254399ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c8387f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaacc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8656390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0797fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bdf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8663b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaacc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324efe4630> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 6700
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8729a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b076dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07296a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c05c400> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06fff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8729a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32fc76bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0729d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b067fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87293c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87293c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b076d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efe4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce75748> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efbdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254371c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ff358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef68cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32543c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef80898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bd89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c12feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c07c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32542d45f8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c157e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3da4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324eeaac88> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652470f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c127048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c136898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b07efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325431d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d393b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431d828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265272b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542d4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0a8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cef38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32652474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325431dc18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee76710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c136828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cea2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c19e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee4ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c873a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee88a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c05c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c044c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c06eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3265247048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf166d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b067f828> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef169e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cef3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8663080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0730320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef166a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328ce5dd68> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0729198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 6900
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf37b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef2f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324efb1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0730080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c042278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef564e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef16048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef564e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324ef2fc50> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c8763278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d393160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf16e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef56710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f325801f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ef16ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c12feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c838080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c002ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258047f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328cf160f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c874da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c8229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324eeaa080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf61be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf26c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c15f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32f40789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1365c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1365c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c87caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3681d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32580359e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32b0757748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32f40789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d37aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254363588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d37aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c0ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254363ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c15f898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca208> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b07bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c190e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32c87ca4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0781e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32580359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ef56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0eb5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06d8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c8763438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c190a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c874da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328ce809e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3265247828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ace748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247acee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247acecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325438acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ace0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324efb19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247acedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c0de828> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ace860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b290b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b290b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac04a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c176eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b06ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ace390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325801f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247aceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce5df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf26160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f325801f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32542ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cee2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324eeaaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328cf16160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247ace2e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32543635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d368a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328ce80320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32542bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d368a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32b0724358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328cf164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35c320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c042f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c008cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f328c1275c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e48> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f325438ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b122e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87320> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d368a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324ee64240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3258035828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1900f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3254355e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1900f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247acebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ace8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b870b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ace208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b05cf8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0fdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c008320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c0d7470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324d3c79b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f326c046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c01e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c077390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c077860> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b87e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32f4026390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324d35ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b05e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247b12e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c44a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 2
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b12a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c444e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3246ca97f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0724080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f326c046748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b12b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c44c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bbba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c44a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c44fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c441d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c441d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c00128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b056d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b056d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c1ff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c44ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c44cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c00668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c00be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c00978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247acebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c00828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c00630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c006d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c077048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c00dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bcecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c44a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c1db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bce048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c00a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3258035f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bcec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ac0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c190240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c754e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c44c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1da58> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c00c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b29630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b29a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b5aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c2bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246ca9828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c2bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c2bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3247b059b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32465cfb00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465fa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246589080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246589630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465897f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465facc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465fa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32465fa470> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 7600
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfe80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c2bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d3c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c0fda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cfd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465dce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cf438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465dc438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f328c1903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c00048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c44c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c44c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324c190e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246589b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c9bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ace8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246ca91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f324c190e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c44be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246589c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246589588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dd30> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246589f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c2be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465460b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465460b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465460b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c2be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465460f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246562048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246589898> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246562668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246562a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246562cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246562550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324654f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324654f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324654f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324654f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324654f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324654f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324654f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324654f048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324654f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b05d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324654f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c75278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32465626d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246589358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c1deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247b5ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246589a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 7
Completed Iteration #10
Best Reward: 0
coverage_call_count 7700
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32b0781908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324ee64320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c44da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbb748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c2bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246562f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 9
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324651a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 10
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324651a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 11
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324c01e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 12
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324651ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324651aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 13
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324651ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 7
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 14
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246522400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32465cff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 15
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246522518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 8
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 16
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246522ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246522518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 9
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 17
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246522c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 10
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 18
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324652d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 11
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 19
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324652dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 12
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 20
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324653b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 13
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 21
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324652de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 0.7042253521126725 14
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 0.7042253521126725 22
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324653b208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324653b630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 1.408450704225345 15
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 1.408450704225345 23
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324653bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 1.408450704225345 16
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 1.408450704225345 24
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 1.408450704225345 17
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 1.408450704225345 25
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324651a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 1.408450704225345 18
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 1.408450704225345 26
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324651a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324651a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324652d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 1.408450704225345 19
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 1.408450704225345 27
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246c2bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 1.408450704225345 20
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 1.408450704225345 28
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324651abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 1.408450704225345 21
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 1.408450704225345 29
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32465225f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 2.1126760563380174 22
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 2.1126760563380174 30
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324651a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324651aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324653b208> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f324653b630> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 2.1126760563380174 23
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 2.1126760563380174 31
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3247b05e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3246522940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 2.81690140845069 24
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 2.81690140845069 32
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324d35c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246522940> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 2.81690140845069 25
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 2.81690140845069 33
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7c88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324654f6d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32465225f8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 3.5211267605633623 26
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 3.5211267605633623 34
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32465465c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324651ae80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32465225f8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 4.225352112676035 27
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 4.225352112676035 35
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3247b87e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324651ae80> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32465225f8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 4.929577464788707 28
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 4.929577464788707 36
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464e2160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324653b630> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 5.63380281690138 29
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 5.63380281690138 37
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464e2828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324653b630> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 6.338028169014052 30
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 6.338028169014052 38
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->6->19
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464e2e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 7.0422535211267245 31
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 7.0422535211267245 39
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246562358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324651add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bf7c88> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f324654f6d8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32465225f8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 7.0422535211267245 32
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 7.0422535211267245 40
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32465cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247ab0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3247b87e48> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f324651ae80> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32465225f8> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 7.0422535211267245 16
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 7.0422535211267245 33
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 7.0422535211267245 41
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
coverage_call_count 7800
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324654f0b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32465226d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2e48> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 7.746478873239397 17
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 7.746478873239397 34
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 7.746478873239397 42
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3246522d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c00b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32465225f8> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 8.45070422535207 35
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 8.45070422535207 43
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 9.154929577464742 36
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 9.154929577464742 44
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464e2b38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 6.338028169014052 12
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 9.859154929577414 37
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 9.859154929577414 45
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32c86e8940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3247bbbeb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2e48> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 10.563380281690087 21
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 10.563380281690087 38
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 10.563380281690087 46
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464e9b38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 11.26760563380276 22
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 11.26760563380276 39
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 11.26760563380276 47
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464e9f60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e9e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32465225f8> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 11.971830985915432 23
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 11.971830985915432 40
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 11.971830985915432 48
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464fb438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 12.676056338028104 24
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 12.676056338028104 41
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 12.676056338028104 49
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->6->19->4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 9.154929577464742 17
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 12.676056338028104 25
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 12.676056338028104 42
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 12.676056338028104 50
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464fbf98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464fbf28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2b38> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 13.380281690140777 26
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 13.380281690140777 43
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 13.380281690140777 51
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324654fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246589b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e9b38> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 9.859154929577414 19
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 13.380281690140777 27
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 13.380281690140777 44
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 13.380281690140777 52
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246562b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c75828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 13.380281690140777 28
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 13.380281690140777 45
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 13.380281690140777 53
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 10.563380281690087 21
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 14.084507042253449 29
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 14.084507042253449 46
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 14.084507042253449 54
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464fb438> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 10.563380281690087 22
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 14.084507042253449 30
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 14.084507042253449 47
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 14.084507042253449 55
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464e9be0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 11.26760563380276 23
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 14.788732394366122 31
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 14.788732394366122 48
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 14.788732394366122 56
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464fbe80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e95c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 11.971830985915432 24
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 15.492957746478794 32
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 15.492957746478794 49
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 15.492957746478794 57
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464fb978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464fb1d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e9b38> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 6.338028169014052 14
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 12.676056338028104 25
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 16.197183098591466 33
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 16.197183098591466 50
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 16.197183098591466 58
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324648a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324648a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464fbe80> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e95c0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 6.338028169014052 15
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 12.676056338028104 26
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 16.197183098591466 34
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 16.197183098591466 51
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 16.197183098591466 59
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324648ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246c2be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464fbf98> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464fbf28> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e2b38> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 6.338028169014052 16
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 12.676056338028104 27
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 16.197183098591466 35
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 16.197183098591466 52
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 16.197183098591466 60
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324648af28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324648a860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 7.0422535211267245 17
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 13.380281690140777 28
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 16.90140845070414 36
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 16.90140845070414 53
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 16.90140845070414 61
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e95c0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 7.0422535211267245 18
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 13.380281690140777 29
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 16.90140845070414 37
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 16.90140845070414 54
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 16.90140845070414 62
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464a0710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464a04e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2b38> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 14.084507042253449 30
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 17.60563380281681 38
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 17.60563380281681 55
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 17.60563380281681 63
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464e2a20> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 8.45070422535207 20
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 14.788732394366122 31
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 18.309859154929484 39
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 18.309859154929484 56
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 18.309859154929484 64
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464e96d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e9fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324648af28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f324648a860> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 9.154929577464742 21
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 15.492957746478794 32
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 19.014084507042156 40
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 19.014084507042156 57
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 19.014084507042156 65
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->6->19->4->13
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324648a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324648a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e9be0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 6.338028169014052 14
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 9.154929577464742 22
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 15.492957746478794 33
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 19.014084507042156 41
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 19.014084507042156 58
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 19.014084507042156 66
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 6.338028169014052 15
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 9.154929577464742 23
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 15.492957746478794 34
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 19.014084507042156 42
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 19.014084507042156 59
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 19.014084507042156 67
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464ba240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 7.0422535211267245 16
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 9.859154929577414 24
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 16.197183098591466 35
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 19.71830985915483 43
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 19.71830985915483 60
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 19.71830985915483 68
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464ba6d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 7.746478873239397 17
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 10.563380281690087 25
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 16.90140845070414 36
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 20.4225352112675 44
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 20.4225352112675 61
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 20.4225352112675 69
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464bad30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 11.26760563380276 26
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 17.60563380281681 37
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 21.126760563380174 45
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 21.126760563380174 62
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 21.126760563380174 70
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324648a8d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba6d8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464ba438> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464ba240> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 11.971830985915432 27
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 18.309859154929484 38
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 21.830985915492846 46
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 21.830985915492846 63
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 21.830985915492846 71
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464467b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464468d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 12.676056338028104 28
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 19.014084507042156 39
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 22.53521126760552 47
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 22.53521126760552 64
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 22.53521126760552 72
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32465226a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464fb978> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464fb1d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e9b38> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 10.563380281690087 21
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 13.380281690140777 29
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 19.71830985915483 40
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 23.23943661971819 48
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 23.23943661971819 65
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 23.23943661971819 73
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e9be0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 10.563380281690087 22
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 13.380281690140777 30
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 19.71830985915483 41
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 23.23943661971819 49
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 23.23943661971819 66
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 23.23943661971819 74
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464ba908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3246546860> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464fb978> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32464fb1d0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32464e9b38> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 11.26760563380276 23
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 14.084507042253449 31
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 20.4225352112675 42
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 23.943661971830863 50
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 23.943661971830863 67
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 23.943661971830863 75
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324653bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba908> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3246546860> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32464fb978> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32464fb1d0> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32464e9b38> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 11.26760563380276 24
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 14.084507042253449 32
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 20.4225352112675 43
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 23.943661971830863 51
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 23.943661971830863 68
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 23.943661971830863 76
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324648ab00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464bae48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e9be0> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 11.971830985915432 25
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 14.788732394366122 33
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 21.126760563380174 44
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 24.647887323943536 52
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 24.647887323943536 69
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 24.647887323943536 77
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464a0128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464a04e0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e2b38> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 12.676056338028104 26
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 15.492957746478794 34
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 21.830985915492846 45
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 25.35211267605621 53
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 25.35211267605621 70
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 25.35211267605621 78
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->6->19->4->13->7
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3246446518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 13.380281690140777 27
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 16.197183098591466 35
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 22.53521126760552 46
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 26.05633802816888 54
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 26.05633802816888 71
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 26.05633802816888 79
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464e9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246446ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 13.380281690140777 28
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 16.197183098591466 36
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 22.53521126760552 47
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 26.05633802816888 55
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 26.05633802816888 72
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 26.05633802816888 80
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3246446c88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464a0da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3246446518> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 14.084507042253449 29
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 16.90140845070414 37
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 23.23943661971819 48
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 26.760563380281553 56
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 26.760563380281553 73
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 26.760563380281553 81
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba550> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464ba6d8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32464ba438> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32464ba240> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 14.084507042253449 30
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 16.90140845070414 38
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 23.23943661971819 49
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 26.760563380281553 57
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 26.760563380281553 74
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 26.760563380281553 82
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324648a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324648afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464467b8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464468d0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 14.084507042253449 31
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 16.90140845070414 39
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 23.23943661971819 50
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 26.760563380281553 58
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 26.760563380281553 75
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 26.760563380281553 83
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246446c88> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464a0da0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3246446518> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 5.63380281690138 14
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 14.084507042253449 32
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 16.90140845070414 40
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 23.23943661971819 51
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 26.760563380281553 59
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 26.760563380281553 76
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 26.760563380281553 84
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464bad30> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 5.63380281690138 15
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 14.084507042253449 33
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 16.90140845070414 41
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 23.23943661971819 52
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 26.760563380281553 60
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 26.760563380281553 77
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 26.760563380281553 85
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba438> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f32464ba240> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 5.63380281690138 16
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 14.084507042253449 34
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 16.90140845070414 42
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 23.23943661971819 53
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 26.760563380281553 61
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 26.760563380281553 78
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 26.760563380281553 86
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246446a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba6d8> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f32464ba438> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f32464ba240> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 4.225352112676035 12
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 5.63380281690138 17
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 14.084507042253449 35
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 16.90140845070414 43
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 23.23943661971819 54
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 26.760563380281553 62
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 26.760563380281553 79
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 26.760563380281553 87
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246446630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246446278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464467b8> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f32464468d0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 5.63380281690138 18
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 14.084507042253449 36
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 16.90140845070414 44
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 23.23943661971819 55
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 26.760563380281553 63
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 26.760563380281553 80
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 26.760563380281553 88
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324645f278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 6.338028169014052 19
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 14.788732394366122 37
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 17.60563380281681 45
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 23.943661971830863 56
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 27.464788732394226 64
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 27.464788732394226 81
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 27.464788732394226 89
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324645f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464fb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 6.338028169014052 20
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 14.788732394366122 38
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 17.60563380281681 46
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 23.943661971830863 57
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 27.464788732394226 65
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 27.464788732394226 82
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 27.464788732394226 90
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464e9a20> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464468d0> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 7.0422535211267245 21
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 15.492957746478794 39
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 18.309859154929484 47
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 24.647887323943536 58
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 28.169014084506898 66
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 28.169014084506898 83
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 28.169014084506898 91
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246546978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464468d0> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 7.0422535211267245 22
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 15.492957746478794 40
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 18.309859154929484 48
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 24.647887323943536 59
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 28.169014084506898 67
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 28.169014084506898 84
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 28.169014084506898 92
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3246522240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324653bf60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 7.746478873239397 23
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 16.197183098591466 41
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 19.014084507042156 49
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 25.35211267605621 60
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 28.87323943661957 68
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 28.87323943661957 85
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 28.87323943661957 93
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324645f5f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324653bf60> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 8.45070422535207 24
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 16.90140845070414 42
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 19.71830985915483 50
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 26.05633802816888 61
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 29.577464788732243 69
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 29.577464788732243 86
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 29.577464788732243 94
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f324645f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f324645f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246522240> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f324653bf60> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 8.45070422535207 25
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 16.90140845070414 43
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 19.71830985915483 51
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 26.05633802816888 62
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 29.577464788732243 70
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 29.577464788732243 87
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 29.577464788732243 95
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->6->19->4->13->7->16
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
coverage_call_count 7900
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324646ac88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324646a8d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464bad30> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 5.63380281690138 14
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 9.154929577464742 26
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 17.60563380281681 44
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 20.4225352112675 52
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 26.760563380281553 63
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 30.281690140844916 71
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 30.281690140844916 88
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 30.281690140844916 96
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f32464729b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246472a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464bad30> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 5.63380281690138 15
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 9.154929577464742 27
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 17.60563380281681 45
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 20.4225352112675 53
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 26.760563380281553 64
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 30.281690140844916 72
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 30.281690140844916 89
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 30.281690140844916 97
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246472f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba550> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f32464ba6d8> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f32464ba438> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f32464ba240> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 5.63380281690138 16
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 9.154929577464742 28
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 17.60563380281681 46
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 20.4225352112675 54
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 26.760563380281553 65
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 30.281690140844916 73
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 30.281690140844916 90
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 30.281690140844916 98
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f32464ba0b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464a00f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324645f278> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 6.338028169014052 17
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 9.859154929577414 29
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 18.309859154929484 47
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 21.126760563380174 55
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 27.464788732394226 66
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 30.985915492957588 74
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 30.985915492957588 91
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 30.985915492957588 99
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->6->19->4->13->7->16->4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324645f2b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324645f898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324645f278> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 7.0422535211267245 18
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 10.563380281690087 30
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 19.014084507042156 48
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 21.830985915492846 56
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 28.169014084506898 67
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 31.69014084507026 75
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 31.69014084507026 92
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 31.69014084507026 100
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324646acf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324646ad30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba0b8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f32464a00f0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f324645f278> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 11.26760563380276 31
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 19.71830985915483 49
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 22.53521126760552 57
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 28.87323943661957 68
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 32.39436619718293 76
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 32.39436619718293 93
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 32.39436619718293 101
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3246472438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3246472908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324645f278> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 8.45070422535207 20
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 11.971830985915432 32
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 20.4225352112675 50
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 23.23943661971819 58
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 29.577464788732243 69
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 33.098591549295605 77
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 33.098591549295605 94
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 33.098591549295605 102
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3246403668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3246403438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f32464ba0b8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f32464a00f0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f324645f278> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 9.154929577464742 21
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 12.676056338028104 33
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 21.126760563380174 51
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 23.943661971830863 59
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 30.281690140844916 70
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 33.80281690140828 78
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 33.80281690140828 95
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 33.80281690140828 103
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3246403f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3246472908> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f324645f278> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 9.154929577464742 22
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 12.676056338028104 34
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 21.126760563380174 52
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 23.943661971830863 60
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 30.281690140844916 71
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 33.80281690140828 79
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 33.80281690140828 96
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 33.80281690140828 104
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324641e0b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324641e080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f324645f2b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f324645f898> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f324645f278> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 9.859154929577414 23
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 13.380281690140777 35
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 21.830985915492846 53
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 24.647887323943536 61
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 30.985915492957588 72
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 34.50704225352095 80
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 34.50704225352095 97
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 34.50704225352095 105
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f324641e748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3246472908> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f324645f278> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f32464ba080> 10.563380281690087 24
backprop <src.mcts.MCTS_Node object at 0x7f32464e2588> 14.084507042253449 36
backprop <src.mcts.MCTS_Node object at 0x7f32464e2be0> 22.53521126760552 54
backprop <src.mcts.MCTS_Node object at 0x7f324653bcf8> 25.35211267605621 62
backprop <src.mcts.MCTS_Node object at 0x7f324651a160> 31.69014084507026 73
backprop <src.mcts.MCTS_Node object at 0x7f324651a128> 35.21126760563362 81
backprop <src.mcts.MCTS_Node object at 0x7f3246562f98> 35.21126760563362 98
backprop <src.mcts.MCTS_Node object at 0x7f3246c1dac8> 35.21126760563362 106
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->6->19->4->13->7->16->4->16
Best Reward: 0.7042253521126725
iteration: 293
found coverage increase 0.7042253521126725
Current Total Coverage 70.4225352112676
initial coverage: 69.0141
time passed (minutes): 60.5724
iterations: 294
number of new inputs: 128
final coverage: 70.4225
total coverage increase: 1.40845
