Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fc42e87bf28>, tc2=<function tc2 at 0x7fc42e88c048>, tc3=<function tc3 at 0x7fc42e88c158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 7.82443
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0879e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0878d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0879e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0870b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0875c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0550f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b11d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0780f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0789e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0780f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0786a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0554a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0646d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0646d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0646d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b390> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 13
Completed Iteration #19
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0642b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07520b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bda0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077db00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077db00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07637f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07634e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bf98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 10
Completed Iteration #15
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b8d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec11a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fab4dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a19b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa40fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa40fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fce44f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fce44f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1be0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1be0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 8
Completed Iteration #9
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07429e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 700
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0789e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0789e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055cf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07421d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07421d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07421d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07526d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 5
Completed Iteration #7
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1198> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 900
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b47290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b47290b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b47290b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0879e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0879e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0879e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec186438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07428d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46817b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46536d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46533c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46538d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec186438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46817f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46817f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b47293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46630b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b47293c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46630b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46630b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 7.8244274809160315
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384feaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384feac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384feaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384feab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4358> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec186438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feab38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 15
Completed Iteration #22
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c9b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c9b0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384feab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f818d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 1300
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f360b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f263c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f261d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f364e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f186a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f186a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee23c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee23c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef63c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 10
Completed Iteration #15
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cf60> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feaa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f182e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f182e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e554a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f182e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e556d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e556d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e629e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e629e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e629e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e627f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 1500
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e627f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb00> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cdd8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e554e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e554e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763940> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e629b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fce44f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b748> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbdd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fab29c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fab29c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fab29c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fab29c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa535f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0785c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1519e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec11a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ada0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec11acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ada0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f181d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa40f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd22e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f184a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09deb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0877f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa49b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0877f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384feadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec124e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729f98> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f261d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f261d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f267f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f269b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb70> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384feab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01db38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46533c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0879b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46534e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46533c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46535c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46535c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec11acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f81860> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e767b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503217f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503218d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503218d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e763c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e763c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e763c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350321c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 5
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 6
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef67f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35030fda0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503046d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 11
Completed Iteration #16
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503046d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502516d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502613c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502610b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502610b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502519b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502619e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502619e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc350279908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502510f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502510f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502610b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350304ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc350304710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d22e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b4a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35022c5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501b70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 12
Completed Iteration #10
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019acf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019acf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019acf8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35019af98> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251940> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502790b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35017e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35017e5f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010e9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6fd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503217f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 6
Completed Iteration #7
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46817b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46817b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681128> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d068fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46817b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fa44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b46815c0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0877f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0877f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec064dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503215f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e8cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350321e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 8
Completed Iteration #6
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fa4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384feaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e76f60> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f18b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384feaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f18940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fea3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf1d0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4681320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 2900
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b7b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e553c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbdd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d072a630> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0752f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a14e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fd48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d077dcc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec09d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35017e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384feac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3fcbd2208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f189b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350321cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bf98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e8c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501c37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501c37f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e62cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e620b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384feae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e620b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35022ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa40f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e55f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e620b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384fd49b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384fea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e76a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e55cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d072af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 7.8244274809160315
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d078b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030fe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3502f14a8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4663f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4653cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d06a1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ef60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35030ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec01d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bbe0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f4cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35023b438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503040b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503045c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503040b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f36668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3faa533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384feadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503040b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503040b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3faa53208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d06ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502516d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350251cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350304438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3503040b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502517f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35022ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3503042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d078bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350304470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46ab978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d071bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec1a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e62ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35010e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f36780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35033be48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f81be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35010e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f26dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec0557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 17
Completed Iteration #17
Best Reward: 0
coverage_call_count 3300
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e53c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e76a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e53c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2a90> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35030f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d077d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350261748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350251a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f81cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3ec10e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3b46abbe0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47290f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502790b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b47292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502790b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502790b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b47292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35033bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec055160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec00d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc384f3b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35017e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc350279470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502793c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35023bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502793c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502793c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3502799e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3502796a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ee2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011de80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6acba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018b588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384ef6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6acba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc34b64ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e9bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f5c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec078b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64ff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6accf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350261898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 3500
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07e63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019afd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384f26320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b47294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b47294e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b47294e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6acf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348baeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba13c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348baef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348baeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348baef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6acf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ba12b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348baed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348baee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bae4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bae4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bae4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d07633c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1630> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348baef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35023bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6acac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35018bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011da58> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b78668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b78048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35019a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b78208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b78a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b78b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b78d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501d28d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b78eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b153c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b153c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b78860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b78390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b78208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b78828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b153c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348b152b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b78cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35033bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b667f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d067b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348baee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348baed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b155f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b66a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b4729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3502a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b78400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b23828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b23a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b23c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b23898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b23860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b23eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3d0742358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b78dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b23e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc35011d518> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b23278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b23ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aeaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad65c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d0763dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d072ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b47294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc350279320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348baef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b78a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aeae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aff518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aff9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348affd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348affd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348affb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348affe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aff9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b78a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b665f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348affeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348affbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b15b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4d30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b6accf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5eda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5eda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0630> 0.0 25
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b78a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35019afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348affe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348affe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aeabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348affe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4470> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3501b7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b780b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc384e766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec03b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a12400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348bc1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b66fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348afff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a12748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc348aea6a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a122b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a12c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b23cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bc15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a12ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a120b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a122b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a120b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a120b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a37278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a270b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a122b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a12f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a122b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a37860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a120b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a37a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a37908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3d07d1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b65a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ba1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35018bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a12f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a12710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a12198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a12748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3501b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3b46f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a37f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a37c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348bae278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc34b64fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a27550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a27e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a37748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a37240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeadd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12550> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348affbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348affdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348b23f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348affbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a373c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348affb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a373c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348affdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a37438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 14
Completed Iteration #21
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348affb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a12eb8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc312588320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312588128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312588128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc312588208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc312588588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc312588cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc312588f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125889e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312588668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312588b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125883c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc312588128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125884e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312588b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc312588ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f79b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb860> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3b46d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348baef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3ec151550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a37630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a37470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b15f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348ab05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348affe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125eb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a37630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a37860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc35011d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312588ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a37b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a129b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a370b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ad6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125f72b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348aeabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312598320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc312598b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312598320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc312598d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aa4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc312598b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312598940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312598320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125bf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125f7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348b66eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312598978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348ab0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348aeaf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312598208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125bf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312598320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc312598ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312598320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc348a4e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc348a5e438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc3125bf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc3125bf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc312598b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc312598320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc348a5ed68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 7.8244274809160315
initial coverage: 7.82443
time passed (minutes): 60.2921
iterations: 159
number of new inputs: 0
final coverage: 7.82443
total coverage increase: 0
