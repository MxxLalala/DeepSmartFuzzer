Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, kmn_k=10000, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'kmn'], random_seed=2, runner='mcts', save_batch=False, skip_layers=[0, 5], tc1=<function tc1 at 0x7f5bc5dc4f28>, tc2=<function tc2 at 0x7f5bc5dd6048>, tc3=<function tc3 at 0x7f5bc5dd6158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 39.5706
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.04450704225352098
backprop <src.mcts.MCTS_Node object at 0x7f5af17945c0> 0.04450704225352098 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17943c8> 0.04450704225352098 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 0.04450704225352098 2
Completed Iteration #0
Best Reward: 0.04450704225352098
Completed Iteration #1
Best Reward: 0.04450704225352098
Reward: 0.12225352112675836
backprop <src.mcts.MCTS_Node object at 0x7f5af17946a0> 0.12225352112675836 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794860> 0.12225352112675836 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 0.16676056338027934 3
Completed Iteration #2
Best Reward: 0.12225352112675836
Reward: 0.11605633802817295
backprop <src.mcts.MCTS_Node object at 0x7f5af1794a58> 0.11605633802817295 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794b38> 0.11605633802817295 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 0.2828169014084523 4
Completed Iteration #3
Best Reward: 0.12225352112675836
Completed Iteration #4
Best Reward: 0.12225352112675836
Reward: 0.10316901408450718
backprop <src.mcts.MCTS_Node object at 0x7f5af1794dd8> 0.10316901408450718 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794d30> 0.10316901408450718 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 0.38598591549295946 5
Completed Iteration #5
Best Reward: 0.12225352112675836
Reward: 0.11859154929577898
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba3c8> 0.11859154929577898 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba198> 0.11859154929577898 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 0.5045774647887384 6
Completed Iteration #6
Best Reward: 0.12225352112675836
Reward: 0.12007042253521405
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba400> 0.12007042253521405 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794860> 0.2423239436619724 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 0.6246478873239525 7
Completed Iteration #7
Best Reward: 0.12225352112675836
Reward: 0.04352112676056663
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba748> 0.04352112676056663 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17943c8> 0.08802816901408761 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 0.6681690140845191 8
Completed Iteration #8
Best Reward: 0.12225352112675836
Reward: 0.09894366197183047
backprop <src.mcts.MCTS_Node object at 0x7f5af17bab00> 0.09894366197183047 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba898> 0.09894366197183047 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 0.7671126760563496 9
Completed Iteration #9
Best Reward: 0.12225352112675836
Reward: 0.04542253521127293
backprop <src.mcts.MCTS_Node object at 0x7f5af17babe0> 0.04542253521127293 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17943c8> 0.13345070422536054 4
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 0.8125352112676225 10
Completed Iteration #10
Best Reward: 0.12225352112675836
Reward: 0.11443661971831176
backprop <src.mcts.MCTS_Node object at 0x7f5af17bafd0> 0.11443661971831176 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17badd8> 0.11443661971831176 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba3c8> 0.23302816901409074 3
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba198> 0.23302816901409074 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 0.9269718309859343 11
Completed Iteration #11
Best Reward: 0.12225352112675836
Reward: 0.11612676056338245
backprop <src.mcts.MCTS_Node object at 0x7f5af17430f0> 0.11612676056338245 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba198> 0.3491549295774732 4
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 1.0430985915493167 12
Completed Iteration #12
Best Reward: 0.12225352112675836
Reward: 0.11676056338028218
backprop <src.mcts.MCTS_Node object at 0x7f5af17433c8> 0.11676056338028218 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba198> 0.46591549295775536 5
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 1.159859154929599 13
Completed Iteration #13
Best Reward: 0.12225352112675836
Reward: 0.1171126760563368
backprop <src.mcts.MCTS_Node object at 0x7f5af17435f8> 0.1171126760563368 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794b38> 0.23316901408450974 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 1.2769718309859357 14
Completed Iteration #14
Best Reward: 0.12225352112675836
Reward: 0.08091549295774314
backprop <src.mcts.MCTS_Node object at 0x7f5af1743828> 0.08091549295774314 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794b38> 0.3140845070422529 4
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 1.3578873239436788 15
Completed Iteration #15
Best Reward: 0.12225352112675836
Reward: 0.09359154929577329
backprop <src.mcts.MCTS_Node object at 0x7f5af1743a90> 0.09359154929577329 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba898> 0.19253521126760376 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 1.4514788732394521 16
Completed Iteration #16
Best Reward: 0.12225352112675836
Completed Iteration #17
Best Reward: 0.12225352112675836
Completed Iteration #18
Best Reward: 0.12225352112675836
Reward: 0.11746478873239852
backprop <src.mcts.MCTS_Node object at 0x7f5af1743ef0> 0.11746478873239852 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794d30> 0.2206338028169057 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 1.5689436619718506 17
Completed Iteration #19
Best Reward: 0.12225352112675836
Reward: 0.11112676056337989
backprop <src.mcts.MCTS_Node object at 0x7f5af1772160> 0.11112676056337989 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794668> 0.11112676056337989 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 1.6800704225352305 18
Completed Iteration #20
Best Reward: 0.12225352112675836
Completed Iteration #21
Best Reward: 0.12225352112675836
Reward: 0.09295774647887356
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 0.09295774647887356 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba898> 0.2854929577464773 4
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 1.773028169014104 19
Completed Iteration #22
Best Reward: 0.12225352112675836
Reward: 0.11457746478873787
backprop <src.mcts.MCTS_Node object at 0x7f5b481854a8> 0.11457746478873787 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794d30> 0.33521126760564357 4
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 1.887605633802842 20
Completed Iteration #23
Best Reward: 0.12225352112675836
Completed Iteration #24
Best Reward: 0.12225352112675836
Reward: 0.08169014084506898
backprop <src.mcts.MCTS_Node object at 0x7f5af1794390> 0.08169014084506898 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794b38> 0.39577464788732186 5
backprop <src.mcts.MCTS_Node object at 0x7f5b481859b0> 1.969295774647911 21
Completed Iteration #25
Best Reward: 0.12225352112675836
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12225352112675836
No reward increase. Abort.
iteration: 0
found coverage increase 0.12225352112675836
Current Total Coverage 39.69288732394366
Reward: 0.12964788732394794
backprop <src.mcts.MCTS_Node object at 0x7f5af1794c18> 0.12964788732394794 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794588> 0.12964788732394794 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 0.12964788732394794 2
Completed Iteration #0
Best Reward: 0.12964788732394794
Completed Iteration #1
Best Reward: 0.12964788732394794
Completed Iteration #2
Best Reward: 0.12964788732394794
Reward: 0.12739436619718703
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba470> 0.12739436619718703 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba940> 0.12739436619718703 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 0.25704225352113497 3
Completed Iteration #3
Best Reward: 0.12964788732394794
Reward: 0.09929577464789219
backprop <src.mcts.MCTS_Node object at 0x7f5af17baa90> 0.09929577464789219 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17baef0> 0.09929577464789219 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 0.35633802816902715 4
Completed Iteration #4
Best Reward: 0.12964788732394794
Completed Iteration #5
Best Reward: 0.12964788732394794
Reward: 0.04669014084507239
backprop <src.mcts.MCTS_Node object at 0x7f5af17432e8> 0.04669014084507239 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743668> 0.04669014084507239 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 0.40302816901409955 5
Completed Iteration #6
Best Reward: 0.12964788732394794
Reward: 0.12260563380282008
backprop <src.mcts.MCTS_Node object at 0x7f5af1743320> 0.12260563380282008 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17baeb8> 0.12260563380282008 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 0.5256338028169196 6
Completed Iteration #7
Best Reward: 0.12964788732394794
Reward: 0.12570422535211634
backprop <src.mcts.MCTS_Node object at 0x7f5af1743ac8> 0.12570422535211634 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba358> 0.12570422535211634 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 0.651338028169036 7
Completed Iteration #8
Best Reward: 0.12964788732394794
Reward: 0.13795774647887526
backprop <src.mcts.MCTS_Node object at 0x7f5af1743c18> 0.13795774647887526 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743668> 0.18464788732394766 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 0.7892957746479112 8
Completed Iteration #9
Best Reward: 0.13795774647887526
Completed Iteration #10
Best Reward: 0.13795774647887526
Completed Iteration #11
Best Reward: 0.13795774647887526
Completed Iteration #12
Best Reward: 0.13795774647887526
Reward: 0.12570422535211634
backprop <src.mcts.MCTS_Node object at 0x7f5af17723c8> 0.12570422535211634 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba358> 0.2514084507042327 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 0.9150000000000276 9
Completed Iteration #13
Best Reward: 0.13795774647887526
Reward: 0.12626760563380657
backprop <src.mcts.MCTS_Node object at 0x7f5af1772710> 0.12626760563380657 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17baef0> 0.22556338028169876 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 1.0412676056338341 10
Completed Iteration #14
Best Reward: 0.13795774647887526
Completed Iteration #15
Best Reward: 0.13795774647887526
Reward: 0.07542253521127407
backprop <src.mcts.MCTS_Node object at 0x7f5af1772d68> 0.07542253521127407 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17729e8> 0.07542253521127407 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 1.1166901408451082 11
Completed Iteration #16
Best Reward: 0.13795774647887526
Completed Iteration #17
Best Reward: 0.13795774647887526
Reward: 0.12183098591549424
backprop <src.mcts.MCTS_Node object at 0x7f5af1772b70> 0.12183098591549424 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794588> 0.2514788732394422 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 1.2385211267606024 12
Completed Iteration #18
Best Reward: 0.13795774647887526
Completed Iteration #19
Best Reward: 0.13795774647887526
Reward: 0.12725352112676802
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990160> 0.12725352112676802 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba358> 0.3786619718310007 4
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 1.3657746478873705 13
Completed Iteration #20
Best Reward: 0.13795774647887526
Completed Iteration #21
Best Reward: 0.13795774647887526
Completed Iteration #22
Best Reward: 0.13795774647887526
Reward: 0.07295774647887754
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990898> 0.07295774647887754 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17729e8> 0.1483802816901516 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 1.438732394366248 14
Completed Iteration #23
Best Reward: 0.13795774647887526
Reward: 0.04387323943662125
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990a90> 0.04387323943662125 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743668> 0.2285211267605689 4
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 1.4826056338028692 15
Completed Iteration #24
Best Reward: 0.13795774647887526
Reward: 0.10014084507042753
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990d68> 0.10014084507042753 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17baef0> 0.3257042253521263 4
backprop <src.mcts.MCTS_Node object at 0x7f5af1794cc0> 1.5827464788732968 16
Completed Iteration #25
Best Reward: 0.13795774647887526
Completed MCTS Level/Depth: #0
root
Best Reward: 0.13795774647887526
No reward increase. Abort.
iteration: 1
found coverage increase 0.13795774647887526
Current Total Coverage 39.830845070422534
Completed Iteration #0
Best Reward: 0
Reward: 0.11661971830986317
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f2b0> 0.11661971830986317 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f128> 0.11661971830986317 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 0.11661971830986317 2
Completed Iteration #1
Best Reward: 0.11661971830986317
Reward: 0.09647887323944104
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f518> 0.09647887323944104 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f128> 0.21309859154930422 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 0.21309859154930422 3
Completed Iteration #2
Best Reward: 0.11661971830986317
Completed Iteration #3
Best Reward: 0.11661971830986317
Completed Iteration #4
Best Reward: 0.11661971830986317
Reward: 0.1151408450704281
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fba8> 0.1151408450704281 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f780> 0.1151408450704281 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 0.3282394366197323 4
Completed Iteration #5
Best Reward: 0.11661971830986317
Reward: 0.06774647887323937
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fb00> 0.06774647887323937 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fcf8> 0.06774647887323937 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 0.3959859154929717 5
Completed Iteration #6
Best Reward: 0.11661971830986317
Completed Iteration #7
Best Reward: 0.11661971830986317
Completed Iteration #8
Best Reward: 0.11661971830986317
Completed Iteration #9
Best Reward: 0.11661971830986317
Completed Iteration #10
Best Reward: 0.11661971830986317
Reward: 0.11507042253521149
backprop <src.mcts.MCTS_Node object at 0x7f5af1794e48> 0.11507042253521149 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794be0> 0.11507042253521149 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 0.5110563380281832 6
Completed Iteration #11
Best Reward: 0.11661971830986317
Reward: 0.11415492957746665
backprop <src.mcts.MCTS_Node object at 0x7f5af17bacc0> 0.11415492957746665 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f128> 0.32725352112677086 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 0.6252112676056498 7
Completed Iteration #12
Best Reward: 0.11661971830986317
Completed Iteration #13
Best Reward: 0.11661971830986317
Completed Iteration #14
Best Reward: 0.11661971830986317
Reward: 0.11373239436620253
backprop <src.mcts.MCTS_Node object at 0x7f5af1743400> 0.11373239436620253 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f780> 0.22887323943663063 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 0.7389436619718524 8
Completed Iteration #15
Best Reward: 0.11661971830986317
Completed Iteration #16
Best Reward: 0.11661971830986317
Completed Iteration #17
Best Reward: 0.11661971830986317
Reward: 0.09471830985916085
backprop <src.mcts.MCTS_Node object at 0x7f5af17720b8> 0.09471830985916085 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f128> 0.4219718309859317 5
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 0.8336619718310132 9
Completed Iteration #18
Best Reward: 0.11661971830986317
Reward: 0.1171830985915463
backprop <src.mcts.MCTS_Node object at 0x7f5af1772eb8> 0.1171830985915463 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990fd0> 0.1171830985915463 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 0.9508450704225595 10
Completed Iteration #19
Best Reward: 0.1171830985915463
Reward: 0.11894366197183359
backprop <src.mcts.MCTS_Node object at 0x7f5af1772cf8> 0.11894366197183359 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990fd0> 0.2361267605633799 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 1.069788732394393 11
Completed Iteration #20
Best Reward: 0.11894366197183359
Reward: 0.045704225352118044
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990390> 0.045704225352118044 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990978> 0.045704225352118044 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 1.1154929577465111 12
Completed Iteration #21
Best Reward: 0.11894366197183359
Completed Iteration #22
Best Reward: 0.11894366197183359
Reward: 0.11359154929577642
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990a58> 0.11359154929577642 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794be0> 0.2286619718309879 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 1.2290845070422876 13
Completed Iteration #23
Best Reward: 0.11894366197183359
Reward: 0.06774647887323937
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f198> 0.06774647887323937 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fcf8> 0.13549295774647874 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 1.296830985915527 14
Completed Iteration #24
Best Reward: 0.11894366197183359
Completed Iteration #25
Best Reward: 0.11894366197183359
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11894366197183359
No reward increase. Abort.
iteration: 2
found coverage increase 0.11894366197183359
Current Total Coverage 39.94978873239437
Reward: 0.06619718309858769
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fb70> 0.06619718309858769 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399ffd0> 0.06619718309858769 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 0.06619718309858769 2
Completed Iteration #0
Best Reward: 0.06619718309858769
Reward: 0.11366197183098592
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2128> 0.11366197183098592 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fcc0> 0.11366197183098592 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 0.1798591549295736 3
Completed Iteration #1
Best Reward: 0.11366197183098592
Reward: 0.12070422535211378
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b22b0> 0.12070422535211378 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b23c8> 0.12070422535211378 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 0.3005633802816874 4
Completed Iteration #2
Best Reward: 0.12070422535211378
Reward: 0.11577464788732073
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b25f8> 0.11577464788732073 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b23c8> 0.2364788732394345 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 0.4163380281690081 5
Completed Iteration #3
Best Reward: 0.12070422535211378
Reward: 0.12042253521126156
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2828> 0.12042253521126156 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399ffd0> 0.18661971830984925 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 0.5367605633802697 6
Completed Iteration #4
Best Reward: 0.12070422535211378
Completed Iteration #5
Best Reward: 0.12070422535211378
Reward: 0.03809859154929285
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2dd8> 0.03809859154929285 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b29b0> 0.03809859154929285 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 0.5748591549295625 7
Completed Iteration #6
Best Reward: 0.12070422535211378
Completed Iteration #7
Best Reward: 0.12070422535211378
Reward: 0.09154929577464799
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df2e8> 0.09154929577464799 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2b70> 0.09154929577464799 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 0.6664084507042105 8
Completed Iteration #8
Best Reward: 0.12070422535211378
Completed Iteration #9
Best Reward: 0.12070422535211378
Reward: 0.03774647887323823
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df588> 0.03774647887323823 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b29b0> 0.07584507042253108 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 0.7041549295774487 9
Completed Iteration #10
Best Reward: 0.12070422535211378
Reward: 0.12204225352112275
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df5f8> 0.12204225352112275 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2c50> 0.12204225352112275 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 0.8261971830985715 10
Completed Iteration #11
Best Reward: 0.12204225352112275
Reward: 0.11478873239436638
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df898> 0.11478873239436638 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df780> 0.11478873239436638 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 0.9409859154929379 11
Completed Iteration #12
Best Reward: 0.12204225352112275
Reward: 0.10802816901408363
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfc18> 0.10802816901408363 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b23c8> 0.34450704225351814 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 1.0490140845070215 12
Completed Iteration #13
Best Reward: 0.12204225352112275
Reward: 0.06971830985915517
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfe48> 0.06971830985915517 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df780> 0.18450704225352155 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 1.1187323943661767 13
Completed Iteration #14
Best Reward: 0.12204225352112275
Reward: 0.1113380281690155
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfb70> 0.1113380281690155 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fcc0> 0.22500000000000142 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 1.2300704225351922 14
Completed Iteration #15
Best Reward: 0.12204225352112275
Completed Iteration #16
Best Reward: 0.12204225352112275
coverage_call_count 100
Completed Iteration #17
Best Reward: 0.12204225352112275
Completed Iteration #18
Best Reward: 0.12204225352112275
Completed Iteration #19
Best Reward: 0.12204225352112275
Completed Iteration #20
Best Reward: 0.12204225352112275
Reward: 0.11936619718309771
backprop <src.mcts.MCTS_Node object at 0x7f5af1794240> 0.11936619718309771 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fcc0> 0.34436619718309913 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 1.3494366197182899 15
Completed Iteration #21
Best Reward: 0.12204225352112275
Reward: 0.08640845070422642
backprop <src.mcts.MCTS_Node object at 0x7f5af17430b8> 0.08640845070422642 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885400> 0.08640845070422642 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 1.4358450704225163 16
Completed Iteration #22
Best Reward: 0.12204225352112275
Reward: 0.10697183098591978
backprop <src.mcts.MCTS_Node object at 0x7f5af1743ba8> 0.10697183098591978 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fcc0> 0.4513380281690189 5
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 1.542816901408436 17
Completed Iteration #23
Best Reward: 0.12204225352112275
Completed Iteration #24
Best Reward: 0.12204225352112275
Reward: 0.11781690140844603
backprop <src.mcts.MCTS_Node object at 0x7f5af1772a58> 0.11781690140844603 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b23c8> 0.46232394366196417 5
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 1.660633802816882 18
Completed Iteration #25
Best Reward: 0.12204225352112275
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12204225352112275
No reward increase. Abort.
iteration: 3
found coverage increase 0.12204225352112275
Current Total Coverage 40.07183098591549
Reward: 0.043028169014085904
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990ef0> 0.043028169014085904 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990a20> 0.043028169014085904 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 0.043028169014085904 2
Completed Iteration #0
Best Reward: 0.043028169014085904
Reward: 0.1172535211267629
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f6a0> 0.1172535211267629 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f400> 0.1172535211267629 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 0.1602816901408488 3
Completed Iteration #1
Best Reward: 0.1172535211267629
Completed Iteration #2
Best Reward: 0.1172535211267629
Reward: 0.111126760563387
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2630> 0.111126760563387 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2160> 0.111126760563387 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 0.2714084507042358 4
Completed Iteration #3
Best Reward: 0.1172535211267629
Reward: 0.0409154929577511
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2a20> 0.0409154929577511 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990a20> 0.083943661971837 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 0.3123239436619869 5
Completed Iteration #4
Best Reward: 0.1172535211267629
Completed Iteration #5
Best Reward: 0.1172535211267629
Reward: 0.11964788732394993
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df320> 0.11964788732394993 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990a20> 0.20359154929578693 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 0.43197183098593683 6
Completed Iteration #6
Best Reward: 0.11964788732394993
Reward: 0.11218309859155084
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df710> 0.11218309859155084 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df7f0> 0.11218309859155084 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 0.5441549295774877 7
Completed Iteration #7
Best Reward: 0.11964788732394993
Reward: 0.04591549295774655
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df978> 0.04591549295774655 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990a20> 0.24950704225353348 5
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 0.5900704225352342 8
Completed Iteration #8
Best Reward: 0.11964788732394993
Reward: 0.09485915492957986
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfda0> 0.09485915492957986 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fa58> 0.09485915492957986 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 0.6849295774648141 9
Completed Iteration #9
Best Reward: 0.11964788732394993
Completed Iteration #10
Best Reward: 0.11964788732394993
Completed Iteration #11
Best Reward: 0.11964788732394993
Reward: 0.12063380281690428
backprop <src.mcts.MCTS_Node object at 0x7f5ae38852e8> 0.12063380281690428 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990a20> 0.37014084507043776 6
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 0.8055633802817184 10
Completed Iteration #12
Best Reward: 0.12063380281690428
Reward: 0.11246478873239596
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885cf8> 0.11246478873239596 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885c18> 0.11246478873239596 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 0.9180281690141143 11
Completed Iteration #13
Best Reward: 0.12063380281690428
Completed Iteration #14
Best Reward: 0.12063380281690428
Reward: 0.043943661971837855
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c0b8> 0.043943661971837855 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990a20> 0.4140845070422756 7
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 0.9619718309859522 12
Completed Iteration #15
Best Reward: 0.12063380281690428
Reward: 0.09626760563380543
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c470> 0.09626760563380543 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fa58> 0.1911267605633853 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 1.0582394366197576 13
Completed Iteration #16
Best Reward: 0.12063380281690428
Completed Iteration #17
Best Reward: 0.12063380281690428
Reward: 0.11169014084507012
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c4a8> 0.11169014084507012 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df7f0> 0.22387323943662096 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 1.1699295774648277 14
Completed Iteration #18
Best Reward: 0.12063380281690428
Reward: 0.11274647887324107
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c828> 0.11274647887324107 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885f98> 0.11274647887324107 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 1.2826760563380688 15
Completed Iteration #19
Best Reward: 0.12063380281690428
Reward: 0.09401408450704452
backprop <src.mcts.MCTS_Node object at 0x7f5ae385ca58> 0.09401408450704452 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885080> 0.09401408450704452 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 1.3766901408451133 16
Completed Iteration #20
Best Reward: 0.12063380281690428
Reward: 0.11267605633803157
backprop <src.mcts.MCTS_Node object at 0x7f5ae385cc88> 0.11267605633803157 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fa58> 0.30380281690141686 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 1.489366197183145 17
Completed Iteration #21
Best Reward: 0.12063380281690428
Completed Iteration #22
Best Reward: 0.12063380281690428
Reward: 0.1230281690140913
backprop <src.mcts.MCTS_Node object at 0x7f5ae385cbe0> 0.1230281690140913 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990a20> 0.5371126760563669 8
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990080> 1.6123943661972362 18
Completed Iteration #23
Best Reward: 0.1230281690140913
Completed Iteration #24
Best Reward: 0.1230281690140913
Completed Iteration #25
Best Reward: 0.1230281690140913
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1230281690140913
No reward increase. Abort.
iteration: 4
found coverage increase 0.1230281690140913
Current Total Coverage 40.19485915492958
Reward: 0.12359154929576732
backprop <src.mcts.MCTS_Node object at 0x7f5ae38615f8> 0.12359154929576732 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861748> 0.12359154929576732 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.12359154929576732 2
Completed Iteration #0
Best Reward: 0.12359154929576732
Completed Iteration #1
Best Reward: 0.12359154929576732
Reward: 0.06373239436619116
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861d30> 0.06373239436619116 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861908> 0.06373239436619116 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.18732394366195848 3
Completed Iteration #2
Best Reward: 0.12359154929576732
Reward: 0.11288732394366008
backprop <src.mcts.MCTS_Node object at 0x7f5af1743710> 0.11288732394366008 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861748> 0.2364788732394274 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.30021126760561856 4
Completed Iteration #3
Best Reward: 0.12359154929576732
Reward: 0.12549295774647362
backprop <src.mcts.MCTS_Node object at 0x7f5af17baf60> 0.12549295774647362 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba2e8> 0.12549295774647362 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.4257042253520922 5
Completed Iteration #4
Best Reward: 0.12549295774647362
Reward: 0.07908450704224634
backprop <src.mcts.MCTS_Node object at 0x7f5ae39904a8> 0.07908450704224634 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772940> 0.07908450704224634 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.5047887323943385 6
Completed Iteration #5
Best Reward: 0.12549295774647362
Reward: 0.0956338028168986
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fef0> 0.0956338028168986 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba2e8> 0.22112676056337222 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.6004225352112371 7
Completed Iteration #6
Best Reward: 0.12549295774647362
Reward: 0.06176056338028246
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2908> 0.06176056338028246 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861908> 0.12549295774647362 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.6621830985915196 8
Completed Iteration #7
Best Reward: 0.12549295774647362
Completed Iteration #8
Best Reward: 0.12549295774647362
Reward: 0.045281690140839714
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfd68> 0.045281690140839714 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df128> 0.045281690140839714 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.7074647887323593 9
Completed Iteration #9
Best Reward: 0.12549295774647362
Reward: 0.0861267605633742
backprop <src.mcts.MCTS_Node object at 0x7f5ae38855f8> 0.0861267605633742 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df7b8> 0.0861267605633742 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.7935915492957335 10
Completed Iteration #10
Best Reward: 0.12549295774647362
Completed Iteration #11
Best Reward: 0.12549295774647362
Reward: 0.1211971830985874
backprop <src.mcts.MCTS_Node object at 0x7f5ae38855c0> 0.1211971830985874 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba2e8> 0.3423239436619596 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.9147887323943209 11
Completed Iteration #12
Best Reward: 0.12549295774647362
Reward: 0.11063380281689916
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c080> 0.11063380281689916 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df550> 0.11063380281689916 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 1.02542253521122 12
Completed Iteration #13
Best Reward: 0.12549295774647362
Reward: 0.11507042253520439
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c4e0> 0.11507042253520439 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c550> 0.11507042253520439 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 1.1404929577464245 13
Completed Iteration #14
Best Reward: 0.12549295774647362
Reward: 0.04676056338027479
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c780> 0.04676056338027479 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df128> 0.0920422535211145 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 1.1872535211266992 14
Completed Iteration #15
Best Reward: 0.12549295774647362
Reward: 0.11492957746478538
backprop <src.mcts.MCTS_Node object at 0x7f5ae385ccc0> 0.11492957746478538 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772940> 0.19401408450703173 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 1.3021830985914846 15
Completed Iteration #16
Best Reward: 0.12549295774647362
Reward: 0.10880281690140237
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614e0> 0.10880281690140237 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df550> 0.21943661971830153 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 1.410985915492887 16
Completed Iteration #17
Best Reward: 0.12549295774647362
Completed Iteration #18
Best Reward: 0.12549295774647362
Reward: 0.11746478873239141
backprop <src.mcts.MCTS_Node object at 0x7f5ae38613c8> 0.11746478873239141 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861748> 0.3539436619718188 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 1.5284507042252784 17
Completed Iteration #19
Best Reward: 0.12549295774647362
Reward: 0.11985915492957133
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861eb8> 0.11985915492957133 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861748> 0.47380281690139014 5
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 1.6483098591548497 18
Completed Iteration #20
Best Reward: 0.12549295774647362
Reward: 0.11739436619718191
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d90f0> 0.11739436619718191 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861748> 0.591197183098572 6
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 1.7657042253520316 19
Completed Iteration #21
Best Reward: 0.12549295774647362
Reward: 0.11809859154929114
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9320> 0.11809859154929114 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df7b8> 0.20422535211266535 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 1.8838028169013228 20
Completed Iteration #22
Best Reward: 0.12549295774647362
Reward: 0.08035211267605291
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9550> 0.08035211267605291 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772940> 0.27436619718308464 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 1.9641549295773757 21
Completed Iteration #23
Best Reward: 0.12549295774647362
Reward: 0.11556338028168511
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d97b8> 0.11556338028168511 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c550> 0.2306338028168895 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 2.079718309859061 22
Completed Iteration #24
Best Reward: 0.12549295774647362
Reward: 0.12169014084506102
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9978> 0.12169014084506102 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861748> 0.7128873239436331 7
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 2.201408450704122 23
Completed Iteration #25
Best Reward: 0.12549295774647362
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12549295774647362
No reward increase. Abort.
iteration: 5
found coverage increase 0.12549295774647362
Current Total Coverage 40.320352112676055
Reward: 0.05894366197183132
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9e48> 0.05894366197183132 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9e10> 0.05894366197183132 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 0.05894366197183132 2
Completed Iteration #0
Best Reward: 0.05894366197183132
Completed Iteration #1
Best Reward: 0.05894366197183132
Reward: 0.09098591549295776
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b438> 0.09098591549295776 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b0f0> 0.09098591549295776 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 0.14992957746478908 3
Completed Iteration #2
Best Reward: 0.09098591549295776
Completed Iteration #3
Best Reward: 0.09098591549295776
Reward: 0.11084507042254188
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b748> 0.11084507042254188 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b0f0> 0.20183098591549964 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 0.26077464788733096 4
Completed Iteration #4
Best Reward: 0.11084507042254188
Reward: 0.07711267605633765
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b940> 0.07711267605633765 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b898> 0.07711267605633765 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 0.3378873239436686 5
Completed Iteration #5
Best Reward: 0.11084507042254188
Completed Iteration #6
Best Reward: 0.11084507042254188
Reward: 0.06704225352113014
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fb38> 0.06704225352113014 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdb70> 0.06704225352113014 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 0.40492957746479874 6
Completed Iteration #7
Best Reward: 0.11084507042254188
Reward: 0.08436619718310112
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990400> 0.08436619718310112 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b0f0> 0.28619718309860076 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 0.48929577464789986 7
Completed Iteration #8
Best Reward: 0.11084507042254188
Reward: 0.055140845070425826
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885588> 0.055140845070425826 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9e10> 0.11408450704225714 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 0.5444366197183257 8
Completed Iteration #9
Best Reward: 0.11084507042254188
Reward: 0.05345070422535514
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfb00> 0.05345070422535514 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9e10> 0.16753521126761228 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 0.5978873239436808 9
Completed Iteration #10
Best Reward: 0.11084507042254188
Reward: 0.11239436619718646
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885828> 0.11239436619718646 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b898> 0.1895070422535241 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 0.7102816901408673 10
Completed Iteration #11
Best Reward: 0.11239436619718646
Reward: 0.11739436619718191
backprop <src.mcts.MCTS_Node object at 0x7f5af1743518> 0.11739436619718191 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b2b0> 0.11739436619718191 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 0.8276760563380492 11
Completed Iteration #12
Best Reward: 0.11739436619718191
Completed Iteration #13
Best Reward: 0.11739436619718191
Reward: 0.1133098591549313
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c748> 0.1133098591549313 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c860> 0.1133098591549313 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 0.9409859154929805 12
Completed Iteration #14
Best Reward: 0.11739436619718191
Completed Iteration #15
Best Reward: 0.11739436619718191
Completed Iteration #16
Best Reward: 0.11739436619718191
Reward: 0.09070422535211264
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9160> 0.09070422535211264 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861ba8> 0.09070422535211264 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 1.0316901408450931 13
Completed Iteration #17
Best Reward: 0.11739436619718191
Completed Iteration #18
Best Reward: 0.11739436619718191
Completed Iteration #19
Best Reward: 0.11739436619718191
Completed Iteration #20
Best Reward: 0.11739436619718191
Completed Iteration #21
Best Reward: 0.11739436619718191
Reward: 0.11112676056337989
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d98d0> 0.11112676056337989 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9f60> 0.11112676056337989 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 1.142816901408473 14
Completed Iteration #22
Best Reward: 0.11739436619718191
Reward: 0.070352112676062
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b198> 0.070352112676062 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdb70> 0.13739436619719214 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 1.213169014084535 15
Completed Iteration #23
Best Reward: 0.11739436619718191
Reward: 0.11176056338027962
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9d68> 0.11176056338027962 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b0f0> 0.3979577464788804 5
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9cc0> 1.3249295774648147 16
Completed Iteration #24
Best Reward: 0.11739436619718191
Completed Iteration #25
Best Reward: 0.11739436619718191
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11739436619718191
No reward increase. Abort.
iteration: 6
found coverage increase 0.11739436619718191
Current Total Coverage 40.43774647887324
Reward: 0.1190845070422597
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bd68> 0.1190845070422597 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bd30> 0.1190845070422597 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 0.1190845070422597 2
Completed Iteration #0
Best Reward: 0.1190845070422597
Reward: 0.11584507042253733
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b0f0> 0.11584507042253733 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376be80> 0.11584507042253733 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 0.23492957746479703 3
Completed Iteration #1
Best Reward: 0.1190845070422597
Completed Iteration #2
Best Reward: 0.1190845070422597
Completed Iteration #3
Best Reward: 0.1190845070422597
Reward: 0.11950704225352382
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b7b8> 0.11950704225352382 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b588> 0.11950704225352382 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b0f0> 0.23535211267606115 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae376be80> 0.23535211267606115 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 0.35443661971832086 4
Completed Iteration #4
Best Reward: 0.11950704225352382
Reward: 0.03915492957747091
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b9e8> 0.03915492957747091 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b5f8> 0.03915492957747091 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 0.39359154929579176 5
Completed Iteration #5
Best Reward: 0.11950704225352382
Reward: 0.07556338028169307
backprop <src.mcts.MCTS_Node object at 0x7f5ae375bd30> 0.07556338028169307 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375bac8> 0.07556338028169307 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 0.46915492957748484 6
Completed Iteration #6
Best Reward: 0.11950704225352382
Reward: 0.11260563380282207
backprop <src.mcts.MCTS_Node object at 0x7f5ae375bf28> 0.11260563380282207 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b278> 0.11260563380282207 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 0.5817605633803069 7
Completed Iteration #7
Best Reward: 0.11950704225352382
Reward: 0.036760563380283884
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff278> 0.036760563380283884 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b5f8> 0.0759154929577548 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 0.6185211267605908 8
Completed Iteration #8
Best Reward: 0.11950704225352382
Reward: 0.07549295774648357
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff470> 0.07549295774648357 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff2e8> 0.07549295774648357 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 0.6940140845070744 9
Completed Iteration #9
Best Reward: 0.11950704225352382
Reward: 0.11415492957746665
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b9b0> 0.11415492957746665 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376be80> 0.3495070422535278 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 0.808169014084541 10
Completed Iteration #10
Best Reward: 0.11950704225352382
Reward: 0.09077464788732925
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff978> 0.09077464788732925 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bd30> 0.20985915492958895 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 0.8989436619718703 11
Completed Iteration #11
Best Reward: 0.11950704225352382
Reward: 0.11647887323943706
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ffb70> 0.11647887323943706 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff9e8> 0.11647887323943706 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 1.0154225352113073 12
Completed Iteration #12
Best Reward: 0.11950704225352382
coverage_call_count 200
Completed Iteration #13
Best Reward: 0.11950704225352382
Reward: 0.11605633802817295
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ffba8> 0.11605633802817295 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375bac8> 0.19161971830986602 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 1.1314788732394803 13
Completed Iteration #14
Best Reward: 0.11950704225352382
Completed Iteration #15
Best Reward: 0.11950704225352382
Reward: 0.09429577464788963
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990518> 0.09429577464788963 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bd30> 0.3041549295774786 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 1.22577464788737 14
Completed Iteration #16
Best Reward: 0.11950704225352382
Reward: 0.11387323943662153
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2358> 0.11387323943662153 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375bac8> 0.30549295774648755 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 1.3396478873239914 15
Completed Iteration #17
Best Reward: 0.11950704225352382
Completed Iteration #18
Best Reward: 0.11950704225352382
Completed Iteration #19
Best Reward: 0.11950704225352382
Reward: 0.121126760563385
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861390> 0.121126760563385 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b5f8> 0.1970422535211398 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 1.4607746478873764 16
Completed Iteration #20
Best Reward: 0.121126760563385
Reward: 0.03838028169014507
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d92e8> 0.03838028169014507 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b5f8> 0.23542253521128487 5
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 1.4991549295775215 17
Completed Iteration #21
Best Reward: 0.121126760563385
Reward: 0.07795774647887299
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b6a0> 0.07795774647887299 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375bac8> 0.38345070422536054 5
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 1.5771126760563945 18
Completed Iteration #22
Best Reward: 0.121126760563385
Reward: 0.11471830985915688
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c18> 0.11471830985915688 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b390> 0.11471830985915688 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 1.6918309859155514 19
Completed Iteration #23
Best Reward: 0.121126760563385
Reward: 0.11774647887324363
backprop <src.mcts.MCTS_Node object at 0x7f5ae376ba20> 0.11774647887324363 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375bac8> 0.5011971830986042 6
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bb70> 1.809577464788795 20
Completed Iteration #24
Best Reward: 0.121126760563385
Completed Iteration #25
Best Reward: 0.121126760563385
Completed MCTS Level/Depth: #0
root
Best Reward: 0.121126760563385
No reward increase. Abort.
iteration: 7
found coverage increase 0.121126760563385
Current Total Coverage 40.55887323943662
Reward: 0.0918309859154931
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bcc0> 0.0918309859154931 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bfd0> 0.0918309859154931 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 0.0918309859154931 2
Completed Iteration #0
Best Reward: 0.0918309859154931
Reward: 0.05429577464788338
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d96d8> 0.05429577464788338 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b438> 0.05429577464788338 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 0.14612676056337648 3
Completed Iteration #1
Best Reward: 0.0918309859154931
Reward: 0.09478873239436325
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b0f0> 0.09478873239436325 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bfd0> 0.18661971830985635 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 0.24091549295773973 4
Completed Iteration #2
Best Reward: 0.09478873239436325
Completed Iteration #3
Best Reward: 0.09478873239436325
Reward: 0.11035211267605405
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d93c8> 0.11035211267605405 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9ba8> 0.11035211267605405 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 0.3512676056337938 5
Completed Iteration #4
Best Reward: 0.11035211267605405
Reward: 0.10901408450703798
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d95f8> 0.10901408450703798 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9ba8> 0.21936619718309203 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 0.46028169014083176 6
Completed Iteration #5
Best Reward: 0.11035211267605405
Reward: 0.11577464788732073
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861a90> 0.11577464788732073 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9898> 0.11577464788732073 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 0.5760563380281525 7
Completed Iteration #6
Best Reward: 0.11577464788732073
Reward: 0.10992957746478282
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861e80> 0.10992957746478282 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9898> 0.22570422535210355 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 0.6859859154929353 8
Completed Iteration #7
Best Reward: 0.11577464788732073
Reward: 0.1112676056337989
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861860> 0.1112676056337989 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861898> 0.1112676056337989 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 0.7972535211267342 9
Completed Iteration #8
Best Reward: 0.11577464788732073
Completed Iteration #9
Best Reward: 0.11577464788732073
Reward: 0.10478873239436126
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861320> 0.10478873239436126 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861d30> 0.10478873239436126 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 0.9020422535210955 10
Completed Iteration #10
Best Reward: 0.11577464788732073
Reward: 0.06577464788732357
backprop <src.mcts.MCTS_Node object at 0x7f5ae385cac8> 0.06577464788732357 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c518> 0.06577464788732357 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 0.967816901408419 11
Completed Iteration #11
Best Reward: 0.11577464788732073
Reward: 0.06429577464788849
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c978> 0.06429577464788849 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c518> 0.13007042253521206 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 1.0321126760563075 12
Completed Iteration #12
Best Reward: 0.11577464788732073
Reward: 0.10725352112675779
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c8d0> 0.10725352112675779 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9898> 0.33295774647886134 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 1.1393661971830653 13
Completed Iteration #13
Best Reward: 0.11577464788732073
Completed Iteration #14
Best Reward: 0.11577464788732073
Reward: 0.11211267605633424
backprop <src.mcts.MCTS_Node object at 0x7f5ae385cfd0> 0.11211267605633424 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861d30> 0.2169014084506955 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 1.2514788732393995 14
Completed Iteration #15
Best Reward: 0.11577464788732073
Completed Iteration #16
Best Reward: 0.11577464788732073
Reward: 0.1113380281690084
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885940> 0.1113380281690084 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bfd0> 0.29795774647886475 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 1.362816901408408 15
Completed Iteration #17
Best Reward: 0.11577464788732073
Completed Iteration #18
Best Reward: 0.11577464788732073
Reward: 0.11471830985914977
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885ba8> 0.11471830985914977 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885160> 0.11471830985914977 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 1.4775352112675577 16
Completed Iteration #19
Best Reward: 0.11577464788732073
Reward: 0.11274647887323397
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885668> 0.11274647887323397 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9898> 0.4457042253520953 5
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 1.5902816901407917 17
Completed Iteration #20
Best Reward: 0.11577464788732073
Reward: 0.10894366197182848
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885438> 0.10894366197182848 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c518> 0.23901408450704054 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 1.6992253521126202 18
Completed Iteration #21
Best Reward: 0.11577464788732073
Completed Iteration #22
Best Reward: 0.11577464788732073
Reward: 0.11302816901408619
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b5f8> 0.11302816901408619 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861898> 0.22429577464788508 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 1.8122535211267063 19
Completed Iteration #23
Best Reward: 0.11577464788732073
Reward: 0.08971830985915119
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b908> 0.08971830985915119 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bfd0> 0.38767605633801594 5
backprop <src.mcts.MCTS_Node object at 0x7f5ae376bc88> 1.9019718309858575 20
Completed Iteration #24
Best Reward: 0.11577464788732073
Completed Iteration #25
Best Reward: 0.11577464788732073
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11577464788732073
No reward increase. Abort.
iteration: 8
found coverage increase 0.11577464788732073
Current Total Coverage 40.67464788732394
Reward: 0.12176056338028474
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9be0> 0.12176056338028474 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9ac8> 0.12176056338028474 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 0.12176056338028474 2
Completed Iteration #0
Best Reward: 0.12176056338028474
Reward: 0.08253521126760432
backprop <src.mcts.MCTS_Node object at 0x7f5ae38612e8> 0.08253521126760432 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9b70> 0.08253521126760432 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 0.20429577464788906 3
Completed Iteration #1
Best Reward: 0.12176056338028474
Completed Iteration #2
Best Reward: 0.12176056338028474
Reward: 0.0428873239436669
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861588> 0.0428873239436669 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9ac8> 0.16464788732395164 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 0.24718309859155596 4
Completed Iteration #3
Best Reward: 0.12176056338028474
Reward: 0.11345070422535031
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861f98> 0.11345070422535031 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861550> 0.11345070422535031 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 0.36063380281690627 5
Completed Iteration #4
Best Reward: 0.12176056338028474
Reward: 0.0821126760563402
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c908> 0.0821126760563402 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9b70> 0.16464788732394453 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 0.4427464788732465 6
Completed Iteration #5
Best Reward: 0.12176056338028474
Reward: 0.06570422535211407
backprop <src.mcts.MCTS_Node object at 0x7f5ae385cbe0> 0.06570422535211407 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c080> 0.06570422535211407 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 0.5084507042253605 7
Completed Iteration #6
Best Reward: 0.12176056338028474
Reward: 0.11492957746479249
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c550> 0.11492957746479249 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885208> 0.11492957746479249 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 0.623380281690153 8
Completed Iteration #7
Best Reward: 0.12176056338028474
Completed Iteration #8
Best Reward: 0.12176056338028474
Reward: 0.08704225352112616
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885a58> 0.08704225352112616 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885e48> 0.08704225352112616 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae385cbe0> 0.15274647887324022 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c080> 0.15274647887324022 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 0.7104225352112792 9
Completed Iteration #9
Best Reward: 0.12176056338028474
Completed Iteration #10
Best Reward: 0.12176056338028474
Reward: 0.08457746478873673
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2908> 0.08457746478873673 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9b70> 0.24922535211268126 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 0.7950000000000159 10
Completed Iteration #11
Best Reward: 0.12176056338028474
Completed Iteration #12
Best Reward: 0.12176056338028474
Completed Iteration #13
Best Reward: 0.12176056338028474
Reward: 0.07915492957746295
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2978> 0.07915492957746295 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2ef0> 0.07915492957746295 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 0.8741549295774789 11
Completed Iteration #14
Best Reward: 0.12176056338028474
Reward: 0.11633802816901095
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2940> 0.11633802816901095 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2ac8> 0.11633802816901095 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae385cbe0> 0.2690845070422512 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c080> 0.2690845070422512 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 0.9904929577464898 12
Completed Iteration #15
Best Reward: 0.12176056338028474
Reward: 0.08309859154930166
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df048> 0.08309859154930166 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfeb8> 0.08309859154930166 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 1.0735915492957915 13
Completed Iteration #16
Best Reward: 0.12176056338028474
Reward: 0.07788732394366349
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df128> 0.07788732394366349 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2ef0> 0.15704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 1.151478873239455 14
Completed Iteration #17
Best Reward: 0.12176056338028474
Reward: 0.11112676056337989
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df780> 0.11112676056337989 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885208> 0.22605633802817238 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 1.2626056338028349 15
Completed Iteration #18
Best Reward: 0.12176056338028474
Reward: 0.11253521126760546
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df2b0> 0.11253521126760546 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885208> 0.33859154929577784 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 1.3751408450704403 16
Completed Iteration #19
Best Reward: 0.12176056338028474
Reward: 0.07866197183098933
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df278> 0.07866197183098933 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2ef0> 0.23570422535211577 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 1.4538028169014297 17
Completed Iteration #20
Best Reward: 0.12176056338028474
Reward: 0.10859154929577386
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df0b8> 0.10859154929577386 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b24a8> 0.10859154929577386 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 1.5623943661972035 18
Completed Iteration #21
Best Reward: 0.12176056338028474
Reward: 0.06366197183098876
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f710> 0.06366197183098876 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c080> 0.33274647887323994 5
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 1.6260563380281923 19
Completed Iteration #22
Best Reward: 0.12176056338028474
Completed Iteration #23
Best Reward: 0.12176056338028474
Reward: 0.11302816901408619
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f2e8> 0.11302816901408619 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfeb8> 0.19612676056338785 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 1.7390845070422785 20
Completed Iteration #24
Best Reward: 0.12176056338028474
Reward: 0.1131690140845123
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f940> 0.1131690140845123 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2630> 0.1131690140845123 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9c88> 1.8522535211267908 21
Completed Iteration #25
Best Reward: 0.12176056338028474
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12176056338028474
No reward increase. Abort.
iteration: 9
found coverage increase 0.12176056338028474
Current Total Coverage 40.79640845070423
Reward: 0.09169014084506699
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990908> 0.09169014084506699 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f630> 0.09169014084506699 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 0.09169014084506699 2
Completed Iteration #0
Best Reward: 0.09169014084506699
Completed Iteration #1
Best Reward: 0.09169014084506699
Reward: 0.11169014084507012
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b390> 0.11169014084507012 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9198> 0.11169014084507012 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 0.2033802816901371 3
Completed Iteration #2
Best Reward: 0.11169014084507012
Completed Iteration #3
Best Reward: 0.11169014084507012
Reward: 0.12154929577464202
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861080> 0.12154929577464202 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861c18> 0.12154929577464202 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 0.32492957746477913 4
Completed Iteration #4
Best Reward: 0.12154929577464202
Completed Iteration #5
Best Reward: 0.12154929577464202
Reward: 0.1191549295774621
backprop <src.mcts.MCTS_Node object at 0x7f5ae385cf60> 0.1191549295774621 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae376b1d0> 0.1191549295774621 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 0.4440845070422412 5
Completed Iteration #6
Best Reward: 0.12154929577464202
Reward: 0.08859154929577073
backprop <src.mcts.MCTS_Node object at 0x7f5ae38857b8> 0.08859154929577073 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f630> 0.18028169014083772 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 0.532676056338012 6
Completed Iteration #7
Best Reward: 0.12154929577464202
Reward: 0.11457746478873077
backprop <src.mcts.MCTS_Node object at 0x7f5ae38859e8> 0.11457746478873077 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.11457746478873077 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 0.6472535211267427 7
Completed Iteration #8
Best Reward: 0.12154929577464202
Reward: 0.07105633802816413
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2080> 0.07105633802816413 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2160> 0.07105633802816413 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 0.7183098591549069 8
Completed Iteration #9
Best Reward: 0.12154929577464202
Reward: 0.07366197183097967
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df908> 0.07366197183097967 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2160> 0.1447183098591438 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 0.7919718309858865 9
Completed Iteration #10
Best Reward: 0.12154929577464202
Reward: 0.12028169014084256
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2278> 0.12028169014084256 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df198> 0.12028169014084256 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 0.9122535211267291 10
Completed Iteration #11
Best Reward: 0.12154929577464202
Reward: 0.10232394366197184
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfa90> 0.10232394366197184 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.2169014084507026 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 1.014577464788701 11
Completed Iteration #12
Best Reward: 0.12154929577464202
Reward: 0.07654929577464742
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f588> 0.07654929577464742 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dffd0> 0.07654929577464742 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 1.0911267605633483 12
Completed Iteration #13
Best Reward: 0.12154929577464202
Reward: 0.07056338028169051
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f5f8> 0.07056338028169051 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2160> 0.21528169014083431 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 1.1616901408450389 13
Completed Iteration #14
Best Reward: 0.12154929577464202
Completed Iteration #15
Best Reward: 0.12154929577464202
Completed Iteration #16
Best Reward: 0.12154929577464202
Completed Iteration #17
Best Reward: 0.12154929577464202
Reward: 0.09140845070422188
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990470> 0.09140845070422188 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f630> 0.2716901408450596 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 1.2530985915492607 14
Completed Iteration #18
Best Reward: 0.12154929577464202
Reward: 0.11049295774647305
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990278> 0.11049295774647305 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9198> 0.22218309859154317 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 1.3635915492957338 15
Completed Iteration #19
Best Reward: 0.12154929577464202
Reward: 0.09514084507041787
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990eb8> 0.09514084507041787 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38614a8> 0.31204225352112047 4
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 1.4587323943661517 16
Completed Iteration #20
Best Reward: 0.12154929577464202
Completed Iteration #21
Best Reward: 0.12154929577464202
Completed Iteration #22
Best Reward: 0.12154929577464202
Reward: 0.02760563380281411
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990048> 0.02760563380281411 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3861c18> 0.14915492957745613 3
backprop <src.mcts.MCTS_Node object at 0x7f5ae399f358> 1.4863380281689658 17
Completed Iteration #23
Best Reward: 0.12154929577464202
Completed Iteration #24
Best Reward: 0.12154929577464202
Completed Iteration #25
Best Reward: 0.12154929577464202
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12154929577464202
No reward increase. Abort.
iteration: 10
found coverage increase 0.12154929577464202
Current Total Coverage 40.91795774647887
Reward: 0.10788732394366463
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990860> 0.10788732394366463 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdbe0> 0.10788732394366463 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 0.10788732394366463 2
Completed Iteration #0
Best Reward: 0.10788732394366463
Reward: 0.10633802816902005
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba9b0> 0.10633802816902005 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdbe0> 0.21422535211268467 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 0.21422535211268467 3
Completed Iteration #1
Best Reward: 0.10788732394366463
Reward: 0.11838028169014336
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba668> 0.11838028169014336 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba828> 0.11838028169014336 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 0.33260563380282804 4
Completed Iteration #2
Best Reward: 0.11838028169014336
Reward: 0.11021126760564215
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba860> 0.11021126760564215 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdbe0> 0.3244366197183268 4
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 0.4428169014084702 5
Completed Iteration #3
Best Reward: 0.11838028169014336
Completed Iteration #4
Best Reward: 0.11838028169014336
Reward: 0.10950704225352581
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba7f0> 0.10950704225352581 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba748> 0.10950704225352581 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 0.552323943661996 6
Completed Iteration #5
Best Reward: 0.11838028169014336
Reward: 0.07063380281690002
backprop <src.mcts.MCTS_Node object at 0x7f5af1772e80> 0.07063380281690002 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17727b8> 0.07063380281690002 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 0.622957746478896 7
Completed Iteration #6
Best Reward: 0.11838028169014336
coverage_call_count 300
Reward: 0.1072535211267649
backprop <src.mcts.MCTS_Node object at 0x7f5af1772a20> 0.1072535211267649 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdbe0> 0.4316901408450917 5
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 0.7302112676056609 8
Completed Iteration #7
Best Reward: 0.11838028169014336
Reward: 0.11204225352113184
backprop <src.mcts.MCTS_Node object at 0x7f5af1772438> 0.11204225352113184 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772940> 0.11204225352113184 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990860> 0.21992957746479647 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdbe0> 0.5437323943662236 6
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 0.8422535211267927 9
Completed Iteration #8
Best Reward: 0.11838028169014336
Completed Iteration #9
Best Reward: 0.11838028169014336
Reward: 0.10816901408450974
backprop <src.mcts.MCTS_Node object at 0x7f5ae37d9550> 0.10816901408450974 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38616a0> 0.10816901408450974 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 0.9504225352113025 10
Completed Iteration #10
Best Reward: 0.11838028169014336
Reward: 0.10633802816902005
backprop <src.mcts.MCTS_Node object at 0x7f5ae3885e80> 0.10633802816902005 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae385c470> 0.10633802816902005 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 1.0567605633803225 11
Completed Iteration #11
Best Reward: 0.11838028169014336
Reward: 0.11422535211268325
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b22b0> 0.11422535211268325 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2320> 0.11422535211268325 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 1.1709859154930058 12
Completed Iteration #12
Best Reward: 0.11838028169014336
Reward: 0.046338028169017775
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfc18> 0.046338028169017775 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfa20> 0.046338028169017775 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 1.2173239436620236 13
Completed Iteration #13
Best Reward: 0.11838028169014336
Reward: 0.08549295774648158
backprop <src.mcts.MCTS_Node object at 0x7f5ae399fbe0> 0.08549295774648158 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2320> 0.19971830985916483 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 1.3028169014085051 14
Completed Iteration #14
Best Reward: 0.11838028169014336
Completed Iteration #15
Best Reward: 0.11838028169014336
Completed Iteration #16
Best Reward: 0.11838028169014336
Completed Iteration #17
Best Reward: 0.11838028169014336
Completed Iteration #18
Best Reward: 0.11838028169014336
Reward: 0.11035211267606115
backprop <src.mcts.MCTS_Node object at 0x7f5ae39904a8> 0.11035211267606115 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdbe0> 0.6540845070422847 7
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 1.4131690140845663 15
Completed Iteration #19
Best Reward: 0.11838028169014336
Reward: 0.08647887323944303
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990c88> 0.08647887323944303 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b2320> 0.28619718309860787 4
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 1.4996478873240093 16
Completed Iteration #20
Best Reward: 0.11838028169014336
Reward: 0.11830985915493386
backprop <src.mcts.MCTS_Node object at 0x7f5ae39909b0> 0.11830985915493386 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba7b8> 0.11830985915493386 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba668> 0.23669014084507722 3
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba828> 0.23669014084507722 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 1.6179577464789432 17
Completed Iteration #21
Best Reward: 0.11838028169014336
Reward: 0.05563380281690655
backprop <src.mcts.MCTS_Node object at 0x7f5af17baef0> 0.05563380281690655 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfa20> 0.10197183098592433 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 1.6735915492958497 18
Completed Iteration #22
Best Reward: 0.11838028169014336
Reward: 0.1133802816901408
backprop <src.mcts.MCTS_Node object at 0x7f5af17badd8> 0.1133802816901408 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdbe0> 0.7674647887324255 8
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 1.7869718309859906 19
Completed Iteration #23
Best Reward: 0.11838028169014336
Reward: 0.11302816901408619
backprop <src.mcts.MCTS_Node object at 0x7f5af1772da0> 0.11302816901408619 2
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdbe0> 0.8804929577465117 9
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 1.9000000000000767 20
Completed Iteration #24
Best Reward: 0.11838028169014336
Reward: 0.11035211267606115
backprop <src.mcts.MCTS_Node object at 0x7f5af17729e8> 0.11035211267606115 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17727b8> 0.18098591549296117 3
backprop <src.mcts.MCTS_Node object at 0x7f5b481fdcc0> 2.010352112676138 21
Completed Iteration #25
Best Reward: 0.11838028169014336
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11838028169014336
No reward increase. Abort.
iteration: 11
found coverage increase 0.11838028169014336
Current Total Coverage 41.03633802816901
Reward: 0.07866197183098933
backprop <src.mcts.MCTS_Node object at 0x7f5af17721d0> 0.07866197183098933 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772748> 0.07866197183098933 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 0.07866197183098933 2
Completed Iteration #0
Best Reward: 0.07866197183098933
Reward: 0.07338028169014166
backprop <src.mcts.MCTS_Node object at 0x7f5af1794080> 0.07338028169014166 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794160> 0.07338028169014166 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 0.152042253521131 3
Completed Iteration #1
Best Reward: 0.07866197183098933
Reward: 0.11992957746478794
backprop <src.mcts.MCTS_Node object at 0x7f5af17946d8> 0.11992957746478794 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794160> 0.1933098591549296 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 0.2719718309859189 4
Completed Iteration #2
Best Reward: 0.11992957746478794
Completed Iteration #3
Best Reward: 0.11992957746478794
Reward: 0.10788732394365752
backprop <src.mcts.MCTS_Node object at 0x7f5af1794860> 0.10788732394365752 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794f28> 0.10788732394365752 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 0.37985915492957645 5
Completed Iteration #4
Best Reward: 0.11992957746478794
Reward: 0.09161971830985749
backprop <src.mcts.MCTS_Node object at 0x7f5af1794dd8> 0.09161971830985749 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794ba8> 0.09161971830985749 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 0.47147887323943394 6
Completed Iteration #5
Best Reward: 0.11992957746478794
Completed Iteration #6
Best Reward: 0.11992957746478794
Reward: 0.10690140845070317
backprop <src.mcts.MCTS_Node object at 0x7f5af1743048> 0.10690140845070317 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17434e0> 0.10690140845070317 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 0.5783802816901371 7
Completed Iteration #7
Best Reward: 0.11992957746478794
Reward: 0.10619718309859394
backprop <src.mcts.MCTS_Node object at 0x7f5af1743400> 0.10619718309859394 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794f28> 0.21408450704225146 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 0.684577464788731 8
Completed Iteration #8
Best Reward: 0.11992957746478794
Reward: 0.11781690140845313
backprop <src.mcts.MCTS_Node object at 0x7f5af1743438> 0.11781690140845313 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743b00> 0.11781690140845313 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 0.8023943661971842 9
Completed Iteration #9
Best Reward: 0.11992957746478794
Reward: 0.10880281690140947
backprop <src.mcts.MCTS_Node object at 0x7f5af1743dd8> 0.10880281690140947 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743390> 0.10880281690140947 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 0.9111971830985937 10
Completed Iteration #10
Best Reward: 0.11992957746478794
Reward: 0.0877464788732425
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b128> 0.0877464788732425 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794ba8> 0.17936619718309998 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 0.9989436619718361 11
Completed Iteration #11
Best Reward: 0.11992957746478794
Reward: 0.11077464788732527
backprop <src.mcts.MCTS_Node object at 0x7f5af1743be0> 0.11077464788732527 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743390> 0.21957746478873474 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 1.1097183098591614 12
Completed Iteration #12
Best Reward: 0.11992957746478794
Reward: 0.03218309859155255
backprop <src.mcts.MCTS_Node object at 0x7f5ae385cc88> 0.03218309859155255 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743b00> 0.15000000000000568 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 1.141901408450714 13
Completed Iteration #13
Best Reward: 0.11992957746478794
Completed Iteration #14
Best Reward: 0.11992957746478794
Reward: 0.06563380281690456
backprop <src.mcts.MCTS_Node object at 0x7f5ae38b29b0> 0.06563380281690456 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794e48> 0.06563380281690456 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 1.2075352112676185 14
Completed Iteration #15
Best Reward: 0.11992957746478794
Completed Iteration #16
Best Reward: 0.11992957746478794
Reward: 0.11049295774648016
backprop <src.mcts.MCTS_Node object at 0x7f5ae38df7f0> 0.11049295774648016 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743390> 0.3300704225352149 4
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 1.3180281690140987 15
Completed Iteration #17
Best Reward: 0.11992957746478794
Reward: 0.11852112676056947
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990a20> 0.11852112676056947 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743390> 0.4485915492957844 5
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 1.4365492957746682 16
Completed Iteration #18
Best Reward: 0.11992957746478794
Reward: 0.11809859154929825
backprop <src.mcts.MCTS_Node object at 0x7f5af17ba630> 0.11809859154929825 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794f28> 0.3321830985915497 4
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 1.5546478873239664 17
Completed Iteration #19
Best Reward: 0.11992957746478794
Reward: 0.11260563380282207
backprop <src.mcts.MCTS_Node object at 0x7f5af17bac88> 0.11260563380282207 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794160> 0.30591549295775167 4
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 1.6672535211267885 18
Completed Iteration #20
Best Reward: 0.11992957746478794
Reward: 0.11154929577465111
backprop <src.mcts.MCTS_Node object at 0x7f5af1772eb8> 0.11154929577465111 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17434e0> 0.2184507042253543 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 1.7788028169014396 19
Completed Iteration #21
Best Reward: 0.11992957746478794
Reward: 0.07936619718309856
backprop <src.mcts.MCTS_Node object at 0x7f5af1772400> 0.07936619718309856 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772748> 0.1580281690140879 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 1.8581690140845382 20
Completed Iteration #22
Best Reward: 0.11992957746478794
Completed Iteration #23
Best Reward: 0.11992957746478794
Reward: 0.07260563380281582
backprop <src.mcts.MCTS_Node object at 0x7f5af1794320> 0.07260563380281582 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1772748> 0.2306338028169037 4
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 1.930774647887354 21
Completed Iteration #24
Best Reward: 0.11992957746478794
Reward: 0.11154929577465111
backprop <src.mcts.MCTS_Node object at 0x7f5af1794470> 0.11154929577465111 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17434e0> 0.3300000000000054 4
backprop <src.mcts.MCTS_Node object at 0x7f5af1772898> 2.042323943662005 22
Completed Iteration #25
Best Reward: 0.11992957746478794
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11992957746478794
No reward increase. Abort.
iteration: 12
found coverage increase 0.11992957746478794
Current Total Coverage 41.1562676056338
Reward: 0.06542253521126895
backprop <src.mcts.MCTS_Node object at 0x7f5af1743710> 0.06542253521126895 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743198> 0.06542253521126895 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 0.06542253521126895 2
Completed Iteration #0
Best Reward: 0.06542253521126895
Reward: 0.06591549295774968
backprop <src.mcts.MCTS_Node object at 0x7f5af1743f28> 0.06591549295774968 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743198> 0.13133802816901863 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 0.13133802816901863 3
Completed Iteration #1
Best Reward: 0.06591549295774968
Completed Iteration #2
Best Reward: 0.06591549295774968
Reward: 0.0507042253521135
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b4e0> 0.0507042253521135 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375ba90> 0.0507042253521135 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 0.18204225352113212 4
Completed Iteration #3
Best Reward: 0.06591549295774968
Reward: 0.09866197183098535
backprop <src.mcts.MCTS_Node object at 0x7f5ae375bcf8> 0.09866197183098535 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375bda0> 0.09866197183098535 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 0.2807042253521175 5
Completed Iteration #4
Best Reward: 0.09866197183098535
Reward: 0.04866197183098819
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff0f0> 0.04866197183098819 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375ba90> 0.09936619718310169 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 0.32936619718310567 6
Completed Iteration #5
Best Reward: 0.09866197183098535
Completed Iteration #6
Best Reward: 0.09866197183098535
Completed Iteration #7
Best Reward: 0.09866197183098535
Reward: 0.06605633802816868
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ffc50> 0.06605633802816868 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743198> 0.1973943661971873 4
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 0.39542253521127435 7
Completed Iteration #8
Best Reward: 0.09866197183098535
Reward: 0.11288732394366718
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ffd68> 0.11288732394366718 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff828> 0.11288732394366718 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 0.5083098591549415 8
Completed Iteration #9
Best Reward: 0.11288732394366718
Completed Iteration #10
Best Reward: 0.11288732394366718
Reward: 0.11992957746478794
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f5080> 0.11992957746478794 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375bda0> 0.2185915492957733 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 0.6282394366197295 9
Completed Iteration #11
Best Reward: 0.11992957746478794
Completed Iteration #12
Best Reward: 0.11992957746478794
Completed Iteration #13
Best Reward: 0.11992957746478794
Reward: 0.11669014084507268
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f5550> 0.11669014084507268 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff320> 0.11669014084507268 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 0.7449295774648022 10
Completed Iteration #14
Best Reward: 0.11992957746478794
Completed Iteration #15
Best Reward: 0.11992957746478794
Completed Iteration #16
Best Reward: 0.11992957746478794
Reward: 0.11598591549296344
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f5f28> 0.11598591549296344 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f5b70> 0.11598591549296344 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 0.8609154929577656 11
Completed Iteration #17
Best Reward: 0.11992957746478794
Reward: 0.11028169014084455
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f5fd0> 0.11028169014084455 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b1d0> 0.11028169014084455 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 0.9711971830986101 12
Completed Iteration #18
Best Reward: 0.11992957746478794
Reward: 0.101408450704227
backprop <src.mcts.MCTS_Node object at 0x7f5adf6c3278> 0.101408450704227 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f5b70> 0.21739436619719044 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 1.0726056338028371 13
Completed Iteration #19
Best Reward: 0.11992957746478794
Reward: 0.08535211267605547
backprop <src.mcts.MCTS_Node object at 0x7f5adf6c34a8> 0.08535211267605547 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f5358> 0.08535211267605547 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 1.1579577464788926 14
Completed Iteration #20
Best Reward: 0.11992957746478794
Completed Iteration #21
Best Reward: 0.11992957746478794
Completed Iteration #22
Best Reward: 0.11992957746478794
Reward: 0.11422535211267615
backprop <src.mcts.MCTS_Node object at 0x7f5ae38dfda0> 0.11422535211267615 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff6a0> 0.11422535211267615 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 1.2721830985915688 15
Completed Iteration #23
Best Reward: 0.11992957746478794
Completed Iteration #24
Best Reward: 0.11992957746478794
Reward: 0.11570422535211122
backprop <src.mcts.MCTS_Node object at 0x7f5ae3990978> 0.11570422535211122 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff828> 0.2285915492957784 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1743eb8> 1.38788732394368 16
Completed Iteration #25
Best Reward: 0.11992957746478794
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11992957746478794
No reward increase. Abort.
iteration: 13
found coverage increase 0.11992957746478794
Current Total Coverage 41.27619718309859
Reward: 0.09661971830986005
backprop <src.mcts.MCTS_Node object at 0x7f5af1794d30> 0.09661971830986005 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17bab00> 0.09661971830986005 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 0.09661971830986005 2
Completed Iteration #0
Best Reward: 0.09661971830986005
Completed Iteration #1
Best Reward: 0.09661971830986005
Reward: 0.11788732394366974
backprop <src.mcts.MCTS_Node object at 0x7f5af1772d68> 0.11788732394366974 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17bab00> 0.2145070422535298 3
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 0.2145070422535298 3
Completed Iteration #2
Best Reward: 0.11788732394366974
Completed Iteration #3
Best Reward: 0.11788732394366974
Reward: 0.11704225352112729
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b8d0> 0.11704225352112729 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743518> 0.11704225352112729 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 0.3315492957746571 4
Completed Iteration #4
Best Reward: 0.11788732394366974
Reward: 0.11387323943662153
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b668> 0.11387323943662153 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743e10> 0.11387323943662153 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 0.4454225352112786 5
Completed Iteration #5
Best Reward: 0.11788732394366974
Reward: 0.11633802816901806
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff438> 0.11633802816901806 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff4a8> 0.11633802816901806 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 0.5617605633802967 6
Completed Iteration #6
Best Reward: 0.11788732394366974
Completed Iteration #7
Best Reward: 0.11788732394366974
Reward: 0.11197183098592234
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ffa20> 0.11197183098592234 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ffa90> 0.11197183098592234 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 0.673732394366219 7
Completed Iteration #8
Best Reward: 0.11788732394366974
Completed Iteration #9
Best Reward: 0.11788732394366974
Completed Iteration #10
Best Reward: 0.11788732394366974
Reward: 0.11485915492958299
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f5ef0> 0.11485915492958299 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ffa90> 0.22683098591550532 3
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 0.788591549295802 8
Completed Iteration #11
Best Reward: 0.11788732394366974
Reward: 0.11788732394366974
backprop <src.mcts.MCTS_Node object at 0x7f5adf6c3160> 0.11788732394366974 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ffa90> 0.34471830985917506 4
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 0.9064788732394717 9
Completed Iteration #12
Best Reward: 0.11788732394366974
Reward: 0.09535211267605348
backprop <src.mcts.MCTS_Node object at 0x7f5adf6c3710> 0.09535211267605348 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17bab00> 0.30985915492958327 4
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 1.0018309859155252 10
Completed Iteration #13
Best Reward: 0.11788732394366974
Reward: 0.11485915492958299
backprop <src.mcts.MCTS_Node object at 0x7f5adf6c3a20> 0.11485915492958299 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff4a8> 0.23119718309860104 3
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 1.1166901408451082 11
Completed Iteration #14
Best Reward: 0.11788732394366974
Reward: 0.07183098591549708
backprop <src.mcts.MCTS_Node object at 0x7f5adf6c3b00> 0.07183098591549708 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794d68> 0.07183098591549708 2
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 1.1885211267606053 12
Completed Iteration #15
Best Reward: 0.11788732394366974
Reward: 0.11971830985915943
backprop <src.mcts.MCTS_Node object at 0x7f5adf6c3eb8> 0.11971830985915943 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6c3c50> 0.11971830985915943 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b8d0> 0.23676056338028673 3
backprop <src.mcts.MCTS_Node object at 0x7f5af1743518> 0.23676056338028673 3
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 1.3082394366197647 13
Completed Iteration #16
Best Reward: 0.11971830985915943
Reward: 0.06880281690141032
backprop <src.mcts.MCTS_Node object at 0x7f5adf68f0f0> 0.06880281690141032 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794d68> 0.1406338028169074 3
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 1.377042253521175 14
Completed Iteration #17
Best Reward: 0.11971830985915943
Completed Iteration #18
Best Reward: 0.11971830985915943
Reward: 0.1172535211267629
backprop <src.mcts.MCTS_Node object at 0x7f5adf68f470> 0.1172535211267629 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff4a8> 0.34845070422536395 4
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 1.494295774647938 15
Completed Iteration #19
Best Reward: 0.11971830985915943
Reward: 0.11492957746479249
backprop <src.mcts.MCTS_Node object at 0x7f5adf68f6a0> 0.11492957746479249 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794d68> 0.2555633802816999 4
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 1.6092253521127304 16
Completed Iteration #20
Best Reward: 0.11971830985915943
Reward: 0.1190140845070502
backprop <src.mcts.MCTS_Node object at 0x7f5adf68f860> 0.1190140845070502 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1794d68> 0.3745774647887501 5
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 1.7282394366197806 17
Completed Iteration #21
Best Reward: 0.11971830985915943
Reward: 0.11429577464788565
backprop <src.mcts.MCTS_Node object at 0x7f5adf68fa90> 0.11429577464788565 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff4a8> 0.4627464788732496 5
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 1.8425352112676663 18
Completed Iteration #22
Best Reward: 0.11971830985915943
Reward: 0.10309859154929768
backprop <src.mcts.MCTS_Node object at 0x7f5adf68fcc0> 0.10309859154929768 2
backprop <src.mcts.MCTS_Node object at 0x7f5af1743e10> 0.2169718309859192 3
backprop <src.mcts.MCTS_Node object at 0x7f5af17bae80> 1.945633802816964 19
Completed Iteration #23
Best Reward: 0.11971830985915943
Completed Iteration #24
Best Reward: 0.11971830985915943
Completed Iteration #25
Best Reward: 0.11971830985915943
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11971830985915943
No reward increase. Abort.
coverage_call_count 400
iteration: 14
found coverage increase 0.11971830985915943
Current Total Coverage 41.39591549295775
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.11640845070422046
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf828> 0.11640845070422046 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf518> 0.11640845070422046 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 0.11640845070422046 2
Completed Iteration #2
Best Reward: 0.11640845070422046
Reward: 0.10422535211267103
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bfa20> 0.10422535211267103 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf320> 0.10422535211267103 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 0.2206338028168915 3
Completed Iteration #3
Best Reward: 0.11640845070422046
Reward: 0.11549295774647561
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bfba8> 0.11549295774647561 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bfcc0> 0.11549295774647561 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 0.3361267605633671 4
Completed Iteration #4
Best Reward: 0.11640845070422046
Completed Iteration #5
Best Reward: 0.11640845070422046
Completed Iteration #6
Best Reward: 0.11640845070422046
Reward: 0.08859154929577073
backprop <src.mcts.MCTS_Node object at 0x7f5af1743208> 0.08859154929577073 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf518> 0.2049999999999912 3
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 0.42471830985913783 5
Completed Iteration #7
Best Reward: 0.11640845070422046
Completed Iteration #8
Best Reward: 0.11640845070422046
Reward: 0.11239436619717935
backprop <src.mcts.MCTS_Node object at 0x7f5af1794b00> 0.11239436619717935 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf4a8> 0.11239436619717935 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 0.5371126760563172 6
Completed Iteration #9
Best Reward: 0.11640845070422046
Completed Iteration #10
Best Reward: 0.11640845070422046
Reward: 0.11352112676055981
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff3c8> 0.11352112676055981 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff4e0> 0.11352112676055981 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 0.650633802816877 7
Completed Iteration #11
Best Reward: 0.11640845070422046
Reward: 0.04852112676056208
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f5f60> 0.04852112676056208 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f57f0> 0.04852112676056208 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 0.6991549295774391 8
Completed Iteration #12
Best Reward: 0.11640845070422046
Reward: 0.10845070422535485
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f5400> 0.10845070422535485 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf4a8> 0.2208450704225342 3
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 0.8076056338027939 9
Completed Iteration #13
Best Reward: 0.11640845070422046
Reward: 0.11204225352112474
backprop <src.mcts.MCTS_Node object at 0x7f5adf6c31d0> 0.11204225352112474 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36ff4e0> 0.22556338028168454 3
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 0.9196478873239187 10
Completed Iteration #14
Best Reward: 0.11640845070422046
Completed Iteration #15
Best Reward: 0.11640845070422046
Reward: 0.10816901408450974
backprop <src.mcts.MCTS_Node object at 0x7f5adf6c3400> 0.10816901408450974 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bfcc0> 0.22366197183098535 3
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 1.0278169014084284 11
Completed Iteration #16
Best Reward: 0.11640845070422046
Reward: 0.054859154929573606
backprop <src.mcts.MCTS_Node object at 0x7f5adf68f2b0> 0.054859154929573606 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f57f0> 0.10338028169013569 3
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 1.082676056338002 12
Completed Iteration #17
Best Reward: 0.11640845070422046
Reward: 0.0956338028168986
backprop <src.mcts.MCTS_Node object at 0x7f5adf68f668> 0.0956338028168986 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf4a8> 0.3164788732394328 4
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 1.1783098591549006 13
Completed Iteration #18
Best Reward: 0.11640845070422046
Reward: 0.04908450704225231
backprop <src.mcts.MCTS_Node object at 0x7f5adf68f978> 0.04908450704225231 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae36f57f0> 0.152464788732388 4
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 1.227394366197153 14
Completed Iteration #19
Best Reward: 0.11640845070422046
Reward: 0.11380281690140492
backprop <src.mcts.MCTS_Node object at 0x7f5adf68f9b0> 0.11380281690140492 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf320> 0.21802816901407596 3
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 1.3411971830985578 15
Completed Iteration #20
Best Reward: 0.11640845070422046
Completed Iteration #21
Best Reward: 0.11640845070422046
Completed Iteration #22
Best Reward: 0.11640845070422046
Reward: 0.11422535211266904
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf9b0> 0.11422535211266904 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf518> 0.31922535211266023 4
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 1.4554225352112269 16
Completed Iteration #23
Best Reward: 0.11640845070422046
Completed Iteration #24
Best Reward: 0.11640845070422046
Reward: 0.11154929577464401
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bfef0> 0.11154929577464401 2
backprop <src.mcts.MCTS_Node object at 0x7f5ae375b5c0> 0.11154929577464401 2
backprop <src.mcts.MCTS_Node object at 0x7f5adf6bf400> 1.566971830985871 17
Completed Iteration #25
Best Reward: 0.11640845070422046
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11640845070422046
No reward increase. Abort.
iteration: 15
found coverage increase 0.11640845070422046
Current Total Coverage 41.51232394366197
initial coverage: 39.5706
time passed (minutes): 40.6095
iterations: 16
number of new inputs: 1024
final coverage: 41.5123
total coverage increase: 1.94169
