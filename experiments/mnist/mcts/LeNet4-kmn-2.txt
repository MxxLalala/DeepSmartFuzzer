Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'kmn'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f24c47ecf28>, tc2=<function tc2 at 0x7f24c47fd048>, tc3=<function tc3 at 0x7f24c47fd158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 11.7254
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7da0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7c50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.03521126760563398 4
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.07042253521126796 5
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.07042253521126796 6
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7f28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.10563380281690193 7
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c0a76a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1408450704225359 8
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1408450704225359 9
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7c50> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 10
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 11
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 12
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 13
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7c50> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 14
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 15
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 16
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 17
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 18
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 19
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243063f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 20
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 21
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243063f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 22
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 23
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 24
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 11
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 25
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 12
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 26
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 13
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 27
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 14
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 28
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 15
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 29
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.07042253521126796 16
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.1760563380281699 30
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c03b860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7fd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b780> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.10563380281690193 17
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.21126760563380387 31
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.10563380281690193 18
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.21126760563380387 32
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.10563380281690193 19
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.21126760563380387 33
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.10563380281690193 20
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.21126760563380387 34
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35220b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.10563380281690193 21
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.21126760563380387 35
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c0a75f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.1408450704225359 22
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.24647887323943785 36
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.1408450704225359 23
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.24647887323943785 37
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3522860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.1760563380281699 24
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.2816901408450718 38
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.1760563380281699 25
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.2816901408450718 39
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3522cf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522d68> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.21126760563380387 26
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.3169014084507058 40
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.21126760563380387 27
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.3169014084507058 41
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f352e358> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.24647887323943785 28
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.3521126760563398 42
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.24647887323943785 29
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.3521126760563398 43
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.24647887323943785 30
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.3521126760563398 44
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3522eb8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522160> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.1760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.2816901408450718 31
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.38732394366197376 45
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522d68> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.1760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.2816901408450718 32
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.38732394366197376 46
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c03bcf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.21126760563380387 10
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.3169014084507058 33
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.42253521126760774 47
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522d68> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.21126760563380387 11
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.3169014084507058 34
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.42253521126760774 48
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522160> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.3169014084507058 35
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.42253521126760774 49
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f352e128> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7b00> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.24647887323943785 13
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.3521126760563398 36
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.4577464788732417 50
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522d68> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.24647887323943785 14
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.3521126760563398 37
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.4577464788732417 51
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.24647887323943785 15
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.3521126760563398 38
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.4577464788732417 52
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f352eb38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35228d0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.2816901408450718 16
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.38732394366197376 39
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.4929577464788757 53
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f35430f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ecc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.3169014084507058 17
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.42253521126760774 40
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.5281690140845097 54
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ecc0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.3169014084507058 18
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.42253521126760774 41
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.5281690140845097 55
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.3169014084507058 19
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.42253521126760774 42
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.5281690140845097 56
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #2
root->6->15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.3521126760563398 20
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.4577464788732417 43
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.5633802816901436 57
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.3521126760563398 21
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.4577464788732417 44
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.5633802816901436 58
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3543dd8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.1760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.38732394366197376 22
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.4929577464788757 45
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.5985915492957776 59
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.38732394366197376 23
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.4929577464788757 46
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.5985915492957776 60
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3522e80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.21126760563380387 11
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.42253521126760774 24
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.5281690140845097 47
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.6338028169014116 61
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.42253521126760774 25
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.5281690140845097 48
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.6338028169014116 62
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.24647887323943785 13
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.4577464788732417 26
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.5633802816901436 49
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.6690140845070456 63
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f352eef0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.2816901408450718 14
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.4929577464788757 27
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.5985915492957776 50
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.7042253521126796 64
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.2816901408450718 15
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.4929577464788757 28
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.5985915492957776 51
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.7042253521126796 65
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.2816901408450718 16
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.4929577464788757 29
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.5985915492957776 52
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.7042253521126796 66
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.2816901408450718 17
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.4929577464788757 30
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.5985915492957776 53
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.7042253521126796 67
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.38732394366197376 18
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.5985915492957776 31
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.7042253521126796 54
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.8098591549295815 68
Completed Iteration #25
Best Reward: 0.10563380281690193
Completed MCTS Level/Depth: #3
root->6->15->0
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.38732394366197376 19
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.5985915492957776 32
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.7042253521126796 55
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.8098591549295815 69
Completed Iteration #0
Best Reward: 0.10563380281690193
Completed Iteration #1
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.38732394366197376 20
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.5985915492957776 33
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.7042253521126796 56
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.8098591549295815 70
Completed Iteration #2
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.38732394366197376 21
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.5985915492957776 34
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.7042253521126796 57
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.8098591549295815 71
Completed Iteration #3
Best Reward: 0.10563380281690193
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec940> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.21126760563380387 5
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.24647887323943785 7
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.4929577464788757 22
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.7042253521126796 35
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.8098591549295815 58
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.9154929577464834 72
Completed Iteration #4
Best Reward: 0.10563380281690193
Completed Iteration #5
Best Reward: 0.10563380281690193
Completed Iteration #6
Best Reward: 0.10563380281690193
Completed Iteration #7
Best Reward: 0.10563380281690193
Completed Iteration #8
Best Reward: 0.10563380281690193
Completed Iteration #9
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.2816901408450718 6
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.3169014084507058 8
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.5633802816901436 23
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.7746478873239475 36
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.8802816901408494 59
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 0.9859154929577514 73
Completed Iteration #10
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f243063f438> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecda0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.38732394366197376 9
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.6338028169014116 24
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.8450704225352155 37
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.9507042253521174 60
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.0563380281690193 74
Completed Iteration #11
Best Reward: 0.10563380281690193
Completed Iteration #12
Best Reward: 0.10563380281690193
Completed Iteration #13
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.2816901408450718 7
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.38732394366197376 10
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.6338028169014116 25
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.8450704225352155 38
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 0.9507042253521174 61
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.0563380281690193 75
Completed Iteration #14
Best Reward: 0.10563380281690193
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec208> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecda0> 0.1760563380281699 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.4929577464788757 11
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.7394366197183135 26
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.9507042253521174 39
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.0563380281690193 62
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.1619718309859213 76
Completed Iteration #15
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec9b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec748> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.5281690140845097 12
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.7746478873239475 27
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 0.9859154929577514 40
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.0915492957746533 63
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.1971830985915553 77
Completed Iteration #16
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f352ec88> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d3c8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.5985915492957776 13
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.8450704225352155 28
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.0563380281690193 41
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.1619718309859213 64
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.2676056338028232 78
Completed Iteration #17
Best Reward: 0.10563380281690193
Completed Iteration #18
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecda0> 0.1760563380281699 4
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.5985915492957776 14
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.8450704225352155 29
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.0563380281690193 42
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.1619718309859213 65
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.2676056338028232 79
Completed Iteration #19
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f354d860> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.3521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.6690140845070456 15
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.9154929577464834 30
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.1267605633802873 43
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.2323943661971892 66
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.3380281690140912 80
Completed Iteration #20
Best Reward: 0.10563380281690193
Completed Iteration #21
Best Reward: 0.10563380281690193
Completed Iteration #22
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d3c8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.6690140845070456 16
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.9154929577464834 31
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.1267605633802873 44
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.2323943661971892 67
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.3380281690140912 81
Completed Iteration #23
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec748> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.6690140845070456 17
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.9154929577464834 32
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.1267605633802873 45
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.2323943661971892 68
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.3380281690140912 82
Completed Iteration #24
Best Reward: 0.10563380281690193
Completed Iteration #25
Best Reward: 0.10563380281690193
Completed MCTS Level/Depth: #4
root->6->15->0->18
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.3521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.6690140845070456 18
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.9154929577464834 33
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.1267605633802873 46
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.2323943661971892 69
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.3380281690140912 83
Completed Iteration #0
Best Reward: 0.10563380281690193
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7f23f3512080> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.4577464788732417 10
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.7746478873239475 19
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.0211267605633854 34
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.2323943661971892 47
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.3380281690140912 70
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.443661971830993 84
Completed Iteration #1
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f35124e0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.1760563380281699 3
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.5281690140845097 11
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.8450704225352155 20
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.0915492957746533 35
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.3028169014084572 48
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.4084507042253591 71
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.514084507042261 85
Completed Iteration #2
Best Reward: 0.10563380281690193
Completed Iteration #3
Best Reward: 0.10563380281690193
Reward: 0.14084507042253414
backprop <src.mcts.MCTS_Node object at 0x7f23f352eac8> 0.14084507042253414 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.6690140845070438 12
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.9859154929577496 21
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.2323943661971875 36
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.4436619718309913 49
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.5492957746478933 72
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.6549295774647952 86
Completed Iteration #4
Best Reward: 0.14084507042253414
Completed Iteration #5
Best Reward: 0.14084507042253414
Completed Iteration #6
Best Reward: 0.14084507042253414
Completed Iteration #7
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35226a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.6690140845070438 13
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.9859154929577496 22
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.2323943661971875 37
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.4436619718309913 50
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.5492957746478933 73
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.6549295774647952 87
Completed Iteration #8
Best Reward: 0.14084507042253414
Completed Iteration #9
Best Reward: 0.14084507042253414
Completed Iteration #10
Best Reward: 0.14084507042253414
Completed Iteration #11
Best Reward: 0.14084507042253414
Completed Iteration #12
Best Reward: 0.14084507042253414
Completed Iteration #13
Best Reward: 0.14084507042253414
Completed Iteration #14
Best Reward: 0.14084507042253414
Completed Iteration #15
Best Reward: 0.14084507042253414
Completed Iteration #16
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d860> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.6690140845070438 14
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 0.9859154929577496 23
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.2323943661971875 38
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.4436619718309913 51
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.5492957746478933 74
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.6549295774647952 88
Completed Iteration #17
Best Reward: 0.14084507042253414
Completed Iteration #18
Best Reward: 0.14084507042253414
Completed Iteration #19
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f3512048> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512a90> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec940> 0.1760563380281699 3
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.7394366197183118 15
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.0563380281690176 24
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.3028169014084554 39
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.5140845070422593 52
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.6197183098591612 75
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.7253521126760631 89
Completed Iteration #20
Best Reward: 0.14084507042253414
Completed Iteration #21
Best Reward: 0.14084507042253414
Completed Iteration #22
Best Reward: 0.14084507042253414
Completed Iteration #23
Best Reward: 0.14084507042253414
Completed Iteration #24
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352eac8> 0.14084507042253414 3
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.7394366197183118 16
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.0563380281690176 25
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.3028169014084554 40
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.5140845070422593 53
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.6197183098591612 76
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.7253521126760631 90
Completed Iteration #25
Best Reward: 0.14084507042253414
Completed MCTS Level/Depth: #5
root->6->15->0->18->1
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.1760563380281699 4
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.7394366197183118 17
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.0563380281690176 26
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.3028169014084554 41
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.5140845070422593 54
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.6197183098591612 77
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.7253521126760631 91
Completed Iteration #0
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f35438d0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d898> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.24647887323943785 5
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.8098591549295797 18
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.1267605633802855 27
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.3732394366197234 42
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.5845070422535272 55
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.6901408450704292 78
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.795774647887331 92
Completed Iteration #1
Best Reward: 0.14084507042253414
Completed Iteration #2
Best Reward: 0.14084507042253414
Completed Iteration #3
Best Reward: 0.14084507042253414
Completed Iteration #4
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.24647887323943785 6
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.8098591549295797 19
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.1267605633802855 28
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.3732394366197234 43
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.5845070422535272 56
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.6901408450704292 79
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.795774647887331 93
Completed Iteration #5
Best Reward: 0.14084507042253414
Completed Iteration #6
Best Reward: 0.14084507042253414
Completed Iteration #7
Best Reward: 0.14084507042253414
Completed Iteration #8
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.24647887323943785 7
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.8098591549295797 20
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.1267605633802855 29
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.3732394366197234 44
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.5845070422535272 57
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.6901408450704292 80
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.795774647887331 94
Completed Iteration #9
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34bab00> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.2816901408450718 8
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.8450704225352137 21
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.1619718309859195 30
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.4084507042253573 45
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.6197183098591612 58
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.7253521126760631 81
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.830985915492965 95
Completed Iteration #10
Best Reward: 0.14084507042253414
Completed Iteration #11
Best Reward: 0.14084507042253414
Completed Iteration #12
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f35120b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aecf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.3169014084507058 9
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.8802816901408477 22
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.1971830985915535 31
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.4436619718309913 46
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.6549295774647952 59
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.7605633802816971 82
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.866197183098599 96
Completed Iteration #13
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f354dc50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecbe0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.3521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.9154929577464817 23
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.2323943661971875 32
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.4788732394366253 47
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.6901408450704292 60
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.795774647887331 83
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.901408450704233 97
Completed Iteration #14
Best Reward: 0.14084507042253414
Completed Iteration #15
Best Reward: 0.14084507042253414
Completed Iteration #16
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aecf8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.3521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.9154929577464817 24
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.2323943661971875 33
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.4788732394366253 48
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.6901408450704292 61
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.795774647887331 84
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.901408450704233 98
Completed Iteration #17
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aecf8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.38732394366197376 12
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.9507042253521156 25
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.2676056338028214 34
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.5140845070422593 49
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.7253521126760631 62
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.830985915492965 85
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 1.936619718309867 99
Completed Iteration #18
Best Reward: 0.14084507042253414
Completed Iteration #19
Best Reward: 0.14084507042253414
Completed Iteration #20
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba320> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.1760563380281699 4
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.4577464788732417 13
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.0211267605633836 26
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.3380281690140894 35
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.5845070422535272 50
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.795774647887331 63
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.901408450704233 86
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.007042253521135 100
Completed Iteration #21
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34baba8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.24647887323943785 5
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.5281690140845097 14
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.0915492957746515 27
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.4084507042253573 36
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.6549295774647952 51
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.866197183098599 64
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 1.971830985915501 87
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.077464788732403 101
Completed Iteration #22
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34bafd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba710> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.5633802816901436 15
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.1267605633802855 28
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.4436619718309913 37
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.6901408450704292 52
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.901408450704233 65
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.007042253521135 88
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.112676056338037 102
Completed Iteration #23
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba358> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba9b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.5985915492957776 16
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.1619718309859195 29
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.4788732394366253 38
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.7253521126760631 53
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 1.936619718309867 66
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.042253521126769 89
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.147887323943671 103
Completed Iteration #24
Best Reward: 0.14084507042253414
Completed Iteration #25
Best Reward: 0.14084507042253414
Completed MCTS Level/Depth: #6
root->6->15->0->18->1->10
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9588> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.3169014084507058 6
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.6690140845070456 17
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.2323943661971875 30
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.5492957746478933 39
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.795774647887331 54
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.007042253521135 67
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.112676056338037 90
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.218309859154939 104
Completed Iteration #0
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9a90> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c97f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35124e0> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.3521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.7042253521126796 18
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.2676056338028214 31
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.5845070422535272 40
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.830985915492965 55
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.042253521126769 68
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.147887323943671 91
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.253521126760573 105
Completed Iteration #1
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecb70> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.42253521126760774 8
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.7746478873239475 19
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.3380281690140894 32
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.6549295774647952 41
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.901408450704233 56
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.112676056338037 69
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.218309859154939 92
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.3239436619718408 106
Completed Iteration #2
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.42253521126760774 9
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.7746478873239475 20
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.3380281690140894 33
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.6549295774647952 42
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.901408450704233 57
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.112676056338037 70
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.218309859154939 93
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.3239436619718408 107
Completed Iteration #3
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b8d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba320> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.4577464788732417 10
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.8098591549295815 21
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.3732394366197234 34
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.6901408450704292 43
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 1.936619718309867 58
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.147887323943671 71
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.253521126760573 94
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.3591549295774747 108
Completed Iteration #4
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba080> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34badd8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bab00> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.5281690140845097 11
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.8802816901408494 22
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.4436619718309913 35
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.7605633802816971 44
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.007042253521135 59
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.218309859154939 72
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.3239436619718408 95
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.4295774647887427 109
Completed Iteration #5
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.5281690140845097 12
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.8802816901408494 23
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.4436619718309913 36
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.7605633802816971 45
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.007042253521135 60
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.218309859154939 73
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.3239436619718408 96
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.4295774647887427 110
Completed Iteration #6
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae550> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.5985915492957776 13
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 0.9507042253521174 24
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.5140845070422593 37
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.830985915492965 46
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.077464788732403 61
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.288732394366207 74
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.3943661971831087 97
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.5000000000000107 111
Completed Iteration #7
Best Reward: 0.14084507042253414
Completed Iteration #8
Best Reward: 0.14084507042253414
Completed Iteration #9
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9898> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c97b8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9588> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.6690140845070456 14
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.0211267605633854 25
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.5845070422535272 38
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 1.901408450704233 47
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.147887323943671 62
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.3591549295774747 75
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.4647887323943767 98
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.5704225352112786 112
Completed Iteration #10
Best Reward: 0.14084507042253414
Completed Iteration #11
Best Reward: 0.14084507042253414
Completed Iteration #12
Best Reward: 0.14084507042253414
Completed Iteration #13
Best Reward: 0.14084507042253414
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.7746478873239475 15
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.1267605633802873 26
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.6901408450704292 39
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.007042253521135 48
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.253521126760573 63
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.4647887323943767 76
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.5704225352112786 99
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.6760563380281805 113
Completed Iteration #14
Best Reward: 0.14084507042253414
Completed Iteration #15
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9278> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6898> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bab00> 0.1760563380281699 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.8450704225352155 16
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.1971830985915553 27
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.7605633802816971 40
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.077464788732403 49
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.3239436619718408 64
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.5352112676056446 77
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.6408450704225466 100
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.7464788732394485 114
Completed Iteration #16
Best Reward: 0.14084507042253414
Completed Iteration #17
Best Reward: 0.14084507042253414
Completed Iteration #18
Best Reward: 0.14084507042253414
Completed Iteration #19
Best Reward: 0.14084507042253414
Completed Iteration #20
Best Reward: 0.14084507042253414
Completed Iteration #21
Best Reward: 0.14084507042253414
Completed Iteration #22
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bae10> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34baba8> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.8802816901408494 17
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.2323943661971892 28
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.795774647887331 41
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.112676056338037 50
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.3591549295774747 65
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.5704225352112786 78
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.6760563380281805 101
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.7816901408450825 115
Completed Iteration #23
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.8802816901408494 18
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.2323943661971892 29
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.795774647887331 42
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.112676056338037 51
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.3591549295774747 66
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.5704225352112786 79
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.6760563380281805 102
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.7816901408450825 116
Completed Iteration #24
Best Reward: 0.14084507042253414
Completed Iteration #25
Best Reward: 0.14084507042253414
Completed MCTS Level/Depth: #7
root->6->15->0->18->1->10->8
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.8802816901408494 19
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.2323943661971892 30
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.795774647887331 43
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.112676056338037 52
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.3591549295774747 67
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.5704225352112786 80
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.6760563380281805 103
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.7816901408450825 117
Completed Iteration #0
Best Reward: 0.14084507042253414
Completed Iteration #1
Best Reward: 0.14084507042253414
Completed Iteration #2
Best Reward: 0.14084507042253414
coverage_call_count 200
Completed Iteration #3
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6278> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c90b8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.1760563380281699 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.9507042253521174 20
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.3028169014084572 31
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.866197183098599 44
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.183098591549305 53
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.4295774647887427 68
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.6408450704225466 81
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.7464788732394485 104
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.8521126760563504 118
Completed Iteration #4
Best Reward: 0.14084507042253414
Completed Iteration #5
Best Reward: 0.14084507042253414
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.1760563380281699 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.9507042253521174 21
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.3028169014084572 32
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.866197183098599 45
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.183098591549305 54
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.4295774647887427 69
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.6408450704225466 82
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.7464788732394485 105
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.8521126760563504 119
Completed Iteration #6
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3470400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470240> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.21126760563380387 6
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.9859154929577514 22
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.3380281690140912 33
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.901408450704233 46
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.218309859154939 55
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.4647887323943767 70
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.6760563380281805 83
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.7816901408450825 106
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.8873239436619844 120
Completed Iteration #7
Best Reward: 0.14084507042253414
Completed Iteration #8
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f354dcf8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6c88> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.2816901408450718 7
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 1.0563380281690193 23
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.4084507042253591 34
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 1.971830985915501 47
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.288732394366207 56
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.5352112676056446 71
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.7464788732394485 84
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.8521126760563504 107
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 2.9577464788732524 121
Completed Iteration #9
Best Reward: 0.14084507042253414
Completed Iteration #10
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f3470be0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c90b8> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.3521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 1.1267605633802873 24
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.478873239436627 35
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 2.042253521126769 48
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.3591549295774747 57
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.6056338028169126 72
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.8169014084507165 85
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.9225352112676184 108
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 3.0281690140845203 122
Completed Iteration #11
Best Reward: 0.14084507042253414
Completed Iteration #12
Best Reward: 0.14084507042253414
Completed Iteration #13
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba978> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470240> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.42253521126760774 9
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 1.1971830985915553 25
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.549295774647895 36
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 2.112676056338037 49
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.4295774647887427 58
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.6760563380281805 73
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.8873239436619844 86
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 2.9929577464788863 109
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 3.0985915492957883 123
Completed Iteration #14
Best Reward: 0.14084507042253414
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6748> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c90b8> 0.21126760563380387 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.4929577464788757 10
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 1.2676056338028232 26
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.619718309859163 37
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 2.183098591549305 50
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.5000000000000107 59
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.7464788732394485 74
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 2.9577464788732524 87
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 3.0633802816901543 110
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 3.1690140845070562 124
Completed Iteration #15
Best Reward: 0.14084507042253414
Completed Iteration #16
Best Reward: 0.14084507042253414
Completed Iteration #17
Best Reward: 0.14084507042253414
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9438> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6b70> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.5985915492957776 11
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 1.3732394366197251 27
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.725352112676065 38
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 2.288732394366207 51
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.6056338028169126 60
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.8521126760563504 75
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 3.0633802816901543 88
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 3.1690140845070562 111
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 3.274647887323958 125
Completed Iteration #18
Best Reward: 0.14084507042253414
Completed Iteration #19
Best Reward: 0.14084507042253414
Completed Iteration #20
Best Reward: 0.14084507042253414
Completed Iteration #21
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3470fd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470be0> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c90b8> 0.24647887323943785 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.6338028169014116 12
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 1.4084507042253591 28
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.760563380281699 39
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 2.3239436619718408 52
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.6408450704225466 61
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.8873239436619844 76
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 3.0985915492957883 89
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 3.20422535211269 112
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 3.309859154929592 126
Completed Iteration #22
Best Reward: 0.14084507042253414
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7f23f348a358> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c90b8> 0.3521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.7394366197183135 13
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 1.514084507042261 29
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.8661971830986008 40
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 2.4295774647887427 53
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.7464788732394485 62
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 2.9929577464788863 77
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 3.20422535211269 90
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 3.309859154929592 113
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 3.415492957746494 127
Completed Iteration #23
Best Reward: 0.14084507042253414
Completed Iteration #24
Best Reward: 0.14084507042253414
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9d68> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6c88> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6438> 0.7746478873239475 14
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 1.549295774647895 30
backprop <src.mcts.MCTS_Node object at 0x7f23f354dd30> 1.9014084507042348 41
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 2.4647887323943767 54
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea20> 2.7816901408450825 63
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 3.0281690140845203 78
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0f0> 3.239436619718324 91
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7e10> 3.345070422535226 114
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2908> 3.450704225352128 128
Completed Iteration #25
Best Reward: 0.14084507042253414
Completed MCTS Level/Depth: #8
root->6->15->0->18->1->10->8->0
Best Reward: 0.14084507042253414
iteration: 0
found coverage increase 0.14084507042253414
Current Total Coverage 11.86619718309859
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34964e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 11.86619718309859
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34704e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34704e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 9
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 10
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 11
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 12
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 13
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 14
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 15
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 16
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34704e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 17
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34402e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 18
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 19
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 20
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 21
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 22
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 23
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 24
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 25
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34409b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 26
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 27
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 28
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 29
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 30
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 31
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 32
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 33
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 34
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 35
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 19
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 36
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 20
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 37
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 21
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 38
Completed Iteration #24
Best Reward: 0.03521126760563398
coverage_call_count 300
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 22
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 39
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 23
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 40
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 24
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 41
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.03521126760563398 25
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.03521126760563398 42
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.07042253521126796 26
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.07042253521126796 43
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.07042253521126796 27
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.07042253521126796 44
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.07042253521126796 28
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.07042253521126796 45
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.07042253521126796 11
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.07042253521126796 29
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.07042253521126796 46
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e87117f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.10563380281690193 30
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.10563380281690193 47
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.10563380281690193 31
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.10563380281690193 48
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #2
root->2->15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.10563380281690193 32
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.10563380281690193 49
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.10563380281690193 15
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.10563380281690193 33
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.10563380281690193 50
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e872b668> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.1408450704225359 16
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.1408450704225359 34
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.1408450704225359 51
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8739940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.1760563380281699 35
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.1760563380281699 52
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.1760563380281699 18
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.1760563380281699 36
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.1760563380281699 53
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.21126760563380387 37
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.21126760563380387 54
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8739da0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.21126760563380387 11
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.24647887323943785 38
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.24647887323943785 55
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e871c4a8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.24647887323943785 12
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.2816901408450718 21
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.2816901408450718 39
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.2816901408450718 56
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3440e80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 13
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 22
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 40
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 57
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739940> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 14
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 23
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 41
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 58
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 15
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 24
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 42
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 59
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #3
root->2->15->6
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 16
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 25
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 43
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 60
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 17
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 26
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 44
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 61
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 18
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 27
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 45
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 62
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 19
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 28
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 46
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 63
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 20
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 29
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 47
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 64
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 21
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 30
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 48
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 65
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 22
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 31
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 49
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 66
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.07042253521126796 11
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 23
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 32
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 50
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 67
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #4
root->2->15->6->17
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.07042253521126796 12
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 24
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 33
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 51
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 68
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.07042253521126796 13
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.2816901408450718 25
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3169014084507058 34
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3169014084507058 52
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3169014084507058 69
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e871c080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b8d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.3169014084507058 26
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.3521126760563398 35
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.3521126760563398 53
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.3521126760563398 70
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4ac8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.1408450704225359 15
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.3521126760563398 27
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.38732394366197376 36
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.38732394366197376 54
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.38732394366197376 71
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.1408450704225359 16
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.3521126760563398 28
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.38732394366197376 37
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.38732394366197376 55
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.38732394366197376 72
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa978> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.38732394366197376 29
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.42253521126760774 38
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.42253521126760774 56
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.42253521126760774 73
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #5
root->2->15->6->17->3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8707390> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87072e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.42253521126760774 30
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.4577464788732417 39
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.4577464788732417 57
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.4577464788732417 74
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.1760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.42253521126760774 31
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.4577464788732417 40
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.4577464788732417 58
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.4577464788732417 75
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8707b00> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707eb8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.21126760563380387 14
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.4577464788732417 32
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.4929577464788757 41
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.4929577464788757 59
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.4929577464788757 76
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
coverage_call_count 400
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3b00> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.24647887323943785 15
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.2816901408450718 21
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.4929577464788757 33
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.5281690140845097 42
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.5281690140845097 60
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.5281690140845097 77
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707eb8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.24647887323943785 16
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.2816901408450718 22
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.4929577464788757 34
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.5281690140845097 43
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.5281690140845097 61
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.5281690140845097 78
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87072e8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.24647887323943785 17
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.2816901408450718 23
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.4929577464788757 35
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.5281690140845097 44
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.5281690140845097 62
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.5281690140845097 79
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.24647887323943785 18
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.2816901408450718 24
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.4929577464788757 36
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.5281690140845097 45
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.5281690140845097 63
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.5281690140845097 80
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.24647887323943785 19
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.2816901408450718 25
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.4929577464788757 37
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.5281690140845097 46
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.5281690140845097 64
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.5281690140845097 81
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.2816901408450718 26
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.4929577464788757 38
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.5281690140845097 47
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.5281690140845097 65
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.5281690140845097 82
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #6
root->2->15->6->17->3->0
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.24647887323943785 21
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.2816901408450718 27
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.4929577464788757 39
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.5281690140845097 48
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.5281690140845097 66
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.5281690140845097 83
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e87076a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.1760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.2816901408450718 22
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.3169014084507058 28
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.5281690140845097 40
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.5633802816901436 49
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.5633802816901436 67
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.5633802816901436 84
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.21126760563380387 14
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.3169014084507058 23
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.3521126760563398 29
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.5633802816901436 41
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.5985915492957776 50
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.5985915492957776 68
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.5985915492957776 85
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86acc50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.24647887323943785 15
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.3521126760563398 24
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.38732394366197376 30
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.5985915492957776 42
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6338028169014116 51
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6338028169014116 69
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6338028169014116 86
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.24647887323943785 16
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.3521126760563398 25
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.38732394366197376 31
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.5985915492957776 43
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6338028169014116 52
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6338028169014116 70
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6338028169014116 87
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.24647887323943785 17
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.3521126760563398 26
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.38732394366197376 32
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.5985915492957776 44
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6338028169014116 53
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6338028169014116 71
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6338028169014116 88
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.24647887323943785 18
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.3521126760563398 27
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.38732394366197376 33
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.5985915492957776 45
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6338028169014116 54
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6338028169014116 72
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6338028169014116 89
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.24647887323943785 19
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.3521126760563398 28
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.38732394366197376 34
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.5985915492957776 46
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6338028169014116 55
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6338028169014116 73
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6338028169014116 90
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #7
root->2->15->6->17->3->0->3
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86acba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3b00> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.3521126760563398 29
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.38732394366197376 35
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.5985915492957776 47
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6338028169014116 56
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6338028169014116 74
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6338028169014116 91
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3b00> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.24647887323943785 21
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.3521126760563398 30
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.38732394366197376 36
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.5985915492957776 48
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6338028169014116 57
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6338028169014116 75
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6338028169014116 92
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86c96d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3b00> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.2816901408450718 22
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.38732394366197376 31
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.42253521126760774 37
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.6338028169014116 49
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6690140845070456 58
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6690140845070456 76
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6690140845070456 93
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3b00> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.2816901408450718 23
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.38732394366197376 32
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.42253521126760774 38
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.6338028169014116 50
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6690140845070456 59
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6690140845070456 77
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6690140845070456 94
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3b00> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.2816901408450718 24
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.38732394366197376 33
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.42253521126760774 39
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.6338028169014116 51
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6690140845070456 60
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6690140845070456 78
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6690140845070456 95
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3b00> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1760563380281699 16
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.2816901408450718 25
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.38732394366197376 34
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.42253521126760774 40
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.6338028169014116 52
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6690140845070456 61
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6690140845070456 79
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6690140845070456 96
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3b00> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.2816901408450718 26
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.38732394366197376 35
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.42253521126760774 41
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.6338028169014116 53
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.6690140845070456 62
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.6690140845070456 80
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.6690140845070456 97
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3be0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707e80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3b00> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.3169014084507058 27
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.42253521126760774 36
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.4577464788732417 42
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.6690140845070456 54
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.7042253521126796 63
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.7042253521126796 81
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.7042253521126796 98
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9710> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707e80> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3b00> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.24647887323943785 19
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.3521126760563398 28
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.4577464788732417 37
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.4929577464788757 43
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.7042253521126796 55
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.7394366197183135 64
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.7394366197183135 82
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.7394366197183135 99
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86658d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac0b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3b00> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.2816901408450718 20
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc1d0> 0.38732394366197376 29
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.4929577464788757 38
backprop <src.mcts.MCTS_Node object at 0x7f23e8739278> 0.5281690140845097 44
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.7394366197183135 56
backprop <src.mcts.MCTS_Node object at 0x7f23f3496cc0> 0.7746478873239475 65
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.7746478873239475 83
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9da0> 0.7746478873239475 100
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #8
root->2->15->6->17->3->0->3->0
Best Reward: 0.03521126760563398
iteration: 2
found coverage increase 0.03521126760563398
Current Total Coverage 11.901408450704224
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86734a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86734a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86739b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 11.901408450704224
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 6
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 7
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 8
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 9
Completed Iteration #11
Best Reward: 0.03521126760563398
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 10
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 11
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 12
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 13
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 14
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 15
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 16
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 17
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 18
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 19
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 20
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 21
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 22
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 23
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 24
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 25
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 26
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86366a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 27
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.03521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.03521126760563398 28
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e862ac50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862acc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.07042253521126796 17
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.07042253521126796 29
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.07042253521126796 18
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.07042253521126796 30
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86364a8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86365f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636a90> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.10563380281690193 19
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.10563380281690193 31
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.10563380281690193 20
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.10563380281690193 32
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.10563380281690193 21
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.10563380281690193 33
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.10563380281690193 22
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.10563380281690193 34
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.10563380281690193 23
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.10563380281690193 35
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.10563380281690193 24
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.10563380281690193 36
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2492d25da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.10563380281690193 25
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.10563380281690193 37
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.10563380281690193 26
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.10563380281690193 38
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.10563380281690193 27
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.10563380281690193 39
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.10563380281690193 28
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.10563380281690193 40
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.10563380281690193 29
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.10563380281690193 41
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f2430675278> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab6d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.1408450704225359 30
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.1408450704225359 42
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.1408450704225359 31
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.1408450704225359 43
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.1408450704225359 32
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.1408450704225359 44
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.1760563380281699 33
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.1760563380281699 45
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862acc0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.1408450704225359 15
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.1760563380281699 34
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.1760563380281699 46
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8673940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.1760563380281699 16
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.21126760563380387 35
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.21126760563380387 47
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24306753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.21126760563380387 36
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.21126760563380387 48
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675278> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab6d8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.1760563380281699 18
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.21126760563380387 37
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.21126760563380387 49
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #2
root->2->17
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e862a780> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.24647887323943785 38
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.24647887323943785 50
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a780> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.21126760563380387 20
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.24647887323943785 39
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.24647887323943785 51
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.21126760563380387 21
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.24647887323943785 40
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.24647887323943785 52
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.21126760563380387 22
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.24647887323943785 41
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.24647887323943785 53
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86360f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.24647887323943785 23
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.2816901408450718 42
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.2816901408450718 54
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.24647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.2816901408450718 43
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.2816901408450718 55
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.24647887323943785 25
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.2816901408450718 44
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.2816901408450718 56
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.24647887323943785 26
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.2816901408450718 45
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.2816901408450718 57
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3e48> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.2816901408450718 27
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.3169014084507058 46
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.3169014084507058 58
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.21126760563380387 13
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.3169014084507058 28
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.3521126760563398 47
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.3521126760563398 59
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #3
root->2->17->7
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8636978> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.24647887323943785 14
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.3521126760563398 29
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.38732394366197376 48
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.38732394366197376 60
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a39e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.2816901408450718 15
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.38732394366197376 30
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.42253521126760774 49
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.42253521126760774 61
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a39e8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.2816901408450718 16
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.38732394366197376 31
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.42253521126760774 50
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.42253521126760774 62
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86acbe0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a39e8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.3169014084507058 17
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.42253521126760774 32
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.4577464788732417 51
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.4577464788732417 63
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8636f28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675eb8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.3521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.4577464788732417 33
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.4929577464788757 52
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.4929577464788757 64
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.1760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.3521126760563398 19
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.4577464788732417 34
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.4929577464788757 53
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.4929577464788757 65
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675eb8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.1760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.3521126760563398 20
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.4577464788732417 35
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.4929577464788757 54
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.4929577464788757 66
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.3521126760563398 21
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.4577464788732417 36
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.4929577464788757 55
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.4929577464788757 67
Completed Iteration #16
Best Reward: 0.03521126760563398
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.1760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.3521126760563398 22
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.4577464788732417 37
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.4929577464788757 56
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.4929577464788757 68
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.3521126760563398 23
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.4577464788732417 38
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.4929577464788757 57
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.4929577464788757 69
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a39e8> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.21126760563380387 13
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.38732394366197376 24
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.4929577464788757 39
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.5281690140845097 58
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.5281690140845097 70
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.24647887323943785 14
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.42253521126760774 25
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.5281690140845097 40
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.5633802816901436 59
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.5633802816901436 71
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #4
root->2->17->7->2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.24647887323943785 15
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.42253521126760774 26
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.5281690140845097 41
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.5633802816901436 60
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.5633802816901436 72
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.24647887323943785 16
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.42253521126760774 27
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.5281690140845097 42
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.5633802816901436 61
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.5633802816901436 73
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.24647887323943785 17
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.42253521126760774 28
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.5281690140845097 43
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.5633802816901436 62
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.5633802816901436 74
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.2816901408450718 18
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.4577464788732417 29
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.5633802816901436 44
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.5985915492957776 63
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.5985915492957776 75
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.2816901408450718 19
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.4577464788732417 30
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.5633802816901436 45
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.5985915492957776 64
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.5985915492957776 76
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8684198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.3169014084507058 20
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.4929577464788757 31
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.5985915492957776 46
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.6338028169014116 65
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.6338028169014116 77
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.3169014084507058 21
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.4929577464788757 32
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.5985915492957776 47
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.6338028169014116 66
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.6338028169014116 78
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.3169014084507058 22
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.4929577464788757 33
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.5985915492957776 48
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.6338028169014116 67
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.6338028169014116 79
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684198> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.3169014084507058 23
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.4929577464788757 34
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.5985915492957776 49
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.6338028169014116 68
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.6338028169014116 80
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.3169014084507058 24
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.4929577464788757 35
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.5985915492957776 50
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.6338028169014116 69
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.6338028169014116 81
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e86fadd8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc5f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3be0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.1760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.3521126760563398 25
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.5281690140845097 36
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.6338028169014116 51
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.6690140845070456 70
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.6690140845070456 82
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e872b7b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.21126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.38732394366197376 26
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.5633802816901436 37
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.6690140845070456 52
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.7042253521126796 71
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.7042253521126796 83
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24306754a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.21126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.38732394366197376 27
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.5633802816901436 38
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.6690140845070456 53
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.7042253521126796 72
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.7042253521126796 84
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.21126760563380387 17
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.38732394366197376 28
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.5633802816901436 39
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.6690140845070456 54
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.7042253521126796 73
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.7042253521126796 85
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #5
root->2->17->7->2->8
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e862aa58> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad68> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.24647887323943785 18
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.42253521126760774 29
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.5985915492957776 40
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7042253521126796 55
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.7394366197183135 74
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.7394366197183135 86
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.24647887323943785 19
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.42253521126760774 30
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.5985915492957776 41
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7042253521126796 56
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.7394366197183135 75
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.7394366197183135 87
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad68> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.42253521126760774 31
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.5985915492957776 42
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7042253521126796 57
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.7394366197183135 76
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.7394366197183135 88
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.24647887323943785 21
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.42253521126760774 32
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.5985915492957776 43
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7042253521126796 58
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.7394366197183135 77
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.7394366197183135 89
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.24647887323943785 22
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.42253521126760774 33
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.5985915492957776 44
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7042253521126796 59
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.7394366197183135 78
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.7394366197183135 90
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e871c240> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c978> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.2816901408450718 23
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.4577464788732417 34
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.6338028169014116 45
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7394366197183135 60
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.7746478873239475 79
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.7746478873239475 91
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8711cf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.3169014084507058 24
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.4929577464788757 35
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.6690140845070456 46
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7746478873239475 61
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.8098591549295815 80
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.8098591549295815 92
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad68> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.3169014084507058 25
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.4929577464788757 36
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.6690140845070456 47
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7746478873239475 62
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.8098591549295815 81
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.8098591549295815 93
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430682f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.3169014084507058 26
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.4929577464788757 37
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.6690140845070456 48
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7746478873239475 63
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.8098591549295815 82
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.8098591549295815 94
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.3169014084507058 27
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.4929577464788757 38
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.6690140845070456 49
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7746478873239475 64
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.8098591549295815 83
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.8098591549295815 95
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711cf8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.3169014084507058 28
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.4929577464788757 39
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.6690140845070456 50
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7746478873239475 65
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.8098591549295815 84
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.8098591549295815 96
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #6
root->2->17->7->2->8->1
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711cf8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.3169014084507058 29
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.4929577464788757 40
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.6690140845070456 51
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.7746478873239475 66
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.8098591549295815 85
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.8098591549295815 97
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8711be0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.1760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.3521126760563398 30
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.5281690140845097 41
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.7042253521126796 52
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.8098591549295815 67
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.8450704225352155 86
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.8450704225352155 98
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e871cb00> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.21126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.38732394366197376 31
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.5633802816901436 42
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.7394366197183135 53
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.8450704225352155 68
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.8802816901408494 87
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.8802816901408494 99
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.21126760563380387 17
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.38732394366197376 32
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.5633802816901436 43
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.7394366197183135 54
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.8450704225352155 69
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.8802816901408494 88
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.8802816901408494 100
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.38732394366197376 33
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.5633802816901436 44
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.7394366197183135 55
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.8450704225352155 70
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.8802816901408494 89
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.8802816901408494 101
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.38732394366197376 34
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.5633802816901436 45
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.7394366197183135 56
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.8450704225352155 71
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.8802816901408494 90
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.8802816901408494 102
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3448898> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.42253521126760774 35
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.5985915492957776 46
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.7746478873239475 57
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.8802816901408494 72
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.9154929577464834 91
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.9154929577464834 103
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.24647887323943785 21
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.42253521126760774 36
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.5985915492957776 47
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.7746478873239475 58
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.8802816901408494 73
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.9154929577464834 92
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.9154929577464834 104
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448898> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.24647887323943785 22
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.42253521126760774 37
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.5985915492957776 48
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.7746478873239475 59
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.8802816901408494 74
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.9154929577464834 93
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.9154929577464834 105
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.24647887323943785 23
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.42253521126760774 38
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.5985915492957776 49
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.7746478873239475 60
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.8802816901408494 75
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.9154929577464834 94
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.9154929577464834 106
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.24647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.42253521126760774 39
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.5985915492957776 50
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.7746478873239475 61
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.8802816901408494 76
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.9154929577464834 95
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.9154929577464834 107
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e871c908> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.1760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.2816901408450718 25
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.4577464788732417 40
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.6338028169014116 51
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.8098591549295815 62
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.9154929577464834 77
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.9507042253521174 96
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.9507042253521174 108
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.1760563380281699 16
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.2816901408450718 26
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.4577464788732417 41
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.6338028169014116 52
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.8098591549295815 63
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.9154929577464834 78
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.9507042253521174 97
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.9507042253521174 109
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #7
root->2->17->7->2->8->1->3
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c908> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.2816901408450718 27
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.4577464788732417 42
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.6338028169014116 53
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.8098591549295815 64
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.9154929577464834 79
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.9507042253521174 98
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.9507042253521174 110
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e48> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c908> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.3169014084507058 28
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.4929577464788757 43
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.6690140845070456 54
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.8450704225352155 65
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.9507042253521174 80
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.9859154929577514 99
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.9859154929577514 111
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34960f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34401d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c908> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.24647887323943785 19
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.3521126760563398 29
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.5281690140845097 44
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.7042253521126796 55
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.8802816901408494 66
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.9859154929577514 81
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 1.0211267605633854 100
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 1.0211267605633854 112
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871c908> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.3521126760563398 30
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.5281690140845097 45
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.7042253521126796 56
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.8802816901408494 67
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.9859154929577514 82
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 1.0211267605633854 101
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 1.0211267605633854 113
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34401d0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871c908> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.24647887323943785 21
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.3521126760563398 31
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.5281690140845097 46
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.7042253521126796 57
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.8802816901408494 68
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.9859154929577514 83
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 1.0211267605633854 102
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 1.0211267605633854 114
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf28> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871c908> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.24647887323943785 22
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.3521126760563398 32
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.5281690140845097 47
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.7042253521126796 58
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.8802816901408494 69
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.9859154929577514 84
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 1.0211267605633854 103
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 1.0211267605633854 115
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c908> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.24647887323943785 23
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.3521126760563398 33
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.5281690140845097 48
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.7042253521126796 59
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.8802816901408494 70
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 0.9859154929577514 85
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 1.0211267605633854 104
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 1.0211267605633854 116
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f348af28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448c88> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c908> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.2816901408450718 24
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.38732394366197376 34
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.5633802816901436 49
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.7394366197183135 60
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.9154929577464834 71
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 1.0211267605633854 86
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 1.0563380281690193 105
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 1.0563380281690193 117
Completed Iteration #21
Best Reward: 0.03521126760563398
coverage_call_count 700
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c908> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.2816901408450718 25
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7b8> 0.38732394366197376 35
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.5633802816901436 50
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace80> 0.7394366197183135 61
backprop <src.mcts.MCTS_Node object at 0x7f249097ca90> 0.9154929577464834 72
backprop <src.mcts.MCTS_Node object at 0x7f23e8673160> 1.0211267605633854 87
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 1.0563380281690193 106
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 1.0563380281690193 118
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #8
root->2->17->7->2->8->1->3->0
Best Reward: 0.03521126760563398
iteration: 4
found coverage increase 0.03521126760563398
Current Total Coverage 11.936619718309858
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2492caeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348abe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348af60> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 11.936619718309858
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34baef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34baef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34706a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 18
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 19
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 20
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 21
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 22
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 23
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 24
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 25
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 26
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 27
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 28
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 29
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 30
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 31
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #1
root->7
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 32
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35129b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 33
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 34
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 19
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 35
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 20
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 36
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 21
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 37
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 22
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 38
Completed Iteration #20
Best Reward: 0.03521126760563398
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 23
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 39
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 24
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 40
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 25
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 41
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #2
root->7->12
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 26
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 42
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 27
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 43
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 28
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 44
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 29
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 45
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 19
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 30
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 46
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 20
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 31
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 47
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 21
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 32
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 48
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #3
root->7->12->8
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 22
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 33
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 49
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 23
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 34
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 50
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 24
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 35
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 51
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.03521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.03521126760563398 25
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.03521126760563398 36
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.03521126760563398 52
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.07042253521126796 18
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.07042253521126796 26
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.07042253521126796 37
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.07042253521126796 53
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.07042253521126796 19
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.07042253521126796 27
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.07042253521126796 38
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.07042253521126796 54
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6128> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543668> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.10563380281690193 20
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.10563380281690193 28
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.10563380281690193 39
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.10563380281690193 55
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.10563380281690193 21
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.10563380281690193 29
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.10563380281690193 40
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.10563380281690193 56
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.10563380281690193 22
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.10563380281690193 30
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.10563380281690193 41
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.10563380281690193 57
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.10563380281690193 23
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.10563380281690193 31
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.10563380281690193 42
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.10563380281690193 58
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.10563380281690193 24
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.10563380281690193 32
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.10563380281690193 43
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.10563380281690193 59
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.10563380281690193 15
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.10563380281690193 25
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.10563380281690193 33
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.10563380281690193 44
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.10563380281690193 60
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.10563380281690193 16
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.10563380281690193 26
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.10563380281690193 34
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.10563380281690193 45
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.10563380281690193 61
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.10563380281690193 17
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.10563380281690193 27
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.10563380281690193 35
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.10563380281690193 46
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.10563380281690193 62
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f352e898> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0c25f8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.1408450704225359 18
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.1408450704225359 28
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.1408450704225359 36
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.1408450704225359 47
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.1408450704225359 63
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243063f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243063f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f354d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.1408450704225359 19
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.1408450704225359 29
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.1408450704225359 37
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.1408450704225359 48
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.1408450704225359 64
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35226d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543668> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.1408450704225359 20
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.1408450704225359 30
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.1408450704225359 38
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.1408450704225359 49
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.1408450704225359 65
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #4
root->7->12->8->15
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.1408450704225359 21
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.1408450704225359 31
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.1408450704225359 39
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.1408450704225359 50
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.1408450704225359 66
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3543c50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.1760563380281699 22
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.1760563380281699 32
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.1760563380281699 40
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.1760563380281699 51
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.1760563380281699 67
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f352e6a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.21126760563380387 23
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.21126760563380387 33
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.21126760563380387 41
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.21126760563380387 52
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.21126760563380387 68
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f243063f8d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.24647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.24647887323943785 34
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.24647887323943785 42
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.24647887323943785 53
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.24647887323943785 69
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.24647887323943785 25
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.24647887323943785 35
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.24647887323943785 43
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.24647887323943785 54
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.24647887323943785 70
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.24647887323943785 26
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.24647887323943785 36
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.24647887323943785 44
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.24647887323943785 55
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.24647887323943785 71
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.24647887323943785 27
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.24647887323943785 37
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.24647887323943785 45
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.24647887323943785 56
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.24647887323943785 72
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.24647887323943785 28
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.24647887323943785 38
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.24647887323943785 46
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.24647887323943785 57
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.24647887323943785 73
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #5
root->7->12->8->15->1
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.24647887323943785 29
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.24647887323943785 39
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.24647887323943785 47
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.24647887323943785 58
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.24647887323943785 74
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c03b160> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.1760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.2816901408450718 30
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.2816901408450718 40
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.2816901408450718 48
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.2816901408450718 59
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.2816901408450718 75
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.1760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.2816901408450718 31
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.2816901408450718 41
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.2816901408450718 49
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.2816901408450718 60
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.2816901408450718 76
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b080> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.1760563380281699 16
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.2816901408450718 32
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.2816901408450718 42
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.2816901408450718 50
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.2816901408450718 61
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.2816901408450718 77
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.2816901408450718 33
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.2816901408450718 43
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.2816901408450718 51
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.2816901408450718 62
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.2816901408450718 78
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c05e240> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35224a8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.3169014084507058 34
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.3169014084507058 44
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.3169014084507058 52
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.3169014084507058 63
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.3169014084507058 79
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.3169014084507058 35
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.3169014084507058 45
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.3169014084507058 53
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.3169014084507058 64
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.3169014084507058 80
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.21126760563380387 20
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.3169014084507058 36
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.3169014084507058 46
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.3169014084507058 54
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.3169014084507058 65
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.3169014084507058 81
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c04dc50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.24647887323943785 21
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.3521126760563398 37
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.3521126760563398 47
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.3521126760563398 55
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.3521126760563398 66
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.3521126760563398 82
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.1760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.24647887323943785 22
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.3521126760563398 38
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.3521126760563398 48
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.3521126760563398 56
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.3521126760563398 67
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.3521126760563398 83
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f35224a8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.1760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.24647887323943785 23
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.3521126760563398 39
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.3521126760563398 49
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.3521126760563398 57
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.3521126760563398 68
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.3521126760563398 84
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.1760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.24647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.3521126760563398 40
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.3521126760563398 50
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.3521126760563398 58
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.3521126760563398 69
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.3521126760563398 85
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #6
root->7->12->8->15->1->0
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.1760563380281699 16
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.24647887323943785 25
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.3521126760563398 41
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.3521126760563398 51
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.3521126760563398 59
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.3521126760563398 70
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.3521126760563398 86
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.24647887323943785 26
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.3521126760563398 42
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.3521126760563398 52
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.3521126760563398 60
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.3521126760563398 71
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.3521126760563398 87
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.1760563380281699 18
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.24647887323943785 27
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.3521126760563398 43
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.3521126760563398 53
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.3521126760563398 61
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.3521126760563398 72
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.3521126760563398 88
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.1760563380281699 19
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.24647887323943785 28
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.3521126760563398 44
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.3521126760563398 54
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.3521126760563398 62
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.3521126760563398 73
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.3521126760563398 89
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.21126760563380387 20
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.2816901408450718 29
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.38732394366197376 45
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.38732394366197376 55
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.38732394366197376 63
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.38732394366197376 74
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.38732394366197376 90
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.21126760563380387 21
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.2816901408450718 30
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.38732394366197376 46
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.38732394366197376 56
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.38732394366197376 64
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.38732394366197376 75
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.38732394366197376 91
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.21126760563380387 22
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.2816901408450718 31
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.38732394366197376 47
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.38732394366197376 57
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.38732394366197376 65
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.38732394366197376 76
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.38732394366197376 92
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.21126760563380387 23
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.2816901408450718 32
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.38732394366197376 48
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.38732394366197376 58
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.38732394366197376 66
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.38732394366197376 77
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.38732394366197376 93
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2492d668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.21126760563380387 24
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.2816901408450718 33
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.38732394366197376 49
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.38732394366197376 59
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.38732394366197376 67
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.38732394366197376 78
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.38732394366197376 94
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e6a0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.21126760563380387 25
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.2816901408450718 34
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.38732394366197376 50
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.38732394366197376 60
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.38732394366197376 68
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.38732394366197376 79
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.38732394366197376 95
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #7
root->7->12->8->15->1->0->1
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f243069f668> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.1408450704225359 15
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.24647887323943785 26
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.3169014084507058 35
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.42253521126760774 51
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.42253521126760774 61
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.42253521126760774 69
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.42253521126760774 80
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.42253521126760774 96
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fba8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.1408450704225359 16
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.24647887323943785 27
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.3169014084507058 36
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.42253521126760774 52
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.42253521126760774 62
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.42253521126760774 70
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.42253521126760774 81
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.42253521126760774 97
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04dd30> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.2816901408450718 28
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.3521126760563398 37
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.4577464788732417 53
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.4577464788732417 63
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.4577464788732417 71
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.4577464788732417 82
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.4577464788732417 98
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23f3522940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04dd30> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.3169014084507058 29
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.38732394366197376 38
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.4929577464788757 54
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.4929577464788757 64
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.4929577464788757 72
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.4929577464788757 83
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.4929577464788757 99
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04dd30> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.3169014084507058 30
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.38732394366197376 39
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.4929577464788757 55
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.4929577464788757 65
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.4929577464788757 73
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.4929577464788757 84
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.4929577464788757 100
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.21126760563380387 20
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.3169014084507058 31
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.38732394366197376 40
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.4929577464788757 56
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.4929577464788757 66
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.4929577464788757 74
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.4929577464788757 85
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.4929577464788757 101
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f23e8665358> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.1760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.24647887323943785 21
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.3521126760563398 32
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.42253521126760774 41
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.5281690140845097 57
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.5281690140845097 67
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.5281690140845097 75
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.5281690140845097 86
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.5281690140845097 102
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fba8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.24647887323943785 22
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.3521126760563398 33
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.42253521126760774 42
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.5281690140845097 58
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.5281690140845097 68
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.5281690140845097 76
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.5281690140845097 87
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.5281690140845097 103
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665438> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.1760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.24647887323943785 23
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.3521126760563398 34
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.42253521126760774 43
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.5281690140845097 59
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.5281690140845097 69
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.5281690140845097 77
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.5281690140845097 88
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.5281690140845097 104
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04dd30> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.24647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.3521126760563398 35
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.42253521126760774 44
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.5281690140845097 60
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.5281690140845097 70
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.5281690140845097 78
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.5281690140845097 89
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.5281690140845097 105
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.1760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.24647887323943785 25
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.3521126760563398 36
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.42253521126760774 45
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.5281690140845097 61
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.5281690140845097 71
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.5281690140845097 79
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.5281690140845097 90
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.5281690140845097 106
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.1760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7f23f352ea90> 0.24647887323943785 26
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.3521126760563398 37
backprop <src.mcts.MCTS_Node object at 0x7f23f34480b8> 0.42253521126760774 46
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae5c0> 0.5281690140845097 62
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae6a0> 0.5281690140845097 72
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.5281690140845097 80
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.5281690140845097 91
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.5281690140845097 107
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #8
root->7->12->8->15->1->0->1->1
Best Reward: 0.03521126760563398
iteration: 6
found coverage increase 0.03521126760563398
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87074e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24909ee7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87390f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87074e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87394e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 11.971830985915492
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34eceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34eceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34eceb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34eceb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34eceb8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34eceb8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b57f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87392e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87395c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c92b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 11.971830985915492
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87076d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a78d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80088d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80088d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80088d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8008748> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 10
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 11
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 12
Completed Iteration #11
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 13
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 14
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.035211267605635754 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 15
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.035211267605635754 6
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 16
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 17
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 18
Completed Iteration #19
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 19
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802be48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 20
Completed Iteration #23
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 21
Completed Iteration #24
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 22
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #0
root
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.035211267605635754 7
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.035211267605635754 23
Completed Iteration #1
Best Reward: 0.035211267605635754
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3630> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3470> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcd30> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 8
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 24
Completed Iteration #3
Best Reward: 0.035211267605635754
Completed Iteration #4
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 9
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 25
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80717f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 10
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 26
Completed Iteration #9
Best Reward: 0.035211267605635754
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 11
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 27
Completed Iteration #11
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 12
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 28
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 13
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 29
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 14
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 30
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 15
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 31
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Completed Iteration #19
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 16
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 32
Completed Iteration #20
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 17
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 33
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 18
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 34
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.035211267605635754 5
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 19
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 35
Completed Iteration #3
Best Reward: 0.035211267605635754
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.035211267605635754 6
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 20
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 36
Completed Iteration #4
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.035211267605635754 7
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 21
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 37
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.035211267605635754 8
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 22
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 38
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.035211267605635754 9
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 23
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 39
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d878be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.035211267605635754 10
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 24
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 40
Completed Iteration #15
Best Reward: 0.035211267605635754
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.035211267605635754 11
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 25
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 41
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.035211267605635754 12
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.07042253521127151 26
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.07042253521127151 42
Completed Iteration #19
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.07042253521127151 13
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.10563380281690726 27
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.10563380281690726 43
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.07042253521127151 14
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.10563380281690726 28
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.10563380281690726 44
Completed Iteration #23
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.07042253521127151 15
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.10563380281690726 29
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.10563380281690726 45
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #2
root->4->0
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7f23e8739b70> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.07042253521127151 5
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.10563380281690726 16
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.14084507042254302 30
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.14084507042254302 46
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.07042253521127151 6
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.10563380281690726 17
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.14084507042254302 31
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.14084507042254302 47
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7f23d878bc18> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b518> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.10563380281690726 7
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.14084507042254302 18
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.17605633802817877 32
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.17605633802817877 48
Completed Iteration #3
Best Reward: 0.035211267605635754
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2860> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.14084507042254302 8
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.17605633802817877 19
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.21126760563381453 33
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.21126760563381453 49
Completed Iteration #12
Best Reward: 0.035211267605635754
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.14084507042254302 9
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.17605633802817877 20
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.21126760563381453 34
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.21126760563381453 50
Completed Iteration #15
Best Reward: 0.035211267605635754
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2e48> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.17605633802817877 10
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.21126760563381453 21
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.24647887323945028 35
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.24647887323945028 51
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4a58> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.21126760563381453 11
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.24647887323945028 22
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.28169014084508603 36
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.28169014084508603 52
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #3
root->4->0->0
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.21126760563381453 12
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.24647887323945028 23
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.28169014084508603 37
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.28169014084508603 53
Completed Iteration #0
Best Reward: 0.035211267605635754
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.10563380281690726 5
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.24647887323945028 13
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.28169014084508603 24
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3169014084507218 38
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3169014084507218 54
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d878b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.10563380281690726 6
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.24647887323945028 14
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.28169014084508603 25
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3169014084507218 39
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3169014084507218 55
Completed Iteration #3
Best Reward: 0.035211267605635754
Completed Iteration #4
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.10563380281690726 7
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.24647887323945028 15
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.28169014084508603 26
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3169014084507218 40
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3169014084507218 56
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.10563380281690726 8
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.24647887323945028 16
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.28169014084508603 27
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3169014084507218 41
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3169014084507218 57
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.10563380281690726 9
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.24647887323945028 17
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.28169014084508603 28
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3169014084507218 42
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3169014084507218 58
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b518> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.10563380281690726 10
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.24647887323945028 18
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.28169014084508603 29
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3169014084507218 43
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3169014084507218 59
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.10563380281690726 11
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.24647887323945028 19
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.28169014084508603 30
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3169014084507218 44
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3169014084507218 60
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.10563380281690726 12
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.24647887323945028 20
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.28169014084508603 31
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3169014084507218 45
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3169014084507218 61
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7f23d873da20> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.14084507042254302 13
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.28169014084508603 21
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.3169014084507218 32
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.35211267605635754 46
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.35211267605635754 62
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7f23d873d630> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 5
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 14
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 22
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 33
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 47
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 63
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #4
root->4->0->0->3
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 6
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 15
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 23
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 34
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 48
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 64
Completed Iteration #0
Best Reward: 0.035211267605635754
Completed Iteration #1
Best Reward: 0.035211267605635754
Completed Iteration #2
Best Reward: 0.035211267605635754
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 7
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 16
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 24
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 35
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 49
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 65
Completed Iteration #4
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 8
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 17
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 25
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 36
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 50
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 66
Completed Iteration #5
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 9
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 18
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 26
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 37
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 51
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 67
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873da20> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 10
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 19
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 27
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 38
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 52
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 68
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 11
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 20
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 28
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 39
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 53
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 69
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 12
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 21
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 29
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 40
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 54
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 70
Completed Iteration #15
Best Reward: 0.035211267605635754
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d630> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 13
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 22
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 30
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 41
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 55
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 71
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #5
root->4->0->0->3->6
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 14
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 23
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 31
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 42
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 56
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 72
Completed Iteration #1
Best Reward: 0.035211267605635754
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 5
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 15
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 24
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 32
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 43
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 57
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 73
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 6
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 16
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 25
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 33
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 44
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 58
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 74
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 7
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 17
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 26
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 34
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 45
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 59
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 75
Completed Iteration #6
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87642b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 8
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 18
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 27
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 35
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 46
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 60
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 76
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87642b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 9
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 19
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 28
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 36
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 47
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 61
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 77
Completed Iteration #9
Best Reward: 0.035211267605635754
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 10
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 20
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 29
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 37
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 48
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 62
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 78
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 11
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 21
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 30
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 38
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 49
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 63
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 79
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 12
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 22
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 31
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 39
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 50
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 64
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 80
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 13
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 23
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 32
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 40
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 51
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 65
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 81
Completed Iteration #19
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 14
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 24
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 33
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 41
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 52
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 66
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 82
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 15
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 25
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 34
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 42
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 53
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 67
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 83
Completed Iteration #22
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873d0f0> 0.035211267605635754 16
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.10563380281690726 26
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc4e0> 0.17605633802817877 35
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.3169014084507218 43
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc550> 0.35211267605635754 54
backprop <src.mcts.MCTS_Node object at 0x7f23e802b4a8> 0.3873239436619933 68
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.3873239436619933 84
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #6
root->4->0->0->3->6->0
Best Reward: 0.035211267605635754
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0.035211267605635754
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717710> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717710> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87342e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87175c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87344a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87175f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86814a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b29e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b29e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2828> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86817f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86fff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86817f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2d68> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86619b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86619b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d97f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80080b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80177b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80170b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80177b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80714a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80179b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2492d1c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d878b0b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243063f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a74e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008eb8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909ee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24909eeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909ee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fe48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909ee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e668> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 2
Completed Iteration #2
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35221d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ed30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f241c05eb70> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35432e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35432e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35432e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35430b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35430b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35432b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522630> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 1900
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f354de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c95f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05e2e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348ac50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35127b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 2000
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34404e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34481d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34404e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34404e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3448518> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e61d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34961d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34961d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3448be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24ebd1a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24306deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2492caeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24306deb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aedd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 20
Completed Iteration #19
Best Reward: 0
coverage_call_count 2100
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2492caeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec160> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08abbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87077f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354db00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34babe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87070f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34bac18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08abba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2492caeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08abba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08abba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87076d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24306754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2492caeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86faf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34407f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3780> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86654e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86739e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86739e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86654e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86659b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8665588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86faf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86840b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86738d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86840b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86840b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8684048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86362e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86362e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86362e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86362e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86faf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8684eb8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8673a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87179e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87179e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c64a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d875dfd0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87346a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87346a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87346a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87646d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87646d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86fff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87645c0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8764630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86fff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86fff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 2700
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86fff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86362e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86362e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 2800
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b45f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b48d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f34a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b48d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4c18> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86faf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306decc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86fad30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab9e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86facc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 20
Completed Iteration #23
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86facc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2430675da0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f35129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35129b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08abe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e871cfd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24306752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24306752e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24306757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24306752e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86faeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8707278> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34481d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34481d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08abe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87645f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f354d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348af98> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352eb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3543b70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86739e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87173c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae630> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243063f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909ee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f243069f780> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243063f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80086d8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243063f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243063f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24306752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243063f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243063f438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243063f438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24306752e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87173c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a70b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a70b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a70b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e8017eb8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87345c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bc50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5cc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87341d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0fd0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243063f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24306756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243063f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 3300
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ac88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8071748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34aea20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5438> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5438> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80176a0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34baa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34405f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f48d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243063f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802bb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802bb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559a5c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87390b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87399e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b47f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b47f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c61d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87390b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34ecc50> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86f4940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3496e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86d94a8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf60> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b555a5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86497b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86497b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86497b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a25c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8684d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86492e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86492e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86492e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86492e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65f98> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e135c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86492e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e136d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86492e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56e48> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e136a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e136a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e136a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 21
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6b38> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e136d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e132e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e132e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e132e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 19
Completed Iteration #19
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6dd8> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796c88> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a20> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47524e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47524e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf588> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5668> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e130b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47020f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47964a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47023c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d74a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47175f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47026a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e132e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47529b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47024a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47965f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 4100
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47965f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47965f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47966d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47966d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47020f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46841d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f58d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46840b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46840b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b473aeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f24a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b473a7f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47024e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46512e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46697b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46697b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4651eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46697f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46697f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e794e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46697f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4669240> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e791d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d873dda0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 4
Completed Iteration #5
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c05e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34bae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c05ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3440c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34baf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86f3588> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8665438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86c64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8665438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d875d828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3440550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86dc6a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e797f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cba58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67cba58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86c68d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8636b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46513c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46513c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8673048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b559aa58> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8717f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87340f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8673048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67840f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b6784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b6784128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4669978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86fa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8636fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86f49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b559ab38> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b46518d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 12.007042253521128
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24909ee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243063f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e81c5978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243063f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86acef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c03bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e86acb38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8734320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8734eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34d6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d8734eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c04d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2430675f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c04d278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2492d1c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8071e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8717ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b559a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc0b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08abe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f348a5f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3448f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e872be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35127b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34481d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2440698be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f24e08abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e872ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f354d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34481d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3448780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34481d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e872bba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8681048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f352efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34707b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34707b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8045b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e87113c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d875dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f24e08ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4651630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d875d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3512be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7400> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 3
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555abe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3512be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8661278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8764828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8707c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8661ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b554a240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d878b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e80b5c88> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f348a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3496898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3543fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e80085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3470c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e8008780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47172b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 12
Completed Iteration #18
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4717f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c03bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8681048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d873df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8017ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e79f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35221d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e4aa90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f35224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3522978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 4900
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e862a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4651240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e862af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f3522320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b472db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b67f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e985c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f352e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d878b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c0a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b472d2e8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b469a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f241c04d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3470da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55f5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f34ec400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b554ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e652e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e653c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e653c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8045940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b559acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4796160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f243069fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4796fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d873d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3522c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f34f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfe48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47020f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d8649a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b554a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47f2f98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47029b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e86dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8711a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46bf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e81c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47bfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47020b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f348a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e98b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af91a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23f3543fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af91a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af91a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af91a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af91a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46764a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46764a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46764a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46845c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4669160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e802b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46764a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4684a58> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e13f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 5200
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23f3496898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23e871ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8649320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b472da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2898> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af91a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af91a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af91a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4702c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f23b47520f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b469a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e67b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4752400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23b4684898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8fff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d8764160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4702d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8910b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af91ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46bfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af91ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af91a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af91a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffeb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 5300
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8008b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4796470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8711a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e65fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4676518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4717e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffcf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8912b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e87399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d87a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8912b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8912b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af856080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8563c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af856828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af856a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8563c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af856588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af856048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8564a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8563c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af856748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af847ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af856400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8475c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8475c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8475c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b473a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8919e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8919e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8475c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d87a2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856cc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4e56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4684dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af856cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b47c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b4676c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af824080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af824390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af856ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8244e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af824978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af824a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8244a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af824da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af824710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8115c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af836518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af836518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8240f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8367f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af824b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af824e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af824128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af8d94a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b472d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af824b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23b473ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86ceb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 20
Completed Iteration #21
Best Reward: 0
coverage_call_count 5500
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c89e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8475f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af891b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af86c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3935c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af856e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af891630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af891b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aab70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3812e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af3aaf60> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e8739f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b46f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3812b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3812b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 5600
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af811f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35d588> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af377400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af377be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af377cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af377e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af377588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4752400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af377438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af377b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af36a9b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b55a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af377128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af836d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af836d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2430675eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af377320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af35de48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af377c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af824a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af381f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 17
Completed Iteration #17
Best Reward: 0
coverage_call_count 5700
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8e10> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3145f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8476a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8476a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af393cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5c88> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af836588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23e802b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 5800
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af377b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23d86b24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af35d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23d86491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af314be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af377fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af252208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af36a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af252780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af252128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af36a5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af252be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af252f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af252908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af252588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2612b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b555a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af252208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2523c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2614e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2523c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2612b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af252ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2612b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2612b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f23af252dd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23b4684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af8d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af824b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af86cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af847ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af393e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af261198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af261400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af261b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af261208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af261748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af33b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af3143c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2166a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af216978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af252828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af228320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af228208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af216da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af216fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af228ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af228a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af228dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af228cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af228c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af228cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af228be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af228a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af228b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af228a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af239898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af239780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af239a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2280f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af228fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af228208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af216048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af239780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216d30> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af216b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2166a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af261da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af228160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af3c8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af314978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2166a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af811908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af35d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af2164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2b4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af33b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af36a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af261b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af228e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af35dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af381c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af261748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f23af2a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f23af216ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f23af216518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 12.007042253521128
initial coverage: 11.7254
time passed (minutes): 60.2056
iterations: 197
number of new inputs: 320
final coverage: 12.007
total coverage increase: 0.28169
