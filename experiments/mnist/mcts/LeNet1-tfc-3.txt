Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='tfc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'tfc'], random_seed=3, runner='mcts', save_batch=False, skip_layers=[0, 5], tc1=<function tc1 at 0x7fb4b48aff28>, tc2=<function tc2 at 0x7fb4b48c0048>, tc3=<function tc3 at 0x7fb4b48c0158>, tfc_subject_layer=-3, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 370
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c136080> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d908> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c121ef0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dfd0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 1 3
Completed Iteration #1
Best Reward: 1
Completed Iteration #2
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121390> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136400> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 1 4
Completed Iteration #3
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c190b38> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121160> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 1 5
Completed Iteration #4
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dbe0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136438> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 1 6
Completed Iteration #5
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d9e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136978> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 2 7
Completed Iteration #6
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d940> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d908> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 2 8
Completed Iteration #7
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121710> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dfd0> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 2 9
Completed Iteration #8
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121358> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dfd0> 1 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 2 10
Completed Iteration #9
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121080> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136e80> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 2 11
Completed Iteration #10
Best Reward: 1
Completed Iteration #11
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c10de80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dd68> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 3 12
Completed Iteration #12
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c136dd8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136438> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 3 13
Completed Iteration #13
Best Reward: 1
Completed Iteration #14
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c1218d0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce6d8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 3 14
Completed Iteration #15
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c10deb8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce6d8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 3 15
Completed Iteration #16
Best Reward: 1
Completed Iteration #17
Best Reward: 1
Completed Iteration #18
Best Reward: 1
Completed Iteration #19
Best Reward: 1
Completed Iteration #20
Best Reward: 1
Completed Iteration #21
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c1212e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121160> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 3 16
Completed Iteration #22
Best Reward: 1
Completed Iteration #23
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c136cf8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136400> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 3 17
Completed Iteration #24
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121898> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121160> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 3 18
Completed Iteration #25
Best Reward: 1
Completed MCTS Level/Depth: #0
root
Best Reward: 1
No reward increase. Abort.
iteration: 0
found coverage increase 1
Current Total Coverage 371
Completed Iteration #0
Best Reward: 0
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c121e10> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121ac8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 3 2
Completed Iteration #1
Best Reward: 3
Completed Iteration #2
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceda0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e76d8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 5 3
Completed Iteration #3
Best Reward: 3
Completed Iteration #4
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cee48> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e76d8> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 7 4
Completed Iteration #5
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136748> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7358> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 9 5
Completed Iteration #6
Best Reward: 3
Completed Iteration #7
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce940> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121ac8> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 12 6
Completed Iteration #8
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce3c8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e74a8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 12 7
Completed Iteration #9
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb4d312d4e0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1900b8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 15 8
Completed Iteration #10
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121be0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e74a8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 17 9
Completed Iteration #11
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cec88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e76d8> 5 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 18 10
Completed Iteration #12
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d5f8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7358> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 20 11
Completed Iteration #13
Best Reward: 3
Completed Iteration #14
Best Reward: 3
Completed Iteration #15
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136ba8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dba8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 22 12
Completed Iteration #16
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136c50> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dba8> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 24 13
Completed Iteration #17
Best Reward: 3
Completed Iteration #18
Best Reward: 3
Completed Iteration #19
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136be0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7358> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 26 14
Completed Iteration #20
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121da0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7358> 8 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 28 15
Completed Iteration #21
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cebe0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121748> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 30 16
Completed Iteration #22
Best Reward: 3
Completed Iteration #23
Best Reward: 3
Completed Iteration #24
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136b70> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1361d0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136c50> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dba8> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 32 17
Completed Iteration #25
Best Reward: 3
Completed MCTS Level/Depth: #0
root
Best Reward: 3
No reward increase. Abort.
iteration: 1
found coverage increase 3
Current Total Coverage 374
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c136d30> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceeb8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 1 2
Completed Iteration #0
Best Reward: 1
Completed Iteration #1
Best Reward: 1
Completed Iteration #2
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceac8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092b00> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 2 3
Completed Iteration #3
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7e10> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092898> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 4 4
Completed Iteration #4
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e71d0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092940> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 5 5
Completed Iteration #5
Best Reward: 2
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c121dd8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092940> 5 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 9 6
Completed Iteration #6
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d630> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092898> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 10 7
Completed Iteration #7
Best Reward: 4
Completed Iteration #8
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7cf8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceeb8> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 10 8
Completed Iteration #9
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c121ba8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092898> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 11 9
Completed Iteration #10
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121860> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121b38> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 11 10
Completed Iteration #11
Best Reward: 4
Completed Iteration #12
Best Reward: 4
Completed Iteration #13
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce390> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceeb8> 1 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 11 11
Completed Iteration #14
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c1215f8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092748> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 11 12
Completed Iteration #15
Best Reward: 4
Completed Iteration #16
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0928d0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092940> 9 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 15 13
Completed Iteration #17
Best Reward: 4
Completed Iteration #18
Best Reward: 4
Completed Iteration #19
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7898> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1214a8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 16 14
Completed Iteration #20
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7668> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092b00> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 17 15
Completed Iteration #21
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7ac8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceeb8> 1 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 17 16
Completed Iteration #22
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c092dd8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092940> 10 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 18 17
Completed Iteration #23
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c121278> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121b38> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 19 18
Completed Iteration #24
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c1216d8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1369b0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce588> 19 19
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 2
found coverage increase 4
Current Total Coverage 378
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c092208> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf550> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 1 2
Completed Iteration #0
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cec18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf550> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 1 3
Completed Iteration #1
Best Reward: 1
Completed Iteration #2
Best Reward: 1
Completed Iteration #3
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa278> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf208> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 3 4
Completed Iteration #4
Best Reward: 2
Completed Iteration #5
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092c50> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf208> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 5 5
Completed Iteration #6
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c092080> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092780> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 5 6
Completed Iteration #7
Best Reward: 2
Completed Iteration #8
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c1217f0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7eb8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 6 7
Completed Iteration #9
Best Reward: 2
Completed Iteration #10
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c092d68> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d978> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 6 8
Completed Iteration #11
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121908> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7eb8> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 6 9
Completed Iteration #12
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aae48> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce550> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 7 10
Completed Iteration #13
Best Reward: 2
Completed Iteration #14
Best Reward: 2
Completed Iteration #15
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c136e48> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf550> 1 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 7 11
Completed Iteration #16
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092358> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf208> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 9 12
Completed Iteration #17
Best Reward: 2
coverage_call_count 100
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c092e80> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce550> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 9 13
Completed Iteration #18
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa470> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf550> 3 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 11 14
Completed Iteration #19
Best Reward: 2
Completed Iteration #20
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c190c18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf550> 3 6
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 11 15
Completed Iteration #21
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c092b70> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce550> 1 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 11 16
Completed Iteration #22
Best Reward: 2
Completed Iteration #23
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7e48> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0921d0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf6d8> 11 17
Completed Iteration #24
Best Reward: 2
Completed Iteration #25
Best Reward: 2
Completed MCTS Level/Depth: #0
root
Best Reward: 2
No reward increase. Abort.
iteration: 3
found coverage increase 2
Current Total Coverage 380
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bffd0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce8d0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 1 2
Completed Iteration #0
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfd30> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0552e8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 3 3
Completed Iteration #1
Best Reward: 2
Completed Iteration #2
Best Reward: 2
Completed Iteration #3
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7978> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0552e8> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 4 4
Completed Iteration #4
Best Reward: 2
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa400> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0552e8> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 7 5
Completed Iteration #5
Best Reward: 3
Completed Iteration #6
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf940> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0552e8> 7 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 8 6
Completed Iteration #7
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092240> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bff98> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 10 7
Completed Iteration #8
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c092860> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055dd8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 10 8
Completed Iteration #9
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c092c88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bff98> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 11 9
Completed Iteration #10
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa6a0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0760f0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 13 10
Completed Iteration #11
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0559b0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055dd8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 13 11
Completed Iteration #12
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055da0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076358> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 15 12
Completed Iteration #13
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c055ef0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0552e8> 8 6
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 16 13
Completed Iteration #14
Best Reward: 3
Completed Iteration #15
Best Reward: 3
Completed Iteration #16
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aaa58> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce8d0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 17 14
Completed Iteration #17
Best Reward: 3
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aac50> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0760f0> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 21 15
Completed Iteration #18
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7b70> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce8d0> 5 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 24 16
Completed Iteration #19
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfe80> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf748> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055da0> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c076358> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 26 17
Completed Iteration #20
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c076c18> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bff98> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 27 18
Completed Iteration #21
Best Reward: 4
Completed Iteration #22
Best Reward: 4
Completed Iteration #23
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aacc0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076358> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cea58> 29 19
Completed Iteration #24
Best Reward: 4
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 4
found coverage increase 4
Current Total Coverage 384
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c055f28> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a668> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 1 2
Completed Iteration #0
Best Reward: 1
Completed Iteration #1
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c076b70> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a668> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 2 3
Completed Iteration #2
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aaef0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121470> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 3 4
Completed Iteration #3
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c076b38> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055d68> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 4 5
Completed Iteration #4
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c076e10> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076e48> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 5 6
Completed Iteration #5
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfbe0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055d68> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 6 7
Completed Iteration #6
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c076198> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a668> 3 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 7 8
Completed Iteration #7
Best Reward: 1
Completed Iteration #8
Best Reward: 1
Completed Iteration #9
Best Reward: 1
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055780> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a668> 6 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 10 9
Completed Iteration #10
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055710> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aa58> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 12 10
Completed Iteration #11
Best Reward: 3
Completed Iteration #12
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c076400> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055d68> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 12 11
Completed Iteration #13
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfe10> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a668> 9 6
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 15 12
Completed Iteration #14
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0764a8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076e48> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 17 13
Completed Iteration #15
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c076978> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076208> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 18 14
Completed Iteration #16
Best Reward: 3
Completed Iteration #17
Best Reward: 3
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0762b0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a668> 13 7
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 22 15
Completed Iteration #18
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c076eb8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfc50> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 25 16
Completed Iteration #19
Best Reward: 4
Completed Iteration #20
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf278> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055d68> 3 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 26 17
Completed Iteration #21
Best Reward: 4
Completed Iteration #22
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aaeb8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121470> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 27 18
Completed Iteration #23
Best Reward: 4
Completed Iteration #24
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092978> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055d68> 5 6
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aac8> 29 19
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 5
found coverage increase 4
Current Total Coverage 388
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa320> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 1 2
Completed Iteration #0
Best Reward: 1
Completed Iteration #1
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfe48> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe80> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 2 3
Completed Iteration #2
Best Reward: 1
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0555c0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076d30> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 5 4
Completed Iteration #3
Best Reward: 3
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0553c8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076d30> 7 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 9 5
Completed Iteration #4
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a7b8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf6a0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 11 6
Completed Iteration #5
Best Reward: 4
Completed Iteration #6
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c00ae80> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076518> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 14 7
Completed Iteration #7
Best Reward: 4
Completed Iteration #8
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a860> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076d30> 10 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 17 8
Completed Iteration #9
Best Reward: 4
Completed Iteration #10
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c00af60> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076d30> 11 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 18 9
Completed Iteration #11
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf4a8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076518> 5 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 20 10
Completed Iteration #12
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fc50> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf208> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 21 11
Completed Iteration #13
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f080> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf400> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 23 12
Completed Iteration #14
Best Reward: 4
Completed Iteration #15
Best Reward: 4
Completed Iteration #16
Best Reward: 4
Reward: 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c00af98> 5 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf6a0> 7 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 28 13
Completed Iteration #17
Best Reward: 5
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a9e8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a9b0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0553c8> 8 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c076d30> 15 6
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 32 14
Completed Iteration #18
Best Reward: 5
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa630> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf208> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 34 15
Completed Iteration #19
Best Reward: 5
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a0f0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8438> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 36 16
Completed Iteration #20
Best Reward: 5
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfef0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf6a0> 9 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 38 17
Completed Iteration #21
Best Reward: 5
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf128> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf6a0> 10 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 39 18
Completed Iteration #22
Best Reward: 5
Completed Iteration #23
Best Reward: 5
Completed Iteration #24
Best Reward: 5
Completed Iteration #25
Best Reward: 5
Completed MCTS Level/Depth: #0
root
Best Reward: 5
No reward increase. Abort.
iteration: 6
found coverage increase 5
Current Total Coverage 393
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c055198> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0558d0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 4 2
Completed Iteration #0
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f128> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d85f8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 5 3
Completed Iteration #1
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c076630> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8208> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 6 4
Completed Iteration #2
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aae80> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0766d8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 9 5
Completed Iteration #3
Best Reward: 4
Completed Iteration #4
Best Reward: 4
Completed Iteration #5
Best Reward: 4
Completed Iteration #6
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347bff28> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0558d0> 7 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 12 6
Completed Iteration #7
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa940> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0558d0> 8 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 13 7
Completed Iteration #8
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfda0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8828> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 16 8
Completed Iteration #9
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfe80> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd68> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 18 9
Completed Iteration #10
Best Reward: 4
coverage_call_count 200
Completed Iteration #11
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf978> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347f0518> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 20 10
Completed Iteration #12
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfe10> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0766d8> 5 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 22 11
Completed Iteration #13
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00ad30> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347f0860> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 24 12
Completed Iteration #14
Best Reward: 4
Completed Iteration #15
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb4347d89b0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8828> 7 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 28 13
Completed Iteration #16
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8d68> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0558d0> 9 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 29 14
Completed Iteration #17
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8e48> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8828> 9 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 31 15
Completed Iteration #18
Best Reward: 4
Completed Iteration #19
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f390> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0558d0> 13 6
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 35 16
Completed Iteration #20
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8ba8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8828> 10 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 36 17
Completed Iteration #21
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8278> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f6d8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 39 18
Completed Iteration #22
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf8d0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d85f8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 40 19
Completed Iteration #23
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf3c8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347f0860> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 41 20
Completed Iteration #24
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f8d0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0766d8> 7 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c055cf8> 43 21
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 7
found coverage increase 4
Current Total Coverage 397
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fcc0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f4a8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 2 2
Completed Iteration #0
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8080> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02ff28> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 2 3
Completed Iteration #1
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fb38> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aa20> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 2 4
Completed Iteration #2
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf5f8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f4a8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 2 5
Completed Iteration #3
Best Reward: 2
Completed Iteration #4
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8b38> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf7f0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 3 6
Completed Iteration #5
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a0f0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf7f0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 4 7
Completed Iteration #6
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfef0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf278> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 5 8
Completed Iteration #7
Best Reward: 2
Completed Iteration #8
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a048> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02ff28> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 7 9
Completed Iteration #9
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8518> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf7f0> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 7 10
Completed Iteration #10
Best Reward: 2
Completed Iteration #11
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a5f8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf7f0> 3 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 8 11
Completed Iteration #12
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfdd8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a828> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 8 12
Completed Iteration #13
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa58> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f4a8> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 8 13
Completed Iteration #14
Best Reward: 2
Completed Iteration #15
Best Reward: 2
Completed Iteration #16
Best Reward: 2
Completed Iteration #17
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8b00> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fc18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 8 14
Completed Iteration #18
Best Reward: 2
Completed Iteration #19
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aa58> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f470> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 8 15
Completed Iteration #20
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c00ab38> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f4a8> 2 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 8 16
Completed Iteration #21
Best Reward: 2
Completed Iteration #22
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8fd0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf278> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 8 17
Completed Iteration #23
Best Reward: 2
Completed Iteration #24
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf630> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf7f0> 3 6
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fa90> 8 18
Completed Iteration #25
Best Reward: 2
Completed MCTS Level/Depth: #0
root
Best Reward: 2
No reward increase. Abort.
iteration: 8
found coverage increase 2
Current Total Coverage 399
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfb70> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0555c0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fe48> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8940> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 0 3
Completed Iteration #2
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f9e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055320> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 0 4
Completed Iteration #3
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c055c50> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076860> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 1 5
Completed Iteration #4
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a898> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055320> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 1 6
Completed Iteration #5
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c055eb8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a550> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 1 7
Completed Iteration #6
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c055d30> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf748> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 1 8
Completed Iteration #7
Best Reward: 1
Completed Iteration #8
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076588> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a550> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 3 9
Completed Iteration #9
Best Reward: 2
Completed Iteration #10
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0551d0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a550> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 3 10
Completed Iteration #11
Best Reward: 2
Completed Iteration #12
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c076be0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076f28> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 3 11
Completed Iteration #13
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f208> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a550> 2 5
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 3 12
Completed Iteration #14
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a320> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076860> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 3 13
Completed Iteration #15
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c076eb8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0559e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 3 14
Completed Iteration #16
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8c88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076860> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 4 15
Completed Iteration #17
Best Reward: 2
Completed Iteration #18
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfe48> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076f28> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 4 16
Completed Iteration #19
Best Reward: 2
Completed Iteration #20
Best Reward: 2
Completed Iteration #21
Best Reward: 2
Completed Iteration #22
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f7b8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf630> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 6 17
Completed Iteration #23
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f828> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf748> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8320> 6 18
Completed Iteration #24
Best Reward: 2
Completed Iteration #25
Best Reward: 2
Completed MCTS Level/Depth: #0
root
Best Reward: 2
No reward increase. Abort.
iteration: 9
found coverage increase 2
Current Total Coverage 401
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f630> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055898> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 1 2
Completed Iteration #0
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aabe0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa780> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 3 3
Completed Iteration #1
Best Reward: 2
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa4a8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aaa90> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 6 4
Completed Iteration #2
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aa90> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aaa90> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 9 5
Completed Iteration #3
Best Reward: 3
Completed Iteration #4
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa2b0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aaa90> 9 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 12 6
Completed Iteration #5
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02f9b0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aaa90> 12 5
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 15 7
Completed Iteration #6
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fcf8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aae48> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 18 8
Completed Iteration #7
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8d30> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0924e0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 21 9
Completed Iteration #8
Best Reward: 3
Completed Iteration #9
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfc18> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092940> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 23 10
Completed Iteration #10
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c6725f8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0924e0> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 26 11
Completed Iteration #11
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb480aecfd0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092da0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 29 12
Completed Iteration #12
Best Reward: 3
Completed Iteration #13
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfa20> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092940> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 31 13
Completed Iteration #14
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf400> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092940> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 33 14
Completed Iteration #15
Best Reward: 3
Completed Iteration #16
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076cf8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076160> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 35 15
Completed Iteration #17
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c02feb8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aaa90> 15 6
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 38 16
Completed Iteration #18
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8f28> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aae48> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 41 17
Completed Iteration #19
Best Reward: 3
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf7f0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0924e0> 10 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 45 18
Completed Iteration #20
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfef0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076160> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 47 19
Completed Iteration #21
Best Reward: 4
Completed Iteration #22
Best Reward: 4
Completed Iteration #23
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aab70> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055898> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 48 20
Completed Iteration #24
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aaef0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa780> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c055630> 50 21
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 10
found coverage increase 4
Current Total Coverage 405
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8e80> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d88d0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa828> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7978> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 1 3
Completed Iteration #1
Best Reward: 1
Completed Iteration #2
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c1cb0b8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7358> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 1 4
Completed Iteration #3
Best Reward: 1
coverage_call_count 300
Completed Iteration #4
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa860> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa358> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 1 5
Completed Iteration #5
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb4d312d1d0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7978> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 2 6
Completed Iteration #6
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7438> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7c18> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 4 7
Completed Iteration #7
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfa20> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa358> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 4 8
Completed Iteration #8
Best Reward: 2
Completed Iteration #9
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c076208> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 4 9
Completed Iteration #10
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aaf60> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7128> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfa20> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa358> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 4 10
Completed Iteration #11
Best Reward: 2
Completed Iteration #12
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c190ba8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7358> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 4 11
Completed Iteration #13
Best Reward: 2
Completed Iteration #14
Best Reward: 2
Completed Iteration #15
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e77f0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7c18> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 5 12
Completed Iteration #16
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c190cf8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d88d0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 5 13
Completed Iteration #17
Best Reward: 2
Completed Iteration #18
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7940> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf3c8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 7 14
Completed Iteration #19
Best Reward: 2
Completed Iteration #20
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8eb8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7358> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 7 15
Completed Iteration #21
Best Reward: 2
Completed Iteration #22
Best Reward: 2
Completed Iteration #23
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c055c18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e75f8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 7 16
Completed Iteration #24
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c1900b8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7550> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347d8550> 8 17
Completed Iteration #25
Best Reward: 2
Completed MCTS Level/Depth: #0
root
Best Reward: 2
No reward increase. Abort.
iteration: 11
found coverage increase 2
Current Total Coverage 407
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c055c88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aba8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 1 2
Completed Iteration #0
Best Reward: 1
Completed Iteration #1
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce978> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce1d0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 2 3
Completed Iteration #2
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf208> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce898> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 4 4
Completed Iteration #3
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0768d0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121240> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 6 5
Completed Iteration #4
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076748> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121860> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 8 6
Completed Iteration #5
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bf828> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121240> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 10 7
Completed Iteration #6
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c092208> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c092c50> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0768d0> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c121240> 5 4
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 11 8
Completed Iteration #7
Best Reward: 2
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0921d0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce898> 5 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 14 9
Completed Iteration #8
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00a710> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121860> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 16 10
Completed Iteration #9
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa630> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121240> 7 5
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 18 11
Completed Iteration #10
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfb70> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aba8> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 20 12
Completed Iteration #11
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa5c0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121860> 5 4
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 21 13
Completed Iteration #12
Best Reward: 3
Completed Iteration #13
Best Reward: 3
Completed Iteration #14
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfe10> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce1d0> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 23 14
Completed Iteration #15
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0aa470> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce898> 7 4
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 25 15
Completed Iteration #16
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0924a8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121208> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 27 16
Completed Iteration #17
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0927f0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121208> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 29 17
Completed Iteration #18
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055f28> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1214a8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 31 18
Completed Iteration #19
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf710> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aba8> 5 4
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 33 19
Completed Iteration #20
Best Reward: 3
Completed Iteration #21
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c076978> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121400> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 35 20
Completed Iteration #22
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055470> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1214a8> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 37 21
Completed Iteration #23
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c190048> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfb38> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 39 22
Completed Iteration #24
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121898> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c00aba8> 7 5
backprop <src.mcts.MCTS_Node object at 0x7fb4347bfd30> 41 23
Completed Iteration #25
Best Reward: 3
Completed MCTS Level/Depth: #0
root
Best Reward: 3
No reward increase. Abort.
iteration: 12
found coverage increase 3
Current Total Coverage 410
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bfb00> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceb00> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf9e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d5f8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 0 3
Completed Iteration #1
Best Reward: 0
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceac8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7f98> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 2 4
Completed Iteration #2
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce6d8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce160> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 2 5
Completed Iteration #3
Best Reward: 2
Completed Iteration #4
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121160> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1217b8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 2 6
Completed Iteration #5
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dd68> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1217b8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 2 7
Completed Iteration #6
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c121e80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d5f8> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 3 8
Completed Iteration #7
Best Reward: 2
Completed Iteration #8
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c1212b0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136e80> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 3 9
Completed Iteration #9
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c147cf8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1217b8> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 3 10
Completed Iteration #10
Best Reward: 2
Completed Iteration #11
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c10df28> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dfd0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 3 11
Completed Iteration #12
Best Reward: 2
Completed Iteration #13
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce208> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136e80> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 3 12
Completed Iteration #14
Best Reward: 2
Completed Iteration #15
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c092e10> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136e80> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 3 13
Completed Iteration #16
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121048> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136400> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 3 14
Completed Iteration #17
Best Reward: 2
Completed Iteration #18
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121ef0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce160> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 3 15
Completed Iteration #19
Best Reward: 2
Completed Iteration #20
Best Reward: 2
Completed Iteration #21
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121ac8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347f0ac8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceac8> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7f98> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 5 16
Completed Iteration #22
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c092668> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceb00> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 5 17
Completed Iteration #23
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c02fac8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136400> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 7 18
Completed Iteration #24
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121e48> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceb00> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ce2b0> 7 19
Completed Iteration #25
Best Reward: 2
Completed MCTS Level/Depth: #0
root
Best Reward: 2
No reward increase. Abort.
iteration: 13
found coverage increase 2
Current Total Coverage 412
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceda0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceba8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c0556a0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055dd8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 1 3
Completed Iteration #1
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0bf278> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347f0c88> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 1 4
Completed Iteration #2
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c136dd8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136518> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 2 5
Completed Iteration #3
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d898> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136518> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 4 6
Completed Iteration #4
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c136a58> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d9e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 4 7
Completed Iteration #5
Best Reward: 2
Completed Iteration #6
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c121550> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1219e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 5 8
Completed Iteration #7
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0926a0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceba8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 7 9
Completed Iteration #8
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c092ba8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0ceba8> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 7 10
Completed Iteration #9
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347f0ba8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347f0c88> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 9 11
Completed Iteration #10
Best Reward: 2
Completed Iteration #11
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136b38> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055dd8> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 11 12
Completed Iteration #12
Best Reward: 2
Completed Iteration #13
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb4347f0390> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777710> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 12 13
Completed Iteration #14
Best Reward: 2
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c136b70> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347f0d68> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 16 14
Completed Iteration #15
Best Reward: 4
Completed Iteration #16
Best Reward: 4
Completed Iteration #17
Best Reward: 4
Completed Iteration #18
Best Reward: 4
Completed Iteration #19
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c092518> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c1219e8> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 16 15
Completed Iteration #20
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c092a90> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347f0c88> 5 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 19 16
Completed Iteration #21
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c121da0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c055dd8> 7 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 23 17
Completed Iteration #22
Best Reward: 4
Completed Iteration #23
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7be0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d9e8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 23 18
Completed Iteration #24
Best Reward: 4
coverage_call_count 400
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d8d0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c136518> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fb45c0cef98> 24 19
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 14
found coverage increase 4
Current Total Coverage 416
Completed Iteration #0
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c1210b8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347f08d0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 0 2
Completed Iteration #1
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb434777b70> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121390> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 1 3
Completed Iteration #2
Best Reward: 1
Completed Iteration #3
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c121588> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434700240> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 1 4
Completed Iteration #4
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c055e80> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347005c0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 1 5
Completed Iteration #5
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d978> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434700e10> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 1 6
Completed Iteration #6
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dcf8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121390> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 2 7
Completed Iteration #7
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c10dc18> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121390> 3 4
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 3 8
Completed Iteration #8
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347770b8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347005c0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 3 9
Completed Iteration #9
Best Reward: 1
Completed Iteration #10
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c10d668> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777da0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 3 10
Completed Iteration #11
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347776d8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777da0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 3 11
Completed Iteration #12
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c1216a0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434700240> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 3 12
Completed Iteration #13
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c136320> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777da0> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 3 13
Completed Iteration #14
Best Reward: 1
Completed Iteration #15
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7ef0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777048> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 3 14
Completed Iteration #16
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fb45c092160> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c121390> 4 5
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 4 15
Completed Iteration #17
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c1219b0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb4347771d0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 4 16
Completed Iteration #18
Best Reward: 1
Completed Iteration #19
Best Reward: 1
Completed Iteration #20
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c10deb8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777da0> 0 5
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 4 17
Completed Iteration #21
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7080> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb45c0e7e80> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 4 18
Completed Iteration #22
Best Reward: 1
Completed Iteration #23
Best Reward: 1
Completed Iteration #24
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fb4347775c0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fb434700e10> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fb434777438> 4 19
Completed Iteration #25
Best Reward: 1
Completed MCTS Level/Depth: #0
root
Best Reward: 1
No reward increase. Abort.
iteration: 15
found coverage increase 1
Current Total Coverage 417
initial coverage: 370
time passed (minutes): 1.22465
iterations: 16
number of new inputs: 1024
final coverage: 417
total coverage increase: 47
