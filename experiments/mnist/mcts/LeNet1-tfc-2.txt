Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='tfc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'tfc'], random_seed=2, runner='mcts', save_batch=False, skip_layers=[0, 5], tc1=<function tc1 at 0x7fa015e0ff28>, tc2=<function tc2 at 0x7fa015e20048>, tc3=<function tc3 at 0x7fa015e20158>, tfc_subject_layer=-3, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 370
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076080> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d908> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061e48> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076400> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 1 3
Completed Iteration #2
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061390> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076320> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 2 4
Completed Iteration #3
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d0b38> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061160> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 3 5
Completed Iteration #4
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dbe0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0761d0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 4 6
Completed Iteration #5
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d9e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061160> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 5 7
Completed Iteration #6
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d940> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076320> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 6 8
Completed Iteration #7
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061710> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076400> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 7 9
Completed Iteration #8
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061358> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0610b8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 8 10
Completed Iteration #9
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614e0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061160> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 9 11
Completed Iteration #10
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04df60> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076400> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 10 12
Completed Iteration #11
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061908> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dfd0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 11 13
Completed Iteration #12
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04da20> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0761d0> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 13 14
Completed Iteration #13
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dba8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076320> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 14 15
Completed Iteration #14
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061ba8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6a0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061358> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0610b8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 15 16
Completed Iteration #15
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04da90> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061160> 4 5
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 16 17
Completed Iteration #16
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061a20> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dc18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 16 18
Completed Iteration #17
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0616d8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dfd0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 17 19
Completed Iteration #18
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dc88> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0761d0> 5 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 19 20
Completed Iteration #19
Best Reward: 2
Completed Iteration #20
Best Reward: 2
Completed Iteration #21
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061128> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061160> 5 6
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 20 21
Completed Iteration #22
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061898> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0610b8> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 21 22
Completed Iteration #23
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076048> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00eb38> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04da20> 4 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0761d0> 7 5
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 23 23
Completed Iteration #24
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061860> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076400> 4 5
backprop <src.mcts.MCTS_Node object at 0x7f9fcc10b0b8> 24 24
Completed Iteration #25
Best Reward: 2
Completed MCTS Level/Depth: #0
root
Best Reward: 2
No reward increase. Abort.
iteration: 0
found coverage increase 2
Current Total Coverage 372
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ef28> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061e10> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fe202cf98> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc1795f8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e10> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061e10> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 3 4
Completed Iteration #3
Best Reward: 3
Completed Iteration #4
Best Reward: 3
Completed Iteration #5
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea90> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061e10> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 3 5
Completed Iteration #6
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ecc0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e2b0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 3 6
Completed Iteration #7
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0767f0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00efd0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 4 7
Completed Iteration #8
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d860> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d0b00> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 5 8
Completed Iteration #9
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0765f8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d0b00> 1 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 5 9
Completed Iteration #10
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076908> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027550> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 6 10
Completed Iteration #11
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d828> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027748> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 6 11
Completed Iteration #12
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d5f8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d780> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 6 12
Completed Iteration #13
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061208> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027550> 1 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 6 13
Completed Iteration #14
Best Reward: 3
Completed Iteration #15
Best Reward: 3
Completed Iteration #16
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d0048> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc1795f8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 6 14
Completed Iteration #17
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d0080> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e2b0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 6 15
Completed Iteration #18
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d898> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d0b00> 1 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 6 16
Completed Iteration #19
Best Reward: 3
Completed Iteration #20
Best Reward: 3
Completed Iteration #21
Best Reward: 3
Completed Iteration #22
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e390> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027748> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 6 17
Completed Iteration #23
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061780> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7518> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0613c8> 6 18
Completed Iteration #24
Best Reward: 3
Completed Iteration #25
Best Reward: 3
Completed MCTS Level/Depth: #0
root
Best Reward: 3
No reward increase. Abort.
iteration: 1
found coverage increase 3
Current Total Coverage 375
Completed Iteration #0
Best Reward: 0
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d7b8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7860> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 2 2
Completed Iteration #1
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d6a0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7860> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 2 3
Completed Iteration #2
Best Reward: 2
Completed Iteration #3
Best Reward: 2
Completed Iteration #4
Best Reward: 2
Completed Iteration #5
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076c50> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7668> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 2 4
Completed Iteration #6
Best Reward: 2
Completed Iteration #7
Best Reward: 2
Completed Iteration #8
Best Reward: 2
Completed Iteration #9
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027cc0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7860> 2 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 2 5
Completed Iteration #10
Best Reward: 2
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00eba8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027da0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 5 6
Completed Iteration #11
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061be0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de4e0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 5 7
Completed Iteration #12
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061198> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7668> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 5 8
Completed Iteration #13
Best Reward: 3
Completed Iteration #14
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e438> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7ba8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 5 9
Completed Iteration #15
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7f98> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7ba8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 5 10
Completed Iteration #16
Best Reward: 3
Completed Iteration #17
Best Reward: 3
Completed Iteration #18
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027ef0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ef60> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 5 11
Completed Iteration #19
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027a58> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ef60> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 5 12
Completed Iteration #20
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0764e0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027e10> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 5 13
Completed Iteration #21
Best Reward: 3
Completed Iteration #22
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027048> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027da0> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 5 14
Completed Iteration #23
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027358> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7668> 0 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 5 15
Completed Iteration #24
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061da0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3518> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e6d8> 5 16
Completed Iteration #25
Best Reward: 3
Completed MCTS Level/Depth: #0
root
Best Reward: 3
No reward increase. Abort.
iteration: 2
found coverage increase 3
Current Total Coverage 378
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47dec18> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076cc0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 2 2
Completed Iteration #0
Best Reward: 2
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d978> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076630> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 5 3
Completed Iteration #1
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47dee10> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e748> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 6 4
Completed Iteration #2
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c73c8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e748> 1 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 6 5
Completed Iteration #3
Best Reward: 3
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061240> 4 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076cc0> 6 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 10 6
Completed Iteration #4
Best Reward: 4
Completed Iteration #5
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c76a0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076d30> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 12 7
Completed Iteration #6
Best Reward: 4
Completed Iteration #7
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00eb00> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c75c0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 14 8
Completed Iteration #8
Best Reward: 4
Completed Iteration #9
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47deda0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3860> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 15 9
Completed Iteration #10
Best Reward: 4
Reward: 6
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de518> 6 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076cc0> 12 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 21 10
Completed Iteration #11
Best Reward: 6
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027080> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7710> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 23 11
Completed Iteration #12
Best Reward: 6
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de588> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3d30> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 24 12
Completed Iteration #13
Best Reward: 6
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47deef0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076cc0> 14 5
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 26 13
Completed Iteration #14
Best Reward: 6
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027c50> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3d30> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 28 14
Completed Iteration #15
Best Reward: 6
Completed Iteration #16
Best Reward: 6
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7128> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e748> 1 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 28 15
Completed Iteration #17
Best Reward: 6
coverage_call_count 100
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7358> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076d30> 5 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 31 16
Completed Iteration #18
Best Reward: 6
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de908> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076cc0> 17 6
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 34 17
Completed Iteration #19
Best Reward: 6
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7eb8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076cc0> 21 7
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 38 18
Completed Iteration #20
Best Reward: 6
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027e80> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076630> 5 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 40 19
Completed Iteration #21
Best Reward: 6
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c71d0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027438> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 41 20
Completed Iteration #22
Best Reward: 6
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7ac8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076630> 8 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 44 21
Completed Iteration #23
Best Reward: 6
Completed Iteration #24
Best Reward: 6
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027ac8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c75c0> 4 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e48> 46 22
Completed Iteration #25
Best Reward: 6
Completed MCTS Level/Depth: #0
root
Best Reward: 6
No reward increase. Abort.
iteration: 3
found coverage increase 6
Current Total Coverage 384
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076518> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797b38> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 3 2
Completed Iteration #0
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3e10> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47970b8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 5 3
Completed Iteration #1
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47dee80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797b38> 4 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 6 4
Completed Iteration #2
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7ef0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7470> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 7 5
Completed Iteration #3
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47def60> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027278> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 8 6
Completed Iteration #4
Best Reward: 3
Completed Iteration #5
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3ef0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797b38> 5 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 9 7
Completed Iteration #6
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47dec50> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f39e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 10 8
Completed Iteration #7
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ded68> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797b38> 6 5
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 11 9
Completed Iteration #8
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de7b8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797b38> 7 6
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 12 10
Completed Iteration #9
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027a90> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027278> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 13 11
Completed Iteration #10
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797b00> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027278> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 14 12
Completed Iteration #11
Best Reward: 3
Completed Iteration #12
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797a58> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027278> 4 5
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 15 13
Completed Iteration #13
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3c88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae278> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 16 14
Completed Iteration #14
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7588> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de550> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 18 15
Completed Iteration #15
Best Reward: 3
Completed Iteration #16
Best Reward: 3
Completed Iteration #17
Best Reward: 3
Completed Iteration #18
Best Reward: 3
Completed Iteration #19
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47dee48> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f39e8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 19 16
Completed Iteration #20
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076828> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae400> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 21 17
Completed Iteration #21
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7470> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 22 18
Completed Iteration #22
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de630> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47970b8> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 23 19
Completed Iteration #23
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de8d0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7470> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 24 20
Completed Iteration #24
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797be0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797b38> 8 7
backprop <src.mcts.MCTS_Node object at 0x7f9fc47979b0> 25 21
Completed Iteration #25
Best Reward: 3
Completed MCTS Level/Depth: #0
root
Best Reward: 3
No reward increase. Abort.
iteration: 4
found coverage increase 3
Current Total Coverage 387
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797668> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797dd8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aea58> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750588> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7550> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750710> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 1 4
Completed Iteration #5
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7b38> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750898> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 1 5
Completed Iteration #6
Best Reward: 1
Completed Iteration #7
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076a58> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797dd8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 1 6
Completed Iteration #8
Best Reward: 1
Completed Iteration #9
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aeef0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 1 7
Completed Iteration #10
Best Reward: 1
Completed Iteration #11
Best Reward: 1
Completed Iteration #12
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027470> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750710> 1 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 1 8
Completed Iteration #13
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7a20> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750898> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 1 9
Completed Iteration #14
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f38d0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 1 10
Completed Iteration #15
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027fd0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750588> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 1 11
Completed Iteration #16
Best Reward: 1
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae9e8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750438> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 4 12
Completed Iteration #17
Best Reward: 3
Completed Iteration #18
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae2e8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797828> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 6 13
Completed Iteration #19
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797c18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797828> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 6 14
Completed Iteration #20
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750470> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750710> 2 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797da0> 7 15
Completed Iteration #21
Best Reward: 3
Completed Iteration #22
Best Reward: 3
Completed Iteration #23
Best Reward: 3
Completed Iteration #24
Best Reward: 3
Completed Iteration #25
Best Reward: 3
Completed MCTS Level/Depth: #0
root
Best Reward: 3
No reward increase. Abort.
iteration: 5
found coverage increase 3
Current Total Coverage 390
Completed Iteration #0
Best Reward: 0
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750c88> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797898> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 3 2
Completed Iteration #1
Best Reward: 3
Completed Iteration #2
Best Reward: 3
Completed Iteration #3
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766a20> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd518> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 4 3
Completed Iteration #4
Best Reward: 3
Completed Iteration #5
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766c88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd828> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 5 4
Completed Iteration #6
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750278> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd9e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 6 5
Completed Iteration #7
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766b00> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae7f0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 7 6
Completed Iteration #8
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766828> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797898> 4 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 8 7
Completed Iteration #9
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766a58> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd4e0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 9 8
Completed Iteration #10
Best Reward: 3
Completed Iteration #11
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae898> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd4e0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 10 9
Completed Iteration #12
Best Reward: 3
Completed Iteration #13
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797f28> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae7f0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 11 10
Completed Iteration #14
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae6a0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae7f0> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 12 11
Completed Iteration #15
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aeb70> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd518> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 13 12
Completed Iteration #16
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae630> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae7f0> 4 5
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 14 13
Completed Iteration #17
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de048> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3f60> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 15 14
Completed Iteration #18
Best Reward: 3
Completed Iteration #19
Best Reward: 3
Completed Iteration #20
Best Reward: 3
Completed Iteration #21
Best Reward: 3
Completed Iteration #22
Best Reward: 3
Completed Iteration #23
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae978> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd518> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae4a8> 16 15
Completed Iteration #24
Best Reward: 3
Completed Iteration #25
Best Reward: 3
Completed MCTS Level/Depth: #0
root
Best Reward: 3
No reward increase. Abort.
iteration: 6
found coverage increase 3
Current Total Coverage 393
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3be0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aeb00> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750d68> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f32e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 0 3
Completed Iteration #1
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750cf8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47106a0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3f28> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710390> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd6a0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710668> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 0 6
Completed Iteration #6
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd860> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47106a0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766320> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766dd8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 1 8
Completed Iteration #9
Best Reward: 1
Completed Iteration #10
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fdf28> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710668> 1 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 2 9
Completed Iteration #11
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750828> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae588> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 2 10
Completed Iteration #12
Best Reward: 1
coverage_call_count 200
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797630> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710898> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 2 11
Completed Iteration #13
Best Reward: 1
Completed Iteration #14
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47970f0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710390> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 2 12
Completed Iteration #15
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd400> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f32e8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 2 13
Completed Iteration #16
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710ba8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766dd8> 1 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 2 14
Completed Iteration #17
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710c88> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766dd8> 1 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 2 15
Completed Iteration #18
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710c18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4714550> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd6a0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710668> 1 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 2 16
Completed Iteration #19
Best Reward: 1
Completed Iteration #20
Best Reward: 1
Completed Iteration #21
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766978> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fdda0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 2 17
Completed Iteration #22
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710a20> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fdda0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 2 18
Completed Iteration #23
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd208> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47664e0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd400> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f32e8> 0 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3358> 2 19
Completed Iteration #24
Best Reward: 1
Completed Iteration #25
Best Reward: 1
Completed MCTS Level/Depth: #0
root
Best Reward: 1
No reward increase. Abort.
iteration: 7
found coverage increase 1
Current Total Coverage 394
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766b38> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750b00> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 1 2
Completed Iteration #0
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd908> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a90> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 2 3
Completed Iteration #1
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710cf8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd160> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 3 4
Completed Iteration #2
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47105f8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750b00> 1 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 3 5
Completed Iteration #3
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750748> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a90> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 4 6
Completed Iteration #4
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fdd68> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47505c0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 5 7
Completed Iteration #5
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766e80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd160> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 6 8
Completed Iteration #6
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47669e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a90> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 7 9
Completed Iteration #7
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750f98> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd160> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 8 10
Completed Iteration #8
Best Reward: 1
Completed Iteration #9
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47106d8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750978> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 9 11
Completed Iteration #10
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766908> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47107b8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 10 12
Completed Iteration #11
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710240> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47107b8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 11 13
Completed Iteration #12
Best Reward: 1
Completed Iteration #13
Best Reward: 1
Completed Iteration #14
Best Reward: 1
Completed Iteration #15
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd2e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47102e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 12 14
Completed Iteration #16
Best Reward: 1
Completed Iteration #17
Best Reward: 1
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710978> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47107b8> 5 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 15 15
Completed Iteration #18
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd898> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47102e8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 16 16
Completed Iteration #19
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae6a0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47505c0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 17 17
Completed Iteration #20
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750c88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aee10> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710cf8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd160> 4 5
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 18 18
Completed Iteration #21
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae438> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766898> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 19 19
Completed Iteration #22
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47104a8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750b00> 2 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 20 20
Completed Iteration #23
Best Reward: 3
Completed Iteration #24
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd128> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a90> 6 5
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750a58> 23 21
Completed Iteration #25
Best Reward: 3
Completed MCTS Level/Depth: #0
root
Best Reward: 3
No reward increase. Abort.
iteration: 8
found coverage increase 3
Current Total Coverage 397
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766be0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766518> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 2 2
Completed Iteration #0
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750128> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47977b8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 4 3
Completed Iteration #1
Best Reward: 2
Completed Iteration #2
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae7f0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797588> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 6 4
Completed Iteration #3
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fdd30> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aef98> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 8 5
Completed Iteration #4
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797978> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797be0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 10 6
Completed Iteration #5
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47974e0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766518> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 11 7
Completed Iteration #6
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766b70> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797be0> 4 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 13 8
Completed Iteration #7
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aea90> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797be0> 6 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 15 9
Completed Iteration #8
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766c18> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3e80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 16 10
Completed Iteration #9
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd358> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797be0> 7 5
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 17 11
Completed Iteration #10
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750eb8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f32b0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 19 12
Completed Iteration #11
Best Reward: 2
Completed Iteration #12
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f35f8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aef98> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 20 13
Completed Iteration #13
Best Reward: 2
Completed Iteration #14
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae780> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797588> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 21 14
Completed Iteration #15
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fda20> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797780> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 22 15
Completed Iteration #16
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797b70> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47977b8> 4 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 24 16
Completed Iteration #17
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797a58> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3e80> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 25 17
Completed Iteration #18
Best Reward: 2
Completed Iteration #19
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797d30> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47deeb8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797b70> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47977b8> 5 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 26 18
Completed Iteration #20
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47975f8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797588> 4 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 27 19
Completed Iteration #21
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd518> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3e80> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 28 20
Completed Iteration #22
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd048> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aef98> 4 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 29 21
Completed Iteration #23
Best Reward: 2
Completed Iteration #24
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47109b0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3e80> 4 5
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766438> 30 22
Completed Iteration #25
Best Reward: 2
Completed MCTS Level/Depth: #0
root
Best Reward: 2
No reward increase. Abort.
iteration: 9
found coverage increase 2
Current Total Coverage 399
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3a58> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3da0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 3 2
Completed Iteration #0
Best Reward: 3
Completed Iteration #1
Best Reward: 3
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc46fd4e0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710630> 4 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 7 3
Completed Iteration #2
Best Reward: 4
Completed Iteration #3
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750d30> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de550> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 8 4
Completed Iteration #4
Best Reward: 4
Completed Iteration #5
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3d68> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de550> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 10 5
Completed Iteration #6
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766780> 4 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750be0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 14 6
Completed Iteration #7
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3e10> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750be0> 5 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 15 7
Completed Iteration #8
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750b38> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3630> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 17 8
Completed Iteration #9
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aedd8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3da0> 4 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 18 9
Completed Iteration #10
Best Reward: 4
Completed Iteration #11
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3908> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47deb70> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 19 10
Completed Iteration #12
Best Reward: 4
Completed Iteration #13
Best Reward: 4
Completed Iteration #14
Best Reward: 4
Completed Iteration #15
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47dee80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710630> 5 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 20 11
Completed Iteration #16
Best Reward: 4
Completed Iteration #17
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aec50> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750be0> 6 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 21 12
Completed Iteration #18
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4750710> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de550> 5 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 23 13
Completed Iteration #19
Best Reward: 4
Completed Iteration #20
Best Reward: 4
Reward: 9
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797908> 9 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710e48> 9 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 32 14
Completed Iteration #21
Best Reward: 9
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797b38> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47deb70> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 33 15
Completed Iteration #22
Best Reward: 9
Completed Iteration #23
Best Reward: 9
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3c88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710e48> 10 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 34 16
Completed Iteration #24
Best Reward: 9
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aea58> 3 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de550> 8 5
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3748> 37 17
Completed Iteration #25
Best Reward: 9
Completed MCTS Level/Depth: #0
root
Best Reward: 9
No reward increase. Abort.
iteration: 10
found coverage increase 9
Current Total Coverage 408
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 6
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7be0> 6 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027518> 6 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 6 2
Completed Iteration #2
Best Reward: 6
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797c50> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0277f0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 7 3
Completed Iteration #3
Best Reward: 6
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fe1fcb438> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797e48> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 8 4
Completed Iteration #4
Best Reward: 6
coverage_call_count 300
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fe202cf98> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027c50> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 9 5
Completed Iteration #5
Best Reward: 6
Reward: 6
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027588> 6 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797e48> 7 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 15 6
Completed Iteration #6
Best Reward: 6
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47deb00> 4 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de898> 4 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 19 7
Completed Iteration #7
Best Reward: 6
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797a90> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797e48> 9 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 21 8
Completed Iteration #8
Best Reward: 6
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3470> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027518> 7 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 22 9
Completed Iteration #9
Best Reward: 6
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa032681160> 4 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de898> 8 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 26 10
Completed Iteration #10
Best Reward: 6
Completed Iteration #11
Best Reward: 6
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027da0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797e48> 10 5
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 27 11
Completed Iteration #12
Best Reward: 6
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027128> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027c50> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 29 12
Completed Iteration #13
Best Reward: 6
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027e48> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00eb00> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 30 13
Completed Iteration #14
Best Reward: 6
Completed Iteration #15
Best Reward: 6
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa0326811d0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027518> 8 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 31 14
Completed Iteration #16
Best Reward: 6
Reward: 7
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7dd8> 7 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027c50> 10 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 38 15
Completed Iteration #17
Best Reward: 7
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47defd0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7898> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 39 16
Completed Iteration #18
Best Reward: 7
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de5c0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00eb00> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 40 17
Completed Iteration #19
Best Reward: 7
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae668> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0277f0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 41 18
Completed Iteration #20
Best Reward: 7
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47504a8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027518> 9 5
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 42 19
Completed Iteration #21
Best Reward: 7
Completed Iteration #22
Best Reward: 7
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7320> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00eb00> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 43 20
Completed Iteration #23
Best Reward: 7
Reward: 7
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d0668> 7 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027518> 16 6
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 50 21
Completed Iteration #24
Best Reward: 7
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47deef0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d0cf8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47decc0> 51 22
Completed Iteration #25
Best Reward: 7
Completed MCTS Level/Depth: #0
root
Best Reward: 7
No reward increase. Abort.
iteration: 11
found coverage increase 7
Current Total Coverage 415
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47972e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ec88> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc1795f8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ec88> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 0 3
Completed Iteration #1
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c73c8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00eb38> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 1 4
Completed Iteration #2
Best Reward: 1
Completed Iteration #3
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d0c18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d00b8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 1 5
Completed Iteration #4
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710dd8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ec88> 0 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 1 6
Completed Iteration #5
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766b00> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00eb38> 1 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 1 7
Completed Iteration #6
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4766470> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3a20> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 2 8
Completed Iteration #7
Best Reward: 1
Completed Iteration #8
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ef28> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e668> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 2 9
Completed Iteration #9
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae400> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0768d0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 2 10
Completed Iteration #10
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae358> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00eb38> 1 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 2 11
Completed Iteration #11
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae320> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e3c8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 3 12
Completed Iteration #12
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076dd8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3a20> 1 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 3 13
Completed Iteration #13
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47ae278> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e3c8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 4 14
Completed Iteration #14
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027e80> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d00b8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 4 15
Completed Iteration #15
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d0d30> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00eb38> 1 5
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 4 16
Completed Iteration #16
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797dd8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e668> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 4 17
Completed Iteration #17
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7d68> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797668> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 5 18
Completed Iteration #18
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47aeef0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47f3a20> 1 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 5 19
Completed Iteration #19
Best Reward: 1
Completed Iteration #20
Best Reward: 1
Completed Iteration #21
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076a90> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e3c8> 2 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 5 20
Completed Iteration #22
Best Reward: 1
Completed Iteration #23
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d05c0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797668> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00ea20> 6 21
Completed Iteration #24
Best Reward: 1
Completed Iteration #25
Best Reward: 1
Completed MCTS Level/Depth: #0
root
Best Reward: 1
No reward increase. Abort.
iteration: 12
found coverage increase 1
Current Total Coverage 416
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de438> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061710> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 1 2
Completed Iteration #0
Best Reward: 1
Completed Iteration #1
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076438> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061358> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 1 3
Completed Iteration #2
Best Reward: 1
Completed Iteration #3
Best Reward: 1
Completed Iteration #4
Best Reward: 1
Completed Iteration #5
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061eb8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061160> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 1 4
Completed Iteration #6
Best Reward: 1
Completed Iteration #7
Best Reward: 1
Completed Iteration #8
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc027748> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061710> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 2 5
Completed Iteration #9
Best Reward: 1
Completed Iteration #10
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04da58> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dd30> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 3 6
Completed Iteration #11
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d828> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dbe0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 5 7
Completed Iteration #12
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061f98> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061710> 4 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 7 8
Completed Iteration #13
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dac8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dd30> 1 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 7 9
Completed Iteration #14
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d860> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061160> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 7 10
Completed Iteration #15
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0276d8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061358> 1 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 8 11
Completed Iteration #16
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0764e0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dbe0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 8 12
Completed Iteration #17
Best Reward: 2
Completed Iteration #18
Best Reward: 2
Completed Iteration #19
Best Reward: 2
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47de3c8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dbe0> 6 4
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 12 13
Completed Iteration #20
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7860> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0616a0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 12 14
Completed Iteration #21
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7e10> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061828> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 12 15
Completed Iteration #22
Best Reward: 4
Completed Iteration #23
Best Reward: 4
Completed Iteration #24
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797710> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076c88> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0614a8> 12 16
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 13
found coverage increase 4
Current Total Coverage 420
Completed Iteration #0
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0d0b38> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4714a90> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 1 2
Completed Iteration #1
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04de80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04db00> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 2 3
Completed Iteration #2
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7a90> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d780> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 2 4
Completed Iteration #3
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0761d0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4714e48> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 4 5
Completed Iteration #4
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d630> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076b70> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 4 6
Completed Iteration #5
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076f28> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4714f28> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 4 7
Completed Iteration #6
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c72e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061d68> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 4 8
Completed Iteration #7
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d5f8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4714a90> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 5 9
Completed Iteration #8
Best Reward: 2
Completed Iteration #9
Best Reward: 2
Completed Iteration #10
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0767b8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04d780> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 7 10
Completed Iteration #11
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076898> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd7f0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 7 11
Completed Iteration #12
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7cf8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061d68> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 7 12
Completed Iteration #13
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c76a0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd7f0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 7 13
Completed Iteration #14
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7f98> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04db00> 3 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 9 14
Completed Iteration #15
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7c88> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd9b0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 9 15
Completed Iteration #16
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47149b0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061d68> 0 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 9 16
Completed Iteration #17
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04ddd8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd7f0> 1 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 10 17
Completed Iteration #18
Best Reward: 2
Completed Iteration #19
Best Reward: 2
Completed Iteration #20
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e470> 2 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4714e48> 4 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 12 18
Completed Iteration #21
Best Reward: 2
Completed Iteration #22
Best Reward: 2
Completed Iteration #23
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7e48> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4714a90> 3 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 13 19
Completed Iteration #24
Best Reward: 2
coverage_call_count 400
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7518> 4 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc4714a90> 7 5
backprop <src.mcts.MCTS_Node object at 0x7f9fc47147b8> 17 20
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 14
found coverage increase 4
Current Total Coverage 424
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd160> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd550> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47970b8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd5f8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 0 3
Completed Iteration #1
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797fd0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc463c6d8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 0 4
Completed Iteration #2
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4797b00> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc463c5c0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 1 5
Completed Iteration #3
Best Reward: 1
Completed Iteration #4
Best Reward: 1
Reward: 7
backprop <src.mcts.MCTS_Node object at 0x7f9fc463c0f0> 7 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc463c2e8> 7 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 8 6
Completed Iteration #5
Best Reward: 7
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fcc076e80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc463c518> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 9 7
Completed Iteration #6
Best Reward: 7
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc463c908> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd320> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 9 8
Completed Iteration #7
Best Reward: 7
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4714400> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc463c2e8> 8 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 10 9
Completed Iteration #8
Best Reward: 7
Completed Iteration #9
Best Reward: 7
Completed Iteration #10
Best Reward: 7
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc47c7d30> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e358> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 10 10
Completed Iteration #11
Best Reward: 7
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4710908> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd5f8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 10 11
Completed Iteration #12
Best Reward: 7
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd240> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc463c6d8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 10 12
Completed Iteration #13
Best Reward: 7
Completed Iteration #14
Best Reward: 7
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc0760f0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e358> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 10 13
Completed Iteration #15
Best Reward: 7
Completed Iteration #16
Best Reward: 7
Completed Iteration #17
Best Reward: 7
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc04dc88> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd5f8> 0 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 10 14
Completed Iteration #18
Best Reward: 7
Completed Iteration #19
Best Reward: 7
Completed Iteration #20
Best Reward: 7
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fc4714e80> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cd320> 0 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 10 15
Completed Iteration #21
Best Reward: 7
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7f9fcc061588> 0 2
backprop <src.mcts.MCTS_Node object at 0x7f9fcc00e358> 0 4
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 10 16
Completed Iteration #22
Best Reward: 7
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7f9fc4714908> 1 2
backprop <src.mcts.MCTS_Node object at 0x7f9fc463c5c0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7f9fc46cde10> 11 17
Completed Iteration #23
Best Reward: 7
Completed Iteration #24
Best Reward: 7
Completed Iteration #25
Best Reward: 7
Completed MCTS Level/Depth: #0
root
Best Reward: 7
No reward increase. Abort.
iteration: 15
found coverage increase 7
Current Total Coverage 431
initial coverage: 370
time passed (minutes): 1.25006
iterations: 16
number of new inputs: 1024
final coverage: 431
total coverage increase: 61
