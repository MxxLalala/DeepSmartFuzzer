Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'kmn'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fd7ca14af28>, tc2=<function tc2 at 0x7fd7ca15b048>, tc3=<function tc3 at 0x7fd7ca15b158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 8.58779
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f32f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 11
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 12
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 13
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 14
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #0
root
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Completed Iteration #2
Best Reward: 0.0190839694656475
Completed Iteration #3
Best Reward: 0.0190839694656475
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 5
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 15
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 6
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 16
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 7
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 17
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eeca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 8
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 18
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f8ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 9
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 19
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 10
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 20
Completed Iteration #14
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 11
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 21
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 12
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 22
Completed Iteration #16
Best Reward: 0.0190839694656475
Completed Iteration #17
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 13
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 23
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 14
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 24
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 15
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 25
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #1
root->7
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Completed Iteration #2
Best Reward: 0.0190839694656475
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 16
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 26
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e92208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 17
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 27
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.0190839694656475 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 18
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0190839694656475 28
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e92940> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92400> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.038167938931295 6
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.038167938931295 19
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.038167938931295 29
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.038167938931295 7
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.038167938931295 20
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.038167938931295 30
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.038167938931295 8
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.038167938931295 21
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.038167938931295 31
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f8b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.038167938931295 9
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.038167938931295 22
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.038167938931295 32
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e9df98> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.0572519083969425 10
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0572519083969425 23
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.0572519083969425 33
Completed Iteration #16
Best Reward: 0.0190839694656475
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.07633587786259 11
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.07633587786259 24
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.07633587786259 34
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.07633587786259 12
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.07633587786259 25
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.07633587786259 35
Completed Iteration #21
Best Reward: 0.0190839694656475
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.07633587786259 13
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.07633587786259 26
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.07633587786259 36
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #2
root->7->16
Best Reward: 0.0190839694656475
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.07633587786259177 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.11450381679388677 14
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.11450381679388677 27
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.11450381679388677 37
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d908> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.09541984732823927 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.13358778625953427 15
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.13358778625953427 28
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.13358778625953427 38
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e92ac8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.11450381679388677 6
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.15267175572518177 16
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.15267175572518177 29
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.15267175572518177 39
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720eecc88> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.13358778625953427 7
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.17175572519082927 17
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.17175572519082927 30
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.17175572519082927 40
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7ef0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.15267175572518177 8
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.19083969465647677 18
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.19083969465647677 31
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.19083969465647677 41
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7978> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.17175572519082927 9
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.20992366412212426 19
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.20992366412212426 32
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.20992366412212426 42
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7b70> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.19083969465647677 10
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.22900763358777176 20
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.22900763358777176 33
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.22900763358777176 43
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e926a0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.20992366412212426 11
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.24809160305341926 21
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.24809160305341926 34
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.24809160305341926 44
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9df98> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.20992366412212426 12
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.24809160305341926 22
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.24809160305341926 35
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.24809160305341926 45
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #3
root->7->16->1
Best Reward: 0.038167938931296774
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e47b70> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47cf8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.05725190839694427 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.22900763358777176 13
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.26717557251906676 23
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.26717557251906676 36
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.26717557251906676 46
Completed Iteration #1
Best Reward: 0.038167938931296774
coverage_call_count 100
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f550> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d358> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.09541984732824105 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.26717557251906854 14
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.30534351145036354 24
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.30534351145036354 37
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.30534351145036354 47
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f940> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d358> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.13358778625953782 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.3053435114503653 15
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.3435114503816603 25
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.3435114503816603 38
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.3435114503816603 48
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e4ff60> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d358> 0.11450381679389032 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.1717557251908346 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.3435114503816621 16
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.3816793893129571 26
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.3816793893129571 39
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.3816793893129571 49
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.20992366412213137 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.38167938931295886 17
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.41984732824425386 27
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.41984732824425386 40
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.41984732824425386 50
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e92160> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.24809160305342814 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.41984732824425564 18
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.45801526717555063 28
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.45801526717555063 41
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.45801526717555063 51
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e9de48> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.11450381679389032 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.2862595419847249 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.4580152671755524 19
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.4961832061068474 29
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.4961832061068474 42
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.4961832061068474 52
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d358> 0.11450381679389032 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.2862595419847249 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.4580152671755524 20
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.4961832061068474 30
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.4961832061068474 43
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.4961832061068474 53
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f6a0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f9e8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.3053435114503724 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.4770992366411999 21
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.5152671755724949 31
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.5152671755724949 44
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.5152671755724949 54
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #4
root->7->16->1->18
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e47940> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.1526717557251871 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.3435114503816692 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.5152671755724967 22
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.5534351145037917 32
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.5534351145037917 45
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.5534351145037917 55
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.1526717557251871 6
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.3435114503816692 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.5152671755724967 23
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.5534351145037917 33
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.5534351145037917 46
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.5534351145037917 56
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bd68> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.1717557251908346 7
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.3625954198473167 14
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.5343511450381442 24
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.5725190839694392 34
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.5725190839694392 47
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.5725190839694392 57
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bcf8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.1908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.3816793893129642 15
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.5534351145037917 25
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.5916030534350867 35
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.5916030534350867 48
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.5916030534350867 58
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.1908396946564821 9
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.3816793893129642 16
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.5534351145037917 26
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.5916030534350867 36
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.5916030534350867 49
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.5916030534350867 59
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e478d0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.2099236641221296 10
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.4007633587786117 17
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.5725190839694392 27
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.6106870229007342 37
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.6106870229007342 50
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.6106870229007342 60
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b4a8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.24809160305342637 11
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.43893129770990846 18
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.610687022900736 28
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.648854961832031 38
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.648854961832031 51
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.648854961832031 61
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.24809160305342637 12
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.43893129770990846 19
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.610687022900736 29
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.648854961832031 39
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.648854961832031 52
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.648854961832031 62
Completed Iteration #22
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.24809160305342637 13
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.43893129770990846 20
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.610687022900736 30
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.648854961832031 40
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.648854961832031 53
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.648854961832031 63
Completed Iteration #23
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e92198> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.28625954198472314 14
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.47709923664120524 21
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.6488549618320327 31
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.6870229007633277 41
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.6870229007633277 54
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.6870229007633277 64
Completed Iteration #24
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d630> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7eb8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b4a8> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3244274809160199 15
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.515267175572502 22
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.6870229007633295 32
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.7251908396946245 42
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.7251908396946245 55
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.7251908396946245 65
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #5
root->7->16->1->18->0
Best Reward: 0.038167938931296774
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.07633587786259355 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3244274809160199 16
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.515267175572502 23
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.6870229007633295 33
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.7251908396946245 43
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.7251908396946245 56
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.7251908396946245 66
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.07633587786259355 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3244274809160199 17
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.515267175572502 24
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.6870229007633295 34
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.7251908396946245 44
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.7251908396946245 57
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.7251908396946245 67
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd72019ab38> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a860> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.09541984732824105 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3435114503816674 18
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.5343511450381495 25
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.706106870228977 35
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.744274809160272 45
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.744274809160272 58
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.744274809160272 68
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.09541984732824105 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3435114503816674 19
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.5343511450381495 26
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.706106870228977 36
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.744274809160272 46
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.744274809160272 59
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.744274809160272 69
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.09541984732824105 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3435114503816674 20
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.5343511450381495 27
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.706106870228977 37
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.744274809160272 47
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.744274809160272 60
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.744274809160272 70
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.09541984732824105 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3435114503816674 21
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.5343511450381495 28
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.706106870228977 38
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.744274809160272 48
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.744274809160272 61
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.744274809160272 71
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.09541984732824105 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3435114503816674 22
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.5343511450381495 29
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.706106870228977 39
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.744274809160272 49
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.744274809160272 62
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.744274809160272 72
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47278> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.11450381679388855 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3625954198473149 23
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.553435114503797 30
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.7251908396946245 40
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.7633587786259195 50
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.7633587786259195 63
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.7633587786259195 73
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #6
root->7->16->1->18->0->0
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.038167938931296774 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.11450381679388855 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3625954198473149 24
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.553435114503797 31
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.7251908396946245 41
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.7633587786259195 51
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.7633587786259195 64
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.7633587786259195 74
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.038167938931296774 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.11450381679388855 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3625954198473149 25
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.553435114503797 32
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.7251908396946245 42
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.7633587786259195 52
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.7633587786259195 65
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.7633587786259195 75
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.038167938931296774 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.11450381679388855 14
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3625954198473149 26
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.553435114503797 33
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.7251908396946245 43
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.7633587786259195 53
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.7633587786259195 66
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.7633587786259195 76
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.038167938931296774 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.11450381679388855 15
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.3625954198473149 27
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.553435114503797 34
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.7251908396946245 44
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.7633587786259195 54
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.7633587786259195 67
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.7633587786259195 77
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.07633587786259355 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.15267175572518532 16
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.4007633587786117 28
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.5916030534350938 35
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.7633587786259213 45
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.8015267175572163 55
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.8015267175572163 68
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.8015267175572163 78
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.07633587786259355 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.15267175572518532 17
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.4007633587786117 29
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.5916030534350938 36
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.7633587786259213 46
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.8015267175572163 56
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.8015267175572163 69
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.8015267175572163 79
Completed Iteration #19
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.07633587786259355 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.15267175572518532 18
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.4007633587786117 30
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.5916030534350938 37
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.7633587786259213 47
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.8015267175572163 57
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.8015267175572163 70
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.8015267175572163 80
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fb70> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.11450381679389032 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.1908396946564821 19
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.43893129770990846 31
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.6297709923663906 38
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.801526717557218 48
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.839694656488513 58
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.839694656488513 71
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.839694656488513 81
Completed Iteration #22
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.11450381679389032 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.1908396946564821 20
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.43893129770990846 32
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.6297709923663906 39
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.801526717557218 49
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.839694656488513 59
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.839694656488513 72
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.839694656488513 82
Completed Iteration #23
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa58> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fb70> 0.05725190839694427 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.13358778625953782 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.2099236641221296 21
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.45801526717555596 33
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.6488549618320381 40
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.8206106870228655 50
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.8587786259541605 60
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.8587786259541605 73
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.8587786259541605 83
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #7
root->7->16->1->18->0->0->8
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd7201a62e8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6b00> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.05725190839694427 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.15267175572518532 14
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.2290076335877771 22
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.47709923664120346 34
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.6679389312976856 41
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.839694656488513 51
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.877862595419808 61
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.877862595419808 74
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.877862595419808 84
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd7201bebe0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6b00> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.07633587786259177 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.17175572519083282 15
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.2480916030534246 23
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.49618320610685096 35
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.687022900763333 42
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.8587786259541605 52
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.8969465648854555 62
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.8969465648854555 75
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.8969465648854555 85
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb198> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6b00> 0.07633587786259177 4
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.11450381679388855 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.2099236641221296 16
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.28625954198472137 24
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.5343511450381477 36
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.7251908396946298 43
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.8969465648854573 53
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.9351145038167523 63
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.9351145038167523 76
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.9351145038167523 86
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720158630> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158358> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.13358778625953605 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.2290076335877771 17
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.30534351145036887 25
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.5534351145037952 37
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.7442748091602773 44
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.9160305343511048 54
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.9541984732823998 64
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.9541984732823998 77
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.9541984732823998 87
Completed Iteration #5
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.13358778625953605 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.2290076335877771 18
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.30534351145036887 26
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.5534351145037952 38
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.7442748091602773 45
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.9160305343511048 55
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.9541984732823998 65
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.9541984732823998 78
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.9541984732823998 88
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158358> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.13358778625953605 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.2290076335877771 19
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.30534351145036887 27
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.5534351145037952 39
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.7442748091602773 46
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.9160305343511048 56
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.9541984732823998 66
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.9541984732823998 79
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.9541984732823998 89
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f080> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158438> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.15267175572518354 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.2480916030534246 20
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.32442748091601636 28
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.5725190839694427 40
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.7633587786259248 47
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.9351145038167523 57
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.9732824427480473 67
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.9732824427480473 80
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.9732824427480473 90
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.15267175572518354 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.2480916030534246 21
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.32442748091601636 29
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.5725190839694427 41
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.7633587786259248 48
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.9351145038167523 58
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.9732824427480473 68
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.9732824427480473 81
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.9732824427480473 91
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.15267175572518354 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.2480916030534246 22
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.32442748091601636 30
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.5725190839694427 42
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.7633587786259248 49
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.9351145038167523 59
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.9732824427480473 69
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.9732824427480473 82
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.9732824427480473 92
Completed Iteration #12
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201bedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.15267175572518354 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.2480916030534246 23
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.32442748091601636 31
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.5725190839694427 43
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.7633587786259248 50
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.9351145038167523 60
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.9732824427480473 70
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.9732824427480473 83
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.9732824427480473 93
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.15267175572518354 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e47e80> 0.2480916030534246 24
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d780> 0.32442748091601636 32
backprop <src.mcts.MCTS_Node object at 0x7fd720e47ef0> 0.5725190839694427 44
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7048> 0.7633587786259248 51
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db38> 0.9351145038167523 61
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c50> 0.9732824427480473 71
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.9732824427480473 84
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ea58> 0.9732824427480473 94
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #8
root->7->16->1->18->0->0->8->0
Best Reward: 0.038167938931296774
iteration: 0
found coverage increase 0.038167938931296774
Current Total Coverage 8.625954198473282
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201586a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f32c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201586a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 8.625954198473282
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72018c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 8.625954198473282
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201402e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201402e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd7201400b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 8.625954198473282
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 300
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200eaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200eaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 8.625954198473282
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201becf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201becf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 8.625954198473282
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7201007b8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.019083969465649275 2
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.019083969465649275 3
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.019083969465649275 4
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.019083969465649275 5
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.019083969465649275 6
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.019083969465649275 7
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200a34a8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100e80> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.03816793893129855 8
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201002e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.03816793893129855 9
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720100fd0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100e80> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.057251908396947826 10
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.057251908396947826 11
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100e80> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.057251908396947826 12
Completed Iteration #13
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.057251908396947826 13
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72012a978> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.0763358778625971 14
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.0763358778625971 15
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.0763358778625971 16
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3a58> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.09541984732824638 17
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3a20> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100710> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.11450381679389565 18
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #0
root
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.11450381679389565 19
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3f60> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.0763358778625971 6
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.13358778625954493 20
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201409b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.0763358778625971 7
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.13358778625954493 21
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.0763358778625971 8
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.13358778625954493 22
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.0763358778625971 9
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.13358778625954493 23
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.09541984732824638 10
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.1526717557251942 24
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.09541984732824638 11
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.1526717557251942 25
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.09541984732824638 12
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.1526717557251942 26
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.09541984732824638 13
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.1526717557251942 27
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.09541984732824638 14
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.1526717557251942 28
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1780> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.11450381679389565 15
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.17175572519084348 29
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.11450381679389565 16
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.17175572519084348 30
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf780> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.13358778625954493 17
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.19083969465649275 31
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.13358778625954493 18
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.19083969465649275 32
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.13358778625954493 19
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.19083969465649275 33
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.13358778625954493 20
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.19083969465649275 34
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201409b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.13358778625954493 21
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.19083969465649275 35
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #1
root->3
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.1526717557251942 22
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.20992366412214203 36
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.1526717557251942 23
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.20992366412214203 37
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3da0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3b38> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.17175572519084348 24
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.2290076335877913 38
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfc18> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.0763358778625971 6
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.19083969465649275 25
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.24809160305344058 39
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfa58> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf630> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.09541984732824638 7
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.20992366412214203 26
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.26717557251908985 40
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
coverage_call_count 400
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72017e6d8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3320> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3da0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3b38> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.11450381679389565 8
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.2290076335877913 27
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.28625954198473913 41
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.11450381679389565 9
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.2290076335877913 28
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.28625954198473913 42
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720140c18> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.0763358778625971 5
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.13358778625954493 10
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.24809160305344058 29
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.3053435114503884 43
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72012a2e8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a4a8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.1526717557251942 11
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.26717557251908985 30
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.3244274809160377 44
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200d83c8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.09541984732824638 6
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.17175572519084348 12
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.28625954198473913 31
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.34351145038168696 45
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72018cf28> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3b38> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.19083969465649275 13
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.3053435114503884 32
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.36259541984733623 46
Completed Iteration #13
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3668> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a4a8> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.20992366412214203 14
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.3244274809160377 33
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.3816793893129855 47
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a4a8> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.20992366412214203 15
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.3244274809160377 34
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.3816793893129855 48
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200c11d0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a4a8> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.2290076335877913 16
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.34351145038168696 35
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.4007633587786348 49
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72012af28> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a4a8> 0.0763358778625971 6
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.24809160305344058 17
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.36259541984733623 36
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.41984732824428406 50
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72005b748> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf828> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.26717557251908985 18
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.3816793893129855 37
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.43893129770993333 51
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #2
root->3->3
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf048> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.11450381679389565 7
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.28625954198473913 19
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.4007633587786348 38
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.4580152671755826 52
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72018c4e0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.13358778625954493 8
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.3053435114503884 20
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.41984732824428406 39
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.4770992366412319 53
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.13358778625954493 9
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.3053435114503884 21
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.41984732824428406 40
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.4770992366412319 54
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.13358778625954493 10
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.3053435114503884 22
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.41984732824428406 41
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.4770992366412319 55
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.13358778625954493 11
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.3053435114503884 23
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.41984732824428406 42
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.4770992366412319 56
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200b34a8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.1526717557251942 12
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.3244274809160377 24
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.43893129770993333 43
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.49618320610688116 57
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72005bb00> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.17175572519084348 13
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.34351145038168696 25
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.4580152671755826 44
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.5152671755725304 58
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72005be80> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.19083969465649275 14
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.36259541984733623 26
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.4770992366412319 45
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.5343511450381797 59
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72005bdd8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.20992366412214203 15
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.3816793893129855 27
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.49618320610688116 46
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.553435114503829 60
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.20992366412214203 16
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.3816793893129855 28
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.49618320610688116 47
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.553435114503829 61
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720080a90> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.2290076335877913 17
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.4007633587786348 29
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.5152671755725304 48
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.5725190839694783 62
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720080e10> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.24809160305344058 18
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.41984732824428406 30
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.5343511450381797 49
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.5916030534351275 63
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720080da0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080b00> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.26717557251908985 19
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.43893129770993333 31
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.553435114503829 50
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.6106870229007768 64
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080a90> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.26717557251908985 20
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.43893129770993333 32
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.553435114503829 51
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.6106870229007768 65
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #3
root->3->3->0
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720080d68> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008c390> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.0763358778625971 5
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.28625954198473913 21
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.4580152671755826 33
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.5725190839694783 52
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.6297709923664261 66
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1710> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.11450381679389388 6
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.3244274809160359 22
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.4961832061068794 34
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.610687022900775 53
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.6679389312977229 67
Completed Iteration #5
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720080ef0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf630> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.13358778625954315 7
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.3435114503816852 23
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.5152671755725287 35
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.6297709923664243 54
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.6870229007633721 68
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720080278> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf630> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.15267175572519243 8
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.36259541984733445 24
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.5343511450381779 36
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.6488549618320736 55
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.7061068702290214 69
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1f98> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf630> 0.0763358778625971 5
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.1717557251908417 9
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.38167938931298373 25
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.5534351145038272 37
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.6679389312977229 56
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.7251908396946707 70
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72005b390> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080b00> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.19083969465649098 10
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.400763358778633 26
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.5725190839694765 38
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.6870229007633721 57
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.74427480916032 71
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7201008d0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140d68> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.20992366412214025 11
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.4198473282442823 27
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.5916030534351258 39
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.7061068702290214 58
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.7633587786259692 72
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Reward: 0.057251908396947826
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.057251908396947826 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.0954198473282446 3
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.2671755725190881 12
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.4770992366412301 28
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.6488549618320736 40
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.7633587786259692 59
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.8206106870229171 73
Completed Iteration #19
Best Reward: 0.057251908396947826
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.2671755725190881 13
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.4770992366412301 29
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.6488549618320736 41
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.7633587786259692 60
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.8206106870229171 74
Completed Iteration #20
Best Reward: 0.057251908396947826
Completed Iteration #21
Best Reward: 0.057251908396947826
Completed Iteration #22
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72002aba8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.11450381679389388 4
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.28625954198473735 14
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.4961832061068794 30
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.6679389312977229 42
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.7824427480916185 61
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.8396946564885663 75
Completed Iteration #23
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72002af98> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.13358778625954315 5
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.30534351145038663 15
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.5152671755725287 31
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.6870229007633721 43
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.8015267175572678 62
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.8587786259542156 76
Completed Iteration #24
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72002af28> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140d68> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.3244274809160359 16
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.5343511450381779 32
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.7061068702290214 44
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.8206106870229171 63
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.8778625954198649 77
Completed Iteration #25
Best Reward: 0.057251908396947826
Completed MCTS Level/Depth: #4
root->3->3->0->19
Best Reward: 0.057251908396947826
Completed Iteration #0
Best Reward: 0.057251908396947826
Completed Iteration #1
Best Reward: 0.057251908396947826
Completed Iteration #2
Best Reward: 0.057251908396947826
Completed Iteration #3
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720080a20> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.15267175572519243 6
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.3435114503816852 17
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.5534351145038272 33
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.7251908396946707 45
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.8396946564885663 64
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.8969465648855142 78
Completed Iteration #4
Best Reward: 0.057251908396947826
Completed Iteration #5
Best Reward: 0.057251908396947826
Completed Iteration #6
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200809e8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.1717557251908417 7
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.36259541984733445 18
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.5725190839694765 34
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.74427480916032 46
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.8587786259542156 65
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.9160305343511634 79
Completed Iteration #7
Best Reward: 0.057251908396947826
Completed Iteration #8
Best Reward: 0.057251908396947826
Completed Iteration #9
Best Reward: 0.057251908396947826
Completed Iteration #10
Best Reward: 0.057251908396947826
Completed Iteration #11
Best Reward: 0.057251908396947826
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd72008c8d0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.20992366412213848 8
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.40076335877863123 19
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.6106870229007733 35
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.7824427480916167 47
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.8969465648855124 66
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.9541984732824602 80
Completed Iteration #12
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72008c908> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.22900763358778775 9
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.4198473282442805 20
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.6297709923664225 36
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.801526717557266 48
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.9160305343511617 67
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.9732824427481095 81
Completed Iteration #13
Best Reward: 0.057251908396947826
Completed Iteration #14
Best Reward: 0.057251908396947826
Completed Iteration #15
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720044550> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.24809160305343703 10
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.4389312977099298 21
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.6488549618320718 37
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.8206106870229153 49
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.9351145038168109 68
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 0.9923664122137588 82
Completed Iteration #16
Best Reward: 0.057251908396947826
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd72005ba20> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044278> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002aba8> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.2862595419847338 11
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.47709923664122655 22
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.6870229007633686 38
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.8587786259542121 50
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.9732824427481077 69
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.0305343511450555 83
Completed Iteration #17
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720158cc0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.3053435114503831 12
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.49618320610687583 23
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.7061068702290179 39
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.8778625954198613 51
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 0.992366412213757 70
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.0496183206107048 84
Completed Iteration #18
Best Reward: 0.057251908396947826
Completed Iteration #19
Best Reward: 0.057251908396947826
Completed Iteration #20
Best Reward: 0.057251908396947826
Completed Iteration #21
Best Reward: 0.057251908396947826
Completed Iteration #22
Best Reward: 0.057251908396947826
Completed Iteration #23
Best Reward: 0.057251908396947826
Completed Iteration #24
Best Reward: 0.057251908396947826
Completed Iteration #25
Best Reward: 0.057251908396947826
Completed MCTS Level/Depth: #5
root->3->3->0->19->5
Best Reward: 0.057251908396947826
Reward: 0.057251908396947826
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.057251908396947826 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.057251908396947826 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.11450381679389565 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.3625954198473309 13
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.5534351145038237 24
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.7633587786259657 40
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.9351145038168092 52
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.0496183206107048 71
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.1068702290076526 85
Completed Iteration #0
Best Reward: 0.057251908396947826
Completed Iteration #1
Best Reward: 0.057251908396947826
Completed Iteration #2
Best Reward: 0.057251908396947826
Completed Iteration #3
Best Reward: 0.057251908396947826
Completed Iteration #4
Best Reward: 0.057251908396947826
Completed Iteration #5
Best Reward: 0.057251908396947826
Completed Iteration #6
Best Reward: 0.057251908396947826
Reward: 0.057251908396947826
backprop <src.mcts.MCTS_Node object at 0x7fd72004ed30> 0.057251908396947826 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.11450381679389565 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.17175572519084348 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.41984732824427873 14
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.6106870229007715 25
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.8206106870229135 41
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 0.992366412213757 53
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.1068702290076526 72
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.1641221374046005 86
Completed Iteration #7
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72004eda0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e4a8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.19083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.438931297709928 15
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.6297709923664208 26
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.8396946564885628 42
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.0114503816794063 54
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.125954198473302 73
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.1832061068702497 87
Completed Iteration #8
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7963e9f98> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200806d8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.20992366412214203 6
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.4580152671755773 16
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.64885496183207 27
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.8587786259542121 43
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.0305343511450555 55
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.1450381679389512 74
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.202290076335899 88
Completed Iteration #9
Best Reward: 0.057251908396947826
Completed Iteration #10
Best Reward: 0.057251908396947826
Completed Iteration #11
Best Reward: 0.057251908396947826
coverage_call_count 500
Completed Iteration #12
Best Reward: 0.057251908396947826
Completed Iteration #13
Best Reward: 0.057251908396947826
Completed Iteration #14
Best Reward: 0.057251908396947826
Completed Iteration #15
Best Reward: 0.057251908396947826
Completed Iteration #16
Best Reward: 0.057251908396947826
Completed Iteration #17
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720f48278> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.13358778625954493 4
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.2290076335877913 7
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.47709923664122655 17
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.6679389312977193 28
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.8778625954198613 44
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.0496183206107048 56
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.1641221374046005 75
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.2213740458015483 89
Completed Iteration #18
Best Reward: 0.057251908396947826
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720f482e8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bd30> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.2671755725190881 8
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.5152671755725233 18
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.7061068702290161 29
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.9160305343511581 45
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.0877862595420016 57
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.2022900763358972 76
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.259541984732845 90
Completed Iteration #19
Best Reward: 0.057251908396947826
Completed Iteration #20
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7963132b0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7963135f8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.28625954198473735 9
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.5343511450381726 19
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.7251908396946654 30
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.9351145038168074 46
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.1068702290076509 58
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.2213740458015465 77
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.2786259541984943 91
Completed Iteration #21
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca4e0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bd30> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.30534351145038663 10
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.5534351145038219 20
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.7442748091603146 31
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.9541984732824567 47
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.1259541984733001 59
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.2404580152671958 78
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.2977099236641436 92
Completed Iteration #22
Best Reward: 0.057251908396947826
Completed Iteration #23
Best Reward: 0.057251908396947826
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3b70> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e4a8> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.3435114503816834 11
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.5916030534351187 21
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.7824427480916114 32
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 0.9923664122137534 48
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.164122137404597 60
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.2786259541984926 79
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.3358778625954404 93
Completed Iteration #24
Best Reward: 0.057251908396947826
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1278> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd7963135f8> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.3816793893129802 12
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.6297709923664154 22
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.8206106870229082 33
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.0305343511450502 49
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.2022900763358937 61
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.3167938931297893 80
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.3740458015267372 94
Completed Iteration #25
Best Reward: 0.057251908396947826
Completed MCTS Level/Depth: #6
root->3->3->0->19->5->19
Best Reward: 0.057251908396947826
Completed Iteration #0
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200ead68> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.1526717557251942 5
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.40076335877862945 13
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.6488549618320647 23
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.8396946564885575 34
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.0496183206106995 50
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.221374045801543 62
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.3358778625954386 81
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.3931297709923864 95
Completed Iteration #1
Best Reward: 0.057251908396947826
Reward: 0.057251908396947826
backprop <src.mcts.MCTS_Node object at 0x7fd7200eaba8> 0.057251908396947826 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.20992366412214203 6
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.4580152671755773 14
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.7061068702290125 24
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.8969465648855053 35
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.1068702290076473 51
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.2786259541984908 63
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.3931297709923864 82
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.4503816793893343 96
Completed Iteration #2
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200eaf98> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea588> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ead68> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.2290076335877913 7
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.47709923664122655 15
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.7251908396946618 25
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.9160305343511546 36
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.1259541984732966 52
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.29770992366414 64
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.4122137404580357 83
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.4694656488549835 97
Completed Iteration #3
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca438> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd796313358> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004ed30> 0.0763358778625971 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.24809160305344058 8
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.49618320610687583 16
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.7442748091603111 26
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.9351145038168038 37
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.1450381679389459 53
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.3167938931297893 65
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.431297709923685 84
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.4885496183206328 98
Completed Iteration #4
Best Reward: 0.057251908396947826
Reward: 0.057251908396947826
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3080> 0.057251908396947826 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.3053435114503884 9
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.5534351145038237 17
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.8015267175572589 27
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 0.9923664122137517 38
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.2022900763358937 54
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.3740458015267372 66
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.4885496183206328 85
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.5458015267175806 99
Completed Iteration #5
Best Reward: 0.057251908396947826
Completed Iteration #6
Best Reward: 0.057251908396947826
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea6a0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.3435114503816852 10
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.5916030534351204 18
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.8396946564885557 28
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.0305343511450484 39
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.2404580152671905 55
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.412213740458034 67
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.5267175572519296 86
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.5839694656488774 100
Completed Iteration #7
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1668> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.36259541984733445 11
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.6106870229007697 19
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.858778625954205 29
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.0496183206106977 40
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.2595419847328397 56
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.4312977099236832 68
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.5458015267175789 87
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.6030534351145267 101
Completed Iteration #8
Best Reward: 0.057251908396947826
Completed Iteration #9
Best Reward: 0.057251908396947826
Completed Iteration #10
Best Reward: 0.057251908396947826
Completed Iteration #11
Best Reward: 0.057251908396947826
Completed Iteration #12
Best Reward: 0.057251908396947826
Completed Iteration #13
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720f48ba8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.38167938931298373 12
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.629770992366419 20
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.8778625954198542 30
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.068702290076347 41
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.278625954198489 57
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.4503816793893325 69
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.5648854961832281 88
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.622137404580176 102
Completed Iteration #14
Best Reward: 0.057251908396947826
Completed Iteration #15
Best Reward: 0.057251908396947826
Completed Iteration #16
Best Reward: 0.057251908396947826
Completed Iteration #17
Best Reward: 0.057251908396947826
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720f48518> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.4198473282442805 13
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.6679389312977158 21
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.916030534351151 31
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.1068702290076438 42
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.3167938931297858 58
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.4885496183206293 70
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.603053435114525 89
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.6603053435114727 103
Completed Iteration #18
Best Reward: 0.057251908396947826
Completed Iteration #19
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720100eb8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8eb8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1668> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.4389312977099298 14
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.687022900763365 22
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.9351145038168003 32
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.125954198473293 43
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.335877862595435 59
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.5076335877862785 71
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.6221374045801742 90
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.679389312977122 104
Completed Iteration #20
Best Reward: 0.057251908396947826
Completed Iteration #21
Best Reward: 0.057251908396947826
Completed Iteration #22
Best Reward: 0.057251908396947826
Completed Iteration #23
Best Reward: 0.057251908396947826
Completed Iteration #24
Best Reward: 0.057251908396947826
Completed Iteration #25
Best Reward: 0.057251908396947826
Completed MCTS Level/Depth: #7
root->3->3->0->19->5->19->6
Best Reward: 0.057251908396947826
Completed Iteration #0
Best Reward: 0.057251908396947826
Completed Iteration #1
Best Reward: 0.057251908396947826
Completed Iteration #2
Best Reward: 0.057251908396947826
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.057251908396947826 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.4389312977099298 15
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.687022900763365 23
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.9351145038168003 33
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.125954198473293 44
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.335877862595435 60
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.5076335877862785 72
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.6221374045801742 91
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.679389312977122 105
Completed Iteration #3
Best Reward: 0.057251908396947826
Completed Iteration #4
Best Reward: 0.057251908396947826
Completed Iteration #5
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd796300fd0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea320> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.0763358778625971 4
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.45801526717557905 16
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.7061068702290143 24
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.9541984732824496 34
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.1450381679389423 45
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.3549618320610843 61
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.5267175572519278 73
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.6412213740458235 92
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.6984732824427713 106
Completed Iteration #6
Best Reward: 0.057251908396947826
Completed Iteration #7
Best Reward: 0.057251908396947826
Completed Iteration #8
Best Reward: 0.057251908396947826
Completed Iteration #9
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720f48128> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7963131d0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.09541984732824638 5
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.47709923664122833 17
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.7251908396946636 25
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.9732824427480988 35
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.1641221374045916 46
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.3740458015267336 62
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.545801526717577 74
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.6603053435114727 93
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.7175572519084206 107
Completed Iteration #10
Best Reward: 0.057251908396947826
Completed Iteration #11
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720100470> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7963131d0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.11450381679389565 6
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.4961832061068776 18
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.7442748091603129 26
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 0.9923664122137481 36
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.1832061068702409 47
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.3931297709923829 63
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.5648854961832264 75
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.679389312977122 94
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.7366412213740698 108
Completed Iteration #12
Best Reward: 0.057251908396947826
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd72017e630> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea320> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.15267175572519243 7
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.5343511450381744 19
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.7824427480916096 27
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 1.0305343511450449 37
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.2213740458015376 48
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.4312977099236797 64
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.6030534351145231 76
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.7175572519084188 95
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.7748091603053666 109
Completed Iteration #13
Best Reward: 0.057251908396947826
Completed Iteration #14
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200d89b0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8358> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.1717557251908417 8
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.5534351145038237 20
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.8015267175572589 28
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 1.0496183206106942 38
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.240458015267187 49
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.450381679389329 65
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.6221374045801724 77
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.736641221374068 96
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.793893129771016 110
Completed Iteration #15
Best Reward: 0.057251908396947826
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd72017e780> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8358> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.20992366412213848 9
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.5916030534351204 21
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.8396946564885557 29
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 1.087786259541991 39
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.2786259541984837 50
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.4885496183206257 66
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.6603053435114692 78
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.7748091603053648 97
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.8320610687023127 111
Completed Iteration #16
Best Reward: 0.057251908396947826
Completed Iteration #17
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6c50> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea080> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.22900763358778775 10
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.6106870229007697 22
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.858778625954205 30
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 1.1068702290076402 40
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.297709923664133 51
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.507633587786275 67
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.6793893129771185 79
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.7938931297710141 98
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.851145038167962 112
Completed Iteration #18
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7201be048> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7963131d0> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.24809160305343703 11
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.629770992366419 23
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.8778625954198542 31
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 1.1259541984732895 41
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.3167938931297822 52
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.5267175572519243 68
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.6984732824427677 80
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.8129770992366634 99
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.8702290076336112 113
Completed Iteration #19
Best Reward: 0.057251908396947826
Completed Iteration #20
Best Reward: 0.057251908396947826
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7986caa58> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea080> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.2671755725190863 12
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.6488549618320683 24
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.8969465648855035 32
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 1.1450381679389388 42
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.3358778625954315 53
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.5458015267175735 69
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.717557251908417 81
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.8320610687023127 100
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.8893129770992605 114
Completed Iteration #21
Best Reward: 0.057251908396947826
Completed Iteration #22
Best Reward: 0.057251908396947826
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea320> 0.05725190839694605 4
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.2671755725190863 13
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.6488549618320683 25
backprop <src.mcts.MCTS_Node object at 0x7fd72008cf60> 0.8969465648855035 33
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3240> 1.1450381679389388 43
backprop <src.mcts.MCTS_Node object at 0x7fd720100550> 1.3358778625954315 54
backprop <src.mcts.MCTS_Node object at 0x7fd72012a3c8> 1.5458015267175735 70
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e80> 1.717557251908417 82
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6828> 1.8320610687023127 101
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb128> 1.8893129770992605 115
Completed Iteration #23
Best Reward: 0.057251908396947826
Completed Iteration #24
Best Reward: 0.057251908396947826
Completed Iteration #25
Best Reward: 0.057251908396947826
Completed MCTS Level/Depth: #8
root->3->3->0->19->5->19->6->1
Best Reward: 0.057251908396947826
iteration: 6
found coverage increase 0.057251908396947826
Current Total Coverage 8.68320610687023
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6a90> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e518> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.0190839694656475 2
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.0190839694656475 3
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e518> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.0190839694656475 4
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.0190839694656475 5
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6128> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48c88> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6a90> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017e518> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.038167938931295 6
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd7201be8d0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bec50> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.0572519083969425 7
Completed Iteration #6
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.0572519083969425 8
Completed Iteration #7
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.0572519083969425 9
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.0572519083969425 10
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd7201be710> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be208> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.07633587786259 11
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.07633587786259 12
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.07633587786259 13
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb748> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bec50> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.0954198473282375 14
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e518> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.0954198473282375 15
Completed Iteration #14
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 16
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bec50> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 17
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 18
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 19
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be208> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 20
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e518> 0.038167938931295 6
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 21
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7963e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 22
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 23
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #0
root
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 24
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 25
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 5
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 26
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 6
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 27
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 7
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 28
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 8
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 29
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 9
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 30
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 10
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 31
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 11
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 32
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 12
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 33
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 13
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 34
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201beef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 14
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 35
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.0190839694656475 15
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.114503816793885 36
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Completed Iteration #2
Best Reward: 0.0190839694656475
Completed Iteration #3
Best Reward: 0.0190839694656475
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Completed Iteration #6
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5c0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be470> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.038167938931295 16
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.1335877862595325 37
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.038167938931295 17
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.1335877862595325 38
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e470f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.038167938931295 6
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.038167938931295 18
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.1335877862595325 39
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.038167938931295 7
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.038167938931295 19
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.1335877862595325 40
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.07633587786259177 8
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.07633587786259177 20
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.17175572519082927 41
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e478d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.07633587786259177 9
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.07633587786259177 21
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.17175572519082927 42
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e478d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.07633587786259177 10
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.07633587786259177 22
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.17175572519082927 43
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.07633587786259177 11
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.07633587786259177 23
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.17175572519082927 44
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.07633587786259177 12
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.07633587786259177 24
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.17175572519082927 45
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #2
root->2->18
Best Reward: 0.038167938931296774
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e924a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.07633587786259177 13
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.07633587786259177 25
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.17175572519082927 46
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e928d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.038167938931296774 4
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.07633587786259177 14
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.07633587786259177 26
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.17175572519082927 47
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e92710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.038167938931296774 5
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.07633587786259177 15
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.07633587786259177 27
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.17175572519082927 48
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #3
root->2->18->2
Best Reward: 0.038167938931296774
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.038167938931296774 4
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.038167938931296774 6
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.07633587786259177 16
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.07633587786259177 28
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.17175572519082927 49
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.038167938931296774 5
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.038167938931296774 7
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.07633587786259177 17
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.07633587786259177 29
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.17175572519082927 50
Completed Iteration #4
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e92cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.038167938931296774 6
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.038167938931296774 8
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.07633587786259177 18
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.07633587786259177 30
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.17175572519082927 51
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7278> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.05725190839694427 7
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.05725190839694427 9
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.09541984732823927 19
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.09541984732823927 31
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.19083969465647677 52
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e923c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.05725190839694427 8
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.05725190839694427 10
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.09541984732823927 20
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.09541984732823927 32
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.19083969465647677 53
Completed Iteration #11
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720140780> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.07633587786259177 9
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.07633587786259177 11
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.11450381679388677 21
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.11450381679388677 33
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.20992366412212426 54
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e923c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.07633587786259177 10
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.07633587786259177 12
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.11450381679388677 22
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.11450381679388677 34
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.20992366412212426 55
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.07633587786259177 11
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.07633587786259177 13
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.11450381679388677 23
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.11450381679388677 35
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.20992366412212426 56
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e92ac8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e923c8> 0.0190839694656475 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.09541984732823927 12
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.09541984732823927 14
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.13358778625953427 24
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.13358778625953427 36
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.22900763358777176 57
Completed Iteration #18
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.09541984732823927 13
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.09541984732823927 15
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.13358778625953427 25
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.13358778625953427 37
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.22900763358777176 58
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb6a0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb9e8> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.11450381679388677 14
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.11450381679388677 16
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.15267175572518177 26
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.15267175572518177 38
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.24809160305341926 59
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #4
root->2->18->2->12
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.11450381679388677 15
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.11450381679388677 17
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.15267175572518177 27
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.15267175572518177 39
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.24809160305341926 60
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7c88> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.0572519083969425 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.13358778625953427 16
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.13358778625953427 18
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.17175572519082927 28
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.17175572519082927 40
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.26717557251906676 61
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.0572519083969425 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.13358778625953427 17
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.13358778625953427 19
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.17175572519082927 29
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.17175572519082927 41
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.26717557251906676 62
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.0572519083969425 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.13358778625953427 18
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.13358778625953427 20
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.17175572519082927 30
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.17175572519082927 42
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.26717557251906676 63
Completed Iteration #4
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ed77f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.07633587786259 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.15267175572518177 19
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.15267175572518177 21
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.19083969465647677 31
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.19083969465647677 43
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.28625954198471426 64
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720f8b9e8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.0954198473282375 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.17175572519082927 20
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.17175572519082927 22
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.20992366412212426 32
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.20992366412212426 44
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.30534351145036176 65
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.0954198473282375 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.17175572519082927 21
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.17175572519082927 23
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.20992366412212426 33
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.20992366412212426 45
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.30534351145036176 66
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.13358778625953427 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.20992366412212604 22
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.20992366412212604 24
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.24809160305342104 34
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.24809160305342104 46
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.34351145038165853 67
Completed Iteration #15
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7da0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.15267175572518177 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.22900763358777354 23
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.22900763358777354 25
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.26717557251906854 35
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.26717557251906854 47
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.36259541984730603 68
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #5
root->2->18->2->12->1
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.15267175572518177 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.22900763358777354 24
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.22900763358777354 26
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.26717557251906854 36
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.26717557251906854 48
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.36259541984730603 69
Completed Iteration #0
Best Reward: 0.038167938931296774
coverage_call_count 700
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.038167938931296774 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.15267175572518177 14
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.22900763358777354 25
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.22900763358777354 27
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.26717557251906854 37
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.26717557251906854 49
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.36259541984730603 70
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.038167938931296774 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.15267175572518177 15
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.22900763358777354 26
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.22900763358777354 28
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.26717557251906854 38
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.26717557251906854 50
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.36259541984730603 71
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f5e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.038167938931296774 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.15267175572518177 16
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.22900763358777354 27
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.22900763358777354 29
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.26717557251906854 39
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.26717557251906854 51
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.36259541984730603 72
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.038167938931296774 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.15267175572518177 17
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.22900763358777354 28
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.22900763358777354 30
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.26717557251906854 40
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.26717557251906854 52
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.36259541984730603 73
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720eec2e8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5eb38> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.05725190839694427 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.17175572519082927 18
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.24809160305342104 29
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.24809160305342104 31
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.28625954198471604 41
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.28625954198471604 53
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.38167938931295353 74
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.05725190839694427 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.17175572519082927 19
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.24809160305342104 30
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.24809160305342104 32
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.28625954198471604 42
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.28625954198471604 54
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.38167938931295353 75
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.05725190839694427 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.17175572519082927 20
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.24809160305342104 31
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.24809160305342104 33
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.28625954198471604 43
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.28625954198471604 55
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.38167938931295353 76
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.05725190839694427 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.17175572519082927 21
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.24809160305342104 32
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.24809160305342104 34
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.28625954198471604 44
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.28625954198471604 56
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.38167938931295353 77
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5eb38> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.05725190839694427 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.17175572519082927 22
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.24809160305342104 33
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.24809160305342104 35
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.28625954198471604 45
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.28625954198471604 57
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.38167938931295353 78
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eeccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.05725190839694427 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.17175572519082927 23
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.24809160305342104 34
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.24809160305342104 36
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.28625954198471604 46
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.28625954198471604 58
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.38167938931295353 79
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.05725190839694427 14
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.17175572519082927 24
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.24809160305342104 35
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.24809160305342104 37
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.28625954198471604 47
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.28625954198471604 59
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.38167938931295353 80
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.05725190839694427 15
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.17175572519082927 25
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.24809160305342104 36
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.24809160305342104 38
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.28625954198471604 48
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.28625954198471604 60
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.38167938931295353 81
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.07633587786259177 16
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.19083969465647677 26
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.26717557251906854 37
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.26717557251906854 39
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.30534351145036354 49
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.30534351145036354 61
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.40076335877860103 82
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #6
root->2->18->2->12->1->10
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.09541984732823927 17
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.20992366412212426 27
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.28625954198471604 38
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.28625954198471604 40
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.32442748091601104 50
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.32442748091601104 62
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.41984732824424853 83
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd798713828> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.11450381679388677 18
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.22900763358777176 28
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.30534351145036354 39
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.30534351145036354 41
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.34351145038165853 51
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.34351145038165853 63
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.43893129770989603 84
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.07633587786259 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.13358778625953427 19
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.24809160305341926 29
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.32442748091601104 40
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.32442748091601104 42
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.36259541984730603 52
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.36259541984730603 64
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.45801526717554353 85
Completed Iteration #4
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd798713f98> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7cc0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.0954198473282375 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.15267175572518177 20
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.26717557251906676 30
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.34351145038165853 41
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.34351145038165853 43
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.38167938931295353 53
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.38167938931295353 65
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.477099236641191 86
Completed Iteration #5
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.0954198473282375 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.15267175572518177 21
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.26717557251906676 31
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.34351145038165853 42
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.34351145038165853 44
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.38167938931295353 54
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.38167938931295353 66
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.477099236641191 87
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ec13c8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.114503816793885 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.17175572519082927 22
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.28625954198471426 32
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.36259541984730603 43
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.36259541984730603 45
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.40076335877860103 55
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.40076335877860103 67
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.4961832061068385 88
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec12b0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1320> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.1335877862595325 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.19083969465647677 23
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.30534351145036176 33
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.38167938931295353 44
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.38167938931295353 46
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.41984732824424853 56
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.41984732824424853 68
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.515267175572486 89
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720ec10f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.15267175572518 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.20992366412212426 24
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.32442748091600926 34
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.40076335877860103 45
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.40076335877860103 47
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.43893129770989603 57
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.43893129770989603 69
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.5343511450381335 90
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd72008c080> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.1717557251908275 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.22900763358777176 25
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.34351145038165676 35
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.41984732824424853 46
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.41984732824424853 48
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.45801526717554353 58
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.45801526717554353 70
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.553435114503781 91
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720158e80> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158ef0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec13c8> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.190839694656475 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.24809160305341926 26
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.36259541984730426 36
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.43893129770989603 47
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.43893129770989603 49
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.477099236641191 59
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.477099236641191 71
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.5725190839694285 92
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #7
root->2->18->2->12->1->10->8
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.190839694656475 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.24809160305341926 27
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.36259541984730426 37
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.43893129770989603 48
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.43893129770989603 50
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.477099236641191 60
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.477099236641191 72
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.5725190839694285 93
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd7201583c8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a208> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.0572519083969425 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.2099236641221225 14
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.26717557251906676 28
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.38167938931295176 38
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.45801526717554353 49
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.45801526717554353 51
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.4961832061068385 61
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.4961832061068385 73
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.591603053435076 94
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.0572519083969425 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.2099236641221225 15
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.26717557251906676 29
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.38167938931295176 39
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.45801526717554353 50
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.45801526717554353 52
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.4961832061068385 62
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.4961832061068385 74
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.591603053435076 95
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd7201585f8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d7f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.07633587786259 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.22900763358777 16
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.28625954198471426 30
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.40076335877859925 40
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.477099236641191 51
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.477099236641191 53
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.515267175572486 63
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.515267175572486 75
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.6106870229007235 96
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.07633587786259 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.22900763358777 17
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.28625954198471426 31
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.40076335877859925 41
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.477099236641191 52
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.477099236641191 54
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.515267175572486 64
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.515267175572486 76
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.6106870229007235 97
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.07633587786259 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.22900763358777 18
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.28625954198471426 32
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.40076335877859925 42
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.477099236641191 53
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.477099236641191 55
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.515267175572486 65
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.515267175572486 77
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.6106870229007235 98
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd72002a358> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dd30> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.0954198473282375 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.2480916030534175 19
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.30534351145036176 33
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.41984732824424675 43
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.4961832061068385 54
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.4961832061068385 56
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.5343511450381335 66
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.5343511450381335 78
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.629770992366371 99
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd72008cc50> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dd30> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.114503816793885 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.267175572519065 20
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.32442748091600926 34
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.43893129770989425 44
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.515267175572486 55
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.515267175572486 57
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.553435114503781 67
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.553435114503781 79
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.6488549618320185 100
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720044438> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7ddd8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.1335877862595325 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.2862595419847125 21
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.34351145038165676 35
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.45801526717554175 45
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.5343511450381335 56
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.5343511450381335 58
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.5725190839694285 68
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.5725190839694285 80
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.667938931297666 101
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720044940> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d7f0> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.15267175572518 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.30534351145036 22
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.36259541984730426 36
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.47709923664118925 46
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.553435114503781 57
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.553435114503781 59
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.591603053435076 69
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.591603053435076 81
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.6870229007633135 102
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720080940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d7f0> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.15267175572518 14
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.30534351145036 23
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.36259541984730426 37
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.47709923664118925 47
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.553435114503781 58
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.553435114503781 60
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.591603053435076 70
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.591603053435076 82
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.6870229007633135 103
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f32fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d7f0> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.15267175572518 15
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.30534351145036 24
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.36259541984730426 38
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.47709923664118925 48
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.553435114503781 59
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.553435114503781 61
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.591603053435076 71
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.591603053435076 83
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.6870229007633135 104
Completed Iteration #18
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7cc0> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.15267175572518 16
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.30534351145036 25
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.36259541984730426 39
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.47709923664118925 49
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.553435114503781 60
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.553435114503781 62
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.591603053435076 72
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.591603053435076 84
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.6870229007633135 105
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dd30> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e925f8> 0.15267175572518 17
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d198> 0.30534351145036 26
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.36259541984730426 40
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.47709923664118925 50
backprop <src.mcts.MCTS_Node object at 0x7fd720e92470> 0.553435114503781 61
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.553435114503781 63
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa20> 0.591603053435076 73
backprop <src.mcts.MCTS_Node object at 0x7fd72019aba8> 0.591603053435076 85
backprop <src.mcts.MCTS_Node object at 0x7fd72017edd8> 0.6870229007633135 106
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #8
root->2->18->2->12->1->10->8->10
Best Reward: 0.038167938931296774
iteration: 7
found coverage increase 0.038167938931296774
Current Total Coverage 8.721374045801527
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200441d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 8.721374045801527
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.0 2
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.0 3
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.0 4
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72004eb70> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec240> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.019083969465649275 5
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.03816793893129855 6
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.03816793893129855 7
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.03816793893129855 8
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4642b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.03816793893129855 9
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec240> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.03816793893129855 10
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.03816793893129855 11
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.03816793893129855 12
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec240> 0.019083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.03816793893129855 13
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.03816793893129855 14
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.03816793893129855 15
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #0
root
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72004ea58> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.057251908396947826 16
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471be0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4718d0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.0763358778625971 17
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.0763358778625971 18
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.057251908396947826 6
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.0763358778625971 19
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471eb8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.0954198473282446 7
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.11450381679389388 20
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471eb8> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.0954198473282446 8
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.11450381679389388 21
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.0954198473282446 9
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.11450381679389388 22
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.0954198473282446 10
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.11450381679389388 23
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72004e898> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.11450381679389388 11
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.13358778625954315 24
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.11450381679389388 12
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.13358778625954315 25
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471cf8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.13358778625954315 13
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.15267175572519243 26
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.13358778625954315 14
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.15267175572519243 27
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471b70> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.15267175572519243 15
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.1717557251908417 28
Completed Iteration #18
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.15267175572519243 16
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.1717557251908417 29
Completed Iteration #19
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471cf8> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.15267175572519243 17
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.1717557251908417 30
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480be0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.1717557251908417 18
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.19083969465649098 31
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480f60> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.19083969465649098 19
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.20992366412214025 32
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480940> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471dd8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.20992366412214025 20
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.22900763358778953 33
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419470> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471dd8> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.0763358778625971 5
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.22900763358778953 21
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.2480916030534388 34
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419828> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4190b8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.09541984732824638 6
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.2480916030534388 22
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.2671755725190881 35
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419dd8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4190b8> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.11450381679389565 7
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.2671755725190881 23
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.28625954198473735 36
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419f98> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4718d0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.13358778625954493 8
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.28625954198473735 24
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.30534351145038663 37
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419160> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4190b8> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.1526717557251942 9
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.30534351145038663 25
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.3244274809160359 38
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1518> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464cf8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.19083969465649098 10
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.3435114503816834 26
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.3625954198473327 39
Completed Iteration #11
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf908> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464470> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.20992366412214025 11
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.3625954198473327 27
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.38167938931298195 40
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720e7df28> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464470> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.22900763358778953 12
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.38167938931298195 28
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.40076335877863123 41
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72004e198> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4718d0> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.2480916030534388 13
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.40076335877863123 29
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.4198473282442805 42
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419630> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.2862595419847356 14
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.438931297709928 30
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.4580152671755773 43
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4197b8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464470> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.30534351145038485 15
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.4580152671755773 31
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.47709923664122655 44
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480b38> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.3435114503816816 16
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.49618320610687405 32
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.5152671755725233 45
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.3435114503816816 17
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.49618320610687405 33
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.5152671755725233 46
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471978> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464cf8> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.3625954198473309 18
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.5152671755725233 34
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.5343511450381726 47
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4804e0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464470> 0.0954198473282446 5
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.4007633587786277 19
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.5534351145038201 35
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.5725190839694694 48
Completed Iteration #24
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4190b8> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.4007633587786277 20
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.5534351145038201 36
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.5725190839694694 49
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #2
root->8->4
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6cf8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.09541984732824282 4
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.41984732824427695 21
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.5725190839694694 37
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.5916030534351187 50
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720eec8d0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.1145038167938921 5
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.4389312977099262 22
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.5916030534351187 38
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.6106870229007679 51
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd72005b198> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.15267175572518887 6
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.477099236641223 23
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.6297709923664154 39
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.6488549618320647 52
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6780> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.19083969465648565 7
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.5152671755725198 24
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.6679389312977122 40
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.6870229007633615 53
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480da0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.20992366412213492 8
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.534351145038169 25
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.6870229007633615 41
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.7061068702290108 54
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424cc0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.2480916030534317 9
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.5725190839694658 26
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.7251908396946583 42
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.7442748091603075 55
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.28625954198472847 10
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.6106870229007626 27
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.763358778625955 43
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.7824427480916043 56
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200807b8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004eeb8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.30534351145037775 11
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.6297709923664119 28
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.7824427480916043 44
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.8015267175572536 57
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.30534351145037775 12
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.6297709923664119 29
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.7824427480916043 45
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.8015267175572536 58
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #3
root->8->4->8
Best Reward: 0.038167938931296774
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd72004ef98> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419208> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.09541984732824282 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.3435114503816745 13
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.6679389312977086 30
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.8206106870229011 46
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.8396946564885504 59
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.1335877862595396 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.3816793893129713 14
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.7061068702290054 31
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.8587786259541978 47
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.8778625954198471 60
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
coverage_call_count 900
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200440b8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004eeb8> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.15267175572518887 6
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.40076335877862057 15
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.7251908396946547 32
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.8778625954198471 48
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.8969465648854964 61
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424e48> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419208> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.19083969465648565 7
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.43893129770991735 16
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.7633587786259515 33
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.9160305343511439 49
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.9351145038167932 62
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c8d0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419208> 0.11450381679389032 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.22900763358778242 8
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.4770992366412141 17
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.8015267175572482 34
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.9541984732824407 50
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.97328244274809 63
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cd68> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c390> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c8d0> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419208> 0.1335877862595396 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.2480916030534317 9
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.4961832061068634 18
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.8206106870228975 35
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 0.97328244274809 51
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 0.9923664122137392 64
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2438> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.28625954198472847 10
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.5343511450381602 19
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.8587786259541943 36
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.0114503816793867 52
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.030534351145036 65
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2518> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.09541984732824282 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.30534351145037775 11
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.5534351145038094 20
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.8778625954198436 37
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.030534351145036 53
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.0496183206106853 66
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1438> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004eeb8> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.324427480916027 12
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.5725190839694587 21
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.8969465648854928 38
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.0496183206106853 54
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.0687022900763345 67
Completed Iteration #22
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419208> 0.1335877862595396 6
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.324427480916027 13
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.5725190839694587 22
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.8969465648854928 39
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.0496183206106853 55
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.0687022900763345 68
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471240> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004eeb8> 0.0954198473282446 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.3625954198473238 14
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.6106870229007555 23
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.9351145038167896 40
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.087786259541982 56
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.1068702290076313 69
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #4
root->8->4->8->7
Best Reward: 0.038167938931296774
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480978> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.1335877862595396 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.40076335877862057 15
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.6488549618320523 24
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.9732824427480864 41
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.1259541984732788 57
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.145038167938928 70
Completed Iteration #4
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.17175572519083637 6
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.43893129770991735 16
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.687022900763349 25
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.0114503816793832 42
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.1641221374045756 58
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.1832061068702249 71
Completed Iteration #5
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c860> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.20992366412213315 7
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.4770992366412141 17
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.7251908396946458 26
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.04961832061068 43
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.2022900763358724 59
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.2213740458015216 72
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cac8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.22900763358778242 8
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.4961832061068634 18
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.7442748091602951 27
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.0687022900763292 44
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.2213740458015216 60
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.240458015267171 73
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2438> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.22900763358778242 9
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.4961832061068634 19
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.7442748091602951 28
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.0687022900763292 45
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.2213740458015216 61
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.240458015267171 74
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1518> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.2671755725190792 10
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.5343511450381602 20
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.7824427480915919 29
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.106870229007626 46
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.2595419847328184 62
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.2786259541984677 75
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #5
root->8->4->8->7->6
Best Reward: 0.038167938931296774
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece80> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec748> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.11450381679389032 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.30534351145037597 11
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.5725190839694569 21
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.8206106870228886 30
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.1450381679389228 47
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.2977099236641152 63
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.3167938931297645 76
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec748> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.11450381679389032 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.30534351145037597 12
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.5725190839694569 22
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.8206106870228886 31
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.1450381679389228 48
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.2977099236641152 64
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.3167938931297645 77
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f65c0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec748> 0.07633587786259355 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.1526717557251871 6
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.34351145038167274 13
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.6106870229007537 23
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.8587786259541854 32
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.1832061068702195 49
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.335877862595412 65
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.3549618320610612 78
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1ef0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecb38> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.17175572519083637 7
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.362595419847322 14
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.629770992366403 24
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.8778625954198347 33
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.2022900763358688 50
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.3549618320610612 66
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.3740458015267105 79
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1cf8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.19083969465648565 8
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.3816793893129713 15
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.6488549618320523 25
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.896946564885484 34
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.221374045801518 51
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.3740458015267105 67
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.3931297709923598 80
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec748> 0.07633587786259355 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.19083969465648565 9
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.3816793893129713 16
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.6488549618320523 26
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.896946564885484 35
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.221374045801518 52
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.3740458015267105 68
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.3931297709923598 81
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #6
root->8->4->8->7->6->26
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c860> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.05725190839694605 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.19083969465648565 10
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.3816793893129713 17
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.6488549618320523 27
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.896946564885484 36
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.221374045801518 53
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.3740458015267105 69
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.3931297709923598 82
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424c88> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.07633587786259532 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.20992366412213492 11
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.40076335877862057 18
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.6679389312977015 28
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.9160305343511332 37
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.2404580152671674 54
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.3931297709923598 70
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.412213740458009 83
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464668> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.0954198473282446 6
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.2290076335877842 12
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.41984732824426985 19
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.6870229007633508 29
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.9351145038167825 38
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.2595419847328166 55
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.412213740458009 71
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.4312977099236583 84
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b38> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.11450381679389388 7
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.24809160305343347 13
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.4389312977099191 20
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.7061068702290001 30
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.9541984732824318 39
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.278625954198466 56
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.4312977099236583 72
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.4503816793893076 85
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1668> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.15267175572519065 8
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.28625954198473025 14
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.4770992366412159 21
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.7442748091602969 31
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 0.9923664122137286 40
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.3167938931297627 57
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.4694656488549551 73
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.4885496183206044 86
Completed Iteration #22
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfc88> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.17175572519083993 9
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.3053435114503795 15
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.49618320610686517 22
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.7633587786259461 32
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 1.0114503816793778 41
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.335877862595412 58
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.4885496183206044 74
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.5076335877862537 87
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480e10> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.2099236641221367 10
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.3435114503816763 16
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.534351145038162 23
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.8015267175572429 33
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 1.0496183206106746 42
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.3740458015267087 59
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.5267175572519012 75
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.5458015267175504 88
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #7
root->8->4->8->7->6->26->6
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7fd72004efd0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f63c8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1668> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.24809160305343347 11
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.38167938931297307 17
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.5725190839694587 24
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.8396946564885397 34
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 1.0877862595419714 43
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.4122137404580055 60
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.564885496183198 76
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.5839694656488472 89
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec048> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f63c8> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1668> 0.09541984732824282 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.26717557251908275 12
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.40076335877862235 18
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.591603053435108 25
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.858778625954189 35
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 1.1068702290076207 44
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.4312977099236548 61
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.5839694656488472 77
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.6030534351144965 90
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785f98> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47854e0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1668> 0.1145038167938921 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.286259541984732 13
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.4198473282442716 19
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.6106870229007573 26
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.8778625954198382 36
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 1.12595419847327 45
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.450381679389304 62
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.6030534351144965 78
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.6221374045801458 91
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7748> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f63c8> 0.07633587786259532 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1668> 0.13358778625954137 6
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.3053435114503813 14
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.4389312977099209 20
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.6297709923664065 27
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.8969465648854875 37
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 1.1450381679389192 46
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.4694656488549533 63
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.6221374045801458 79
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.641221374045795 92
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
coverage_call_count 1000
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7e80> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47854e0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1668> 0.15267175572519065 7
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.3244274809160306 15
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.4580152671755702 21
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.6488549618320558 28
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c780> 0.9160305343511368 38
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4196a0> 1.1641221374045685 47
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 1.4885496183206026 64
backprop <src.mcts.MCTS_Node object at 0x7fd720080390> 1.641221374045795 80
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1470> 1.6603053435114443 93
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #8
root->8->4->8->7->6->26->6->3
Best Reward: 0.038167938931296774
iteration: 9
found coverage increase 0.038167938931296774
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47eccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc50> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47710f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47710f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47205f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47209e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47205f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47205f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fd68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b96d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b94a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 8.759541984732824
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47205f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46caf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47207f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46caa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47205f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46caa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46823c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 8.759541984732824
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 1200
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f6a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46410b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46410b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e469aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46410b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46410b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47852b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b90b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 1300
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46762b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46762b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46769e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46769e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda58> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46827f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc4e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 12
Completed Iteration #11
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77400f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77400f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740358> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 8.759541984732824
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46caf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 13
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 14
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 15
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 16
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 17
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46caf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 18
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 19
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #0
root
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 20
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.019083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 21
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.019083969465649275 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 22
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.019083969465649275 7
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 23
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.019083969465649275 8
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 24
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.019083969465649275 9
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 25
Completed Iteration #9
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.019083969465649275 10
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 26
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.019083969465649275 11
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 27
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.019083969465649275 12
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 28
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.019083969465649275 13
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.019083969465649275 29
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.03816793893129855 14
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.03816793893129855 30
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.03816793893129855 15
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.03816793893129855 31
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.03816793893129855 16
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.03816793893129855 32
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.03816793893129855 17
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.03816793893129855 33
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #1
root->7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.03816793893129855 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.03816793893129855 18
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.03816793893129855 34
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b777cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b777cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.03816793893129855 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.03816793893129855 19
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.03816793893129855 35
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b777ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.03816793893129855 7
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.03816793893129855 20
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.03816793893129855 36
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b777cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.03816793893129855 8
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.03816793893129855 21
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.03816793893129855 37
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709908> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709470> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.057251908396947826 9
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.057251908396947826 22
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.057251908396947826 38
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709470> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.057251908396947826 10
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.057251908396947826 23
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.057251908396947826 39
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.057251908396947826 11
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.057251908396947826 24
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.057251908396947826 40
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c390> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c9e8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.0763358778625971 12
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.0763358778625971 25
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0763358778625971 41
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.0763358778625971 13
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.0763358778625971 26
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0763358778625971 42
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.0763358778625971 14
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.0763358778625971 27
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0763358778625971 43
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772860> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae198> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.09541984732824638 15
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.09541984732824638 28
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.09541984732824638 44
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae198> 0.019083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.09541984732824638 16
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.09541984732824638 29
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.09541984732824638 45
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c9e8> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.09541984732824638 17
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.09541984732824638 30
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.09541984732824638 46
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709470> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.09541984732824638 18
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.09541984732824638 31
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.09541984732824638 47
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.09541984732824638 19
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.09541984732824638 32
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.09541984732824638 48
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #2
root->7->13
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.09541984732824638 20
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.09541984732824638 33
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.09541984732824638 49
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77097b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.09541984732824638 21
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.09541984732824638 34
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.09541984732824638 50
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.019083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.09541984732824638 22
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.09541984732824638 35
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.09541984732824638 51
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772320> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 23
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 36
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 52
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 7
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 24
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 37
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 53
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 8
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 25
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 38
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 54
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46829e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 9
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 26
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 39
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 55
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 10
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 27
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 40
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 56
Completed Iteration #12
Best Reward: 0.019083969465649275
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 11
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 28
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 41
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 57
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 12
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 29
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 42
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 58
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 13
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 30
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 43
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 59
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #3
root->7->13->4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 14
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 31
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 44
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 60
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 15
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 32
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 45
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 61
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.019083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 16
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 33
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 46
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 62
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.019083969465649275 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.03816793893129855 17
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.11450381679389565 34
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.11450381679389565 47
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.11450381679389565 63
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709a58> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 7
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 18
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 35
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 48
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 64
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 8
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 19
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 36
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 49
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 65
Completed Iteration #9
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 9
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 20
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 37
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 50
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 66
Completed Iteration #10
Best Reward: 0.019083969465649275
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 10
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 21
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 38
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 51
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 67
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 11
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 22
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 39
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 52
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 68
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77404a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 12
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 23
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 40
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 53
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 69
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 13
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 24
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 41
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 54
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 70
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 14
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 25
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 42
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 55
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 71
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77404a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 15
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 26
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 43
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 56
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 72
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 16
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 27
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 44
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 57
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 73
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77402e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 17
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 28
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 45
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 58
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 74
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 18
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 29
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 46
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 59
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 75
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.03816793893129855 19
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.057251908396947826 30
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.13358778625954493 47
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.13358778625954493 60
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.13358778625954493 76
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #4
root->7->13->4->10
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.057251908396947826 20
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.0763358778625971 31
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.1526717557251942 48
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.1526717557251942 61
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.1526717557251942 77
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.057251908396947826 21
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.0763358778625971 32
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.1526717557251942 49
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.1526717557251942 62
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.1526717557251942 78
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.03816793893129855 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.057251908396947826 22
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.0763358778625971 33
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.1526717557251942 50
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.1526717557251942 63
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.1526717557251942 79
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.03816793893129855 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.057251908396947826 23
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.0763358778625971 34
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.1526717557251942 51
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.1526717557251942 64
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.1526717557251942 80
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.03816793893129855 7
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.057251908396947826 24
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.0763358778625971 35
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.1526717557251942 52
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.1526717557251942 65
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.1526717557251942 81
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.03816793893129855 8
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.057251908396947826 25
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.0763358778625971 36
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.1526717557251942 53
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.1526717557251942 66
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.1526717557251942 82
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c630> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.057251908396947826 9
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.0763358778625971 26
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.09541984732824638 37
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.17175572519084348 54
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.17175572519084348 67
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.17175572519084348 83
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.057251908396947826 10
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.0763358778625971 27
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.09541984732824638 38
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.17175572519084348 55
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.17175572519084348 68
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.17175572519084348 84
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.057251908396947826 11
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.0763358778625971 28
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.09541984732824638 39
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.17175572519084348 56
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.17175572519084348 69
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.17175572519084348 85
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676f98> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.0763358778625971 12
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.09541984732824638 29
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.11450381679389565 40
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.19083969465649275 57
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.19083969465649275 70
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.19083969465649275 86
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.0763358778625971 13
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.09541984732824638 30
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.11450381679389565 41
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.19083969465649275 58
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.19083969465649275 71
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.19083969465649275 87
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #5
root->7->13->4->10->6
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.0763358778625971 14
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.09541984732824638 31
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.11450381679389565 42
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.19083969465649275 59
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.19083969465649275 72
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.19083969465649275 88
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc278> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc358> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.09541984732824638 15
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.11450381679389565 32
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.13358778625954493 43
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.20992366412214203 60
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.20992366412214203 73
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.20992366412214203 89
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc358> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.03816793893129855 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.09541984732824638 16
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.11450381679389565 33
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.13358778625954493 44
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.20992366412214203 61
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.20992366412214203 74
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.20992366412214203 90
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.03816793893129855 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.09541984732824638 17
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.11450381679389565 34
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.13358778625954493 45
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.20992366412214203 62
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.20992366412214203 75
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.20992366412214203 91
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b777cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.03816793893129855 7
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.09541984732824638 18
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.11450381679389565 35
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.13358778625954493 46
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.20992366412214203 63
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.20992366412214203 76
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.20992366412214203 92
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.03816793893129855 8
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.09541984732824638 19
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.11450381679389565 36
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.13358778625954493 47
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.20992366412214203 64
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.20992366412214203 77
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.20992366412214203 93
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.03816793893129855 9
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.09541984732824638 20
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.11450381679389565 37
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.13358778625954493 48
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.20992366412214203 65
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.20992366412214203 78
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.20992366412214203 94
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc358> 0.019083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.03816793893129855 10
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.09541984732824638 21
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.11450381679389565 38
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.13358778625954493 49
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.20992366412214203 66
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.20992366412214203 79
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.20992366412214203 95
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.03816793893129855 11
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.09541984732824638 22
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.11450381679389565 39
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.13358778625954493 50
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.20992366412214203 67
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.20992366412214203 80
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.20992366412214203 96
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddba8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.057251908396947826 12
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.11450381679389565 23
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.13358778625954493 40
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.1526717557251942 51
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.2290076335877913 68
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.2290076335877913 81
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.2290076335877913 97
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.057251908396947826 13
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.11450381679389565 24
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.13358778625954493 41
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.1526717557251942 52
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.2290076335877913 69
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.2290076335877913 82
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.2290076335877913 98
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #6
root->7->13->4->10->6->0
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.057251908396947826 14
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.11450381679389565 25
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.13358778625954493 42
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.1526717557251942 53
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.2290076335877913 70
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.2290076335877913 83
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.2290076335877913 99
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.057251908396947826 15
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.11450381679389565 26
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.13358778625954493 43
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.1526717557251942 54
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.2290076335877913 71
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.2290076335877913 84
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.2290076335877913 100
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.019083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.057251908396947826 16
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.11450381679389565 27
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.13358778625954493 44
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.1526717557251942 55
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.2290076335877913 72
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.2290076335877913 85
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.2290076335877913 101
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.019083969465649275 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.057251908396947826 17
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.11450381679389565 28
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.13358778625954493 45
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.1526717557251942 56
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.2290076335877913 73
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.2290076335877913 86
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.2290076335877913 102
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.019083969465649275 7
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.057251908396947826 18
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.11450381679389565 29
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.13358778625954493 46
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.1526717557251942 57
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.2290076335877913 74
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.2290076335877913 87
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.2290076335877913 103
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.019083969465649275 8
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.057251908396947826 19
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.11450381679389565 30
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.13358778625954493 47
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.1526717557251942 58
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.2290076335877913 75
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.2290076335877913 88
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.2290076335877913 104
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641828> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cca20> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9588> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.03816793893129855 9
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0763358778625971 20
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.13358778625954493 31
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.1526717557251942 48
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.17175572519084348 59
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.24809160305344058 76
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.24809160305344058 89
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.24809160305344058 105
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd4a8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.057251908396947826 10
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.09541984732824638 21
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.1526717557251942 32
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.17175572519084348 49
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.19083969465649275 60
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.26717557251908985 77
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.26717557251908985 90
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.26717557251908985 106
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.057251908396947826 11
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.09541984732824638 22
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.1526717557251942 33
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.17175572519084348 50
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.19083969465649275 61
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.26717557251908985 78
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.26717557251908985 91
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.26717557251908985 107
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.057251908396947826 12
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.09541984732824638 23
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.1526717557251942 34
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.17175572519084348 51
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.19083969465649275 62
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.26717557251908985 79
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.26717557251908985 92
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.26717557251908985 108
Completed Iteration #22
Best Reward: 0.019083969465649275
coverage_call_count 1600
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9470> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.0763358778625971 13
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.11450381679389565 24
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.17175572519084348 35
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.19083969465649275 52
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.20992366412214203 63
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.28625954198473913 80
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.28625954198473913 93
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.28625954198473913 109
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #7
root->7->13->4->10->6->0->5
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddba8> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.0763358778625971 14
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.11450381679389565 25
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.17175572519084348 36
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.19083969465649275 53
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.20992366412214203 64
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.28625954198473913 81
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.28625954198473913 94
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.28625954198473913 110
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddba8> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.0763358778625971 15
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.11450381679389565 26
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.17175572519084348 37
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.19083969465649275 54
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.20992366412214203 65
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.28625954198473913 82
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.28625954198473913 95
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.28625954198473913 111
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddba8> 0.019083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.0763358778625971 16
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.11450381679389565 27
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.17175572519084348 38
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.19083969465649275 55
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.20992366412214203 66
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.28625954198473913 83
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.28625954198473913 96
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.28625954198473913 112
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddba8> 0.019083969465649275 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.0763358778625971 17
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.11450381679389565 28
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.17175572519084348 39
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.19083969465649275 56
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.20992366412214203 67
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.28625954198473913 84
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.28625954198473913 97
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.28625954198473913 113
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca1d0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc9b0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddba8> 0.03816793893129855 7
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.09541984732824638 18
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.13358778625954493 29
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.19083969465649275 40
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.20992366412214203 57
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.2290076335877913 68
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.3053435114503884 85
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.3053435114503884 98
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.3053435114503884 114
Completed Iteration #13
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc9b0> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddba8> 0.03816793893129855 8
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.09541984732824638 19
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.13358778625954493 30
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.19083969465649275 41
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.20992366412214203 58
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.2290076335877913 69
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.3053435114503884 86
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.3053435114503884 99
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.3053435114503884 115
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddba8> 0.03816793893129855 9
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.09541984732824638 20
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.13358778625954493 31
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.19083969465649275 42
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.20992366412214203 59
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.2290076335877913 70
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.3053435114503884 87
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.3053435114503884 100
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.3053435114503884 116
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddb38> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddda0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddba8> 0.057251908396947826 10
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.11450381679389565 21
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.1526717557251942 32
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.20992366412214203 43
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.2290076335877913 60
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.24809160305344058 71
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.3244274809160377 88
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.3244274809160377 101
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.3244274809160377 117
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9cc0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dddd8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddba8> 0.0763358778625971 11
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.13358778625954493 22
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.17175572519084348 33
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.2290076335877913 44
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.24809160305344058 61
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.26717557251908985 72
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.34351145038168696 89
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.34351145038168696 102
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.34351145038168696 118
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddba8> 0.0763358778625971 12
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641278> 0.13358778625954493 23
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.17175572519084348 34
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.2290076335877913 45
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772da0> 0.24809160305344058 62
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772908> 0.26717557251908985 73
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.34351145038168696 90
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.34351145038168696 103
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.34351145038168696 119
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #8
root->7->13->4->10->6->0->5->1
Best Reward: 0.019083969465649275
iteration: 26
found coverage increase 0.019083969465649275
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77096a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47711d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47711d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47851d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47851d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d16d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec470> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47855f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f65c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4240f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 8.778625954198473
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424f98> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 8.778625954198473
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4199b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4199b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419cc0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 8.778625954198473
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd798713828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f5e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eeccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f32c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f8bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f8bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f5eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f32e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f8bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eecd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1198> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f8bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f32c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f5e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f8be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 8.778625954198473
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f8b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b72e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec17b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e92160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e92198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 6
Completed Iteration #9
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e92780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7963e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720fc0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720fc04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd796313438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720fc0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd796313438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e92710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7986caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd796313438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720fc0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd796313940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd796313438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7963132e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e477b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e477b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e92400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e477b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f32e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4197b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e923c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eeceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e923c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 8.778625954198473
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720eec4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 8.778625954198473
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200446d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200446d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72004e828> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 8.778625954198473
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72008c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a0b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e920f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bfd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bfd0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bfd0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720080860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720080d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720080518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720080748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720080710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4feb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 8.778625954198473
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720080dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720080ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd796300fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200806a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200806a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7a20> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 8.778625954198473
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72002a9e8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004ee48> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 4
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 5
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 6
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 7
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 8
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 9
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 10
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 11
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004ee48> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 12
Completed Iteration #13
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 13
Completed Iteration #14
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 14
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 15
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.019083969465649275 16
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b4a8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.019083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.03816793893129855 17
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.03816793893129855 18
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.03816793893129855 19
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.03816793893129855 20
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004ee48> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.03816793893129855 21
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72019af98> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.03816793893129855 6
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.057251908396947826 22
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #0
root
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.03816793893129855 7
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.057251908396947826 23
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72017e400> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 8
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 24
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e400> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 9
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 25
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 10
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 26
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 11
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 27
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 12
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 28
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 13
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 29
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 14
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 30
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 15
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 31
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 16
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 32
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 17
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 33
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 18
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 34
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 19
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 35
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.057251908396947826 20
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.0763358778625971 36
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7201401d0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.0763358778625971 21
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.09541984732824638 37
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72012a4a8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a240> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201582b0> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.09541984732824638 22
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.11450381679389565 38
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.09541984732824638 23
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.11450381679389565 39
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.11450381679389565 24
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.13358778625954493 40
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.019083969465649275
coverage_call_count 2300
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.11450381679389565 25
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.13358778625954493 41
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.11450381679389565 26
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.13358778625954493 42
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720140d68> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.03816793893129855 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.13358778625954493 27
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.1526717557251942 43
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72017e828> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.057251908396947826 6
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.1526717557251942 28
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.17175572519084348 44
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720f5ee48> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be048> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.0763358778625971 7
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.17175572519084348 29
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.19083969465649275 45
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb5c0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.09541984732824638 8
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.19083969465649275 30
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.20992366412214203 46
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72019a978> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158710> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.11450381679389565 9
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.20992366412214203 31
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.2290076335877913 47
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480c88> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.0763358778625971 5
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.13358778625954493 10
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.2290076335877913 32
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.24809160305344058 48
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201be048> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.13358778625954493 11
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.2290076335877913 33
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.24809160305344058 49
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.13358778625954493 12
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.2290076335877913 34
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.24809160305344058 50
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.13358778625954493 13
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.2290076335877913 35
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.24809160305344058 51
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #2
root->8->14
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea400> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.09541984732824638 6
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.1526717557251942 14
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.24809160305344058 36
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.26717557251908985 52
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72018ccc0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.11450381679389565 7
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.17175572519084348 15
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.26717557251908985 37
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.28625954198473913 53
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.13358778625954493 8
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.19083969465649275 16
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.28625954198473913 38
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.3053435114503884 54
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd438> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.1526717557251942 9
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.20992366412214203 17
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.3053435114503884 39
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.3244274809160377 55
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d2b0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.17175572519084348 10
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.2290076335877913 18
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.3244274809160377 40
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.34351145038168696 56
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7201584e0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.19083969465649275 11
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.24809160305344058 19
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.34351145038168696 41
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.36259541984733623 57
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb5c0> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.19083969465649275 12
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.24809160305344058 20
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.34351145038168696 42
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.36259541984733623 58
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d2b0> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.19083969465649275 13
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.24809160305344058 21
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.34351145038168696 43
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.36259541984733623 59
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.19083969465649275 14
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.24809160305344058 22
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.34351145038168696 44
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.36259541984733623 60
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #3
root->8->14->5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.19083969465649275 15
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.24809160305344058 23
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.34351145038168696 45
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.36259541984733623 61
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.19083969465649275 16
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.24809160305344058 24
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.34351145038168696 46
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.36259541984733623 62
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.019083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.19083969465649275 17
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.24809160305344058 25
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.34351145038168696 47
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.36259541984733623 63
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1588> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.03816793893129855 6
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.20992366412214203 18
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.26717557251908985 26
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.36259541984733623 48
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.3816793893129855 64
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfeb8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3860> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.057251908396947826 7
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.2290076335877913 19
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.28625954198473913 27
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.3816793893129855 49
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.4007633587786348 65
Completed Iteration #10
Best Reward: 0.019083969465649275
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.057251908396947826 8
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.2290076335877913 20
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.28625954198473913 28
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.3816793893129855 50
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.4007633587786348 66
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3c50> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3390> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.0763358778625971 9
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.24809160305344058 21
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.3053435114503884 29
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.4007633587786348 51
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.41984732824428406 67
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb908> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea240> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.09541984732824638 10
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.26717557251908985 22
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.3244274809160377 30
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.41984732824428406 52
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.43893129770993333 68
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea588> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3588> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.11450381679389565 11
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.28625954198473913 23
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.34351145038168696 31
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.43893129770993333 53
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.4580152671755826 69
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3860> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.11450381679389565 12
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.28625954198473913 24
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.34351145038168696 32
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.43893129770993333 54
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.4580152671755826 70
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #4
root->8->14->5->0
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfe48> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.13358778625954493 13
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.3053435114503884 25
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.36259541984733623 33
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.4580152671755826 55
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.4770992366412319 71
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfe48> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.13358778625954493 14
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.3053435114503884 26
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.36259541984733623 34
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.4580152671755826 56
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.4770992366412319 72
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200d84a8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.1526717557251942 15
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.3244274809160377 27
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.3816793893129855 35
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.4770992366412319 57
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.49618320610688116 73
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8cc0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.0763358778625971 6
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.17175572519084348 16
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.34351145038168696 28
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.4007633587786348 36
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.49618320610688116 58
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.5152671755725304 74
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8d30> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.09541984732824638 7
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.19083969465649275 17
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.36259541984733623 29
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.41984732824428406 37
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.5152671755725304 59
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.5343511450381797 75
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1588> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.09541984732824638 8
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.19083969465649275 18
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.36259541984733623 30
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.41984732824428406 38
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.5152671755725304 60
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.5343511450381797 76
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200d83c8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.11450381679389565 9
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.20992366412214203 19
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.3816793893129855 31
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.43893129770993333 39
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.5343511450381797 61
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.553435114503829 77
Completed Iteration #10
Best Reward: 0.019083969465649275
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720100400> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.13358778625954493 10
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.2290076335877913 20
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.4007633587786348 32
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.4580152671755826 40
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.553435114503829 62
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.5725190839694783 78
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.1526717557251942 11
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.24809160305344058 21
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.41984732824428406 33
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.4770992366412319 41
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.5725190839694783 63
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.5916030534351275 79
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfc50> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.17175572519084348 12
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.26717557251908985 22
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.43893129770993333 34
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.49618320610688116 42
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.5916030534351275 64
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6106870229007768 80
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.17175572519084348 13
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.26717557251908985 23
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.43893129770993333 35
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.49618320610688116 43
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.5916030534351275 65
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6106870229007768 81
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #5
root->8->14->5->0->5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.17175572519084348 14
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.26717557251908985 24
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.43893129770993333 36
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.49618320610688116 44
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.5916030534351275 66
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6106870229007768 82
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.03816793893129855 5
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.17175572519084348 15
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.26717557251908985 25
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.43893129770993333 37
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.49618320610688116 45
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.5916030534351275 67
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6106870229007768 83
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.03816793893129855 6
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.17175572519084348 16
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.26717557251908985 26
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.43893129770993333 38
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.49618320610688116 46
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.5916030534351275 68
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6106870229007768 84
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8940> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8b00> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.057251908396947826 7
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.19083969465649275 17
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.28625954198473913 27
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.4580152671755826 39
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.5152671755725304 47
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.6106870229007768 69
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6297709923664261 85
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
coverage_call_count 2400
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200eab70> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a38d0> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.0763358778625971 8
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.20992366412214203 18
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.3053435114503884 28
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.4770992366412319 40
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.5343511450381797 48
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.6297709923664261 70
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6488549618320754 86
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.0763358778625971 9
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.20992366412214203 19
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.3053435114503884 29
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.4770992366412319 41
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.5343511450381797 49
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.6297709923664261 71
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6488549618320754 87
Completed Iteration #9
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.0763358778625971 10
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.20992366412214203 20
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.3053435114503884 30
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.4770992366412319 42
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.5343511450381797 50
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.6297709923664261 72
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6488549618320754 88
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725898> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.09541984732824638 11
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.2290076335877913 21
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.3244274809160377 31
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.49618320610688116 43
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.553435114503829 51
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.6488549618320754 73
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6679389312977246 89
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a38d0> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.09541984732824638 12
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.2290076335877913 22
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.3244274809160377 32
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.49618320610688116 44
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.553435114503829 52
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.6488549618320754 74
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6679389312977246 90
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.09541984732824638 13
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.2290076335877913 23
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.3244274809160377 33
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.49618320610688116 45
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.553435114503829 53
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.6488549618320754 75
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6679389312977246 91
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.09541984732824638 14
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.2290076335877913 24
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.3244274809160377 34
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.49618320610688116 46
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.553435114503829 54
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.6488549618320754 76
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6679389312977246 92
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #6
root->8->14->5->0->5->18
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3b00> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.11450381679389565 15
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.24809160305344058 25
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.34351145038168696 35
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.5152671755725304 47
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.5725190839694783 55
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.6679389312977246 77
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.6870229007633739 93
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.0763358778625971 5
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.13358778625954493 16
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.26717557251908985 26
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.36259541984733623 36
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.5343511450381797 48
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.5916030534351275 56
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.6870229007633739 78
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.7061068702290232 94
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5be0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.09541984732824638 6
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.1526717557251942 17
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.28625954198473913 27
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.3816793893129855 37
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.553435114503829 49
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.6106870229007768 57
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.7061068702290232 79
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.7251908396946725 95
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5d30> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5d68> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfc50> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.11450381679389565 7
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.17175572519084348 18
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.3053435114503884 28
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.4007633587786348 38
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.5725190839694783 50
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.6297709923664261 58
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.7251908396946725 80
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.7442748091603217 96
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b77255f8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.13358778625954493 8
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.19083969465649275 19
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.3244274809160377 29
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.41984732824428406 39
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.5916030534351275 51
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.6488549618320754 59
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.7442748091603217 81
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.763358778625971 97
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebe80> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eba20> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.1526717557251942 9
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.20992366412214203 20
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.34351145038168696 30
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.43893129770993333 40
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.6106870229007768 52
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.6679389312977246 60
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.763358778625971 82
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.7824427480916203 98
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #7
root->8->14->5->0->5->18->8
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5c50> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5048> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.17175572519084348 10
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.2290076335877913 21
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.36259541984733623 31
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.4580152671755826 41
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.6297709923664261 53
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.6870229007633739 61
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.7824427480916203 83
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.8015267175572696 99
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b77255c0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e57f0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0763358778625971 5
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.19083969465649275 11
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.24809160305344058 22
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.3816793893129855 32
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.4770992366412319 42
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.6488549618320754 54
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.7061068702290232 62
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.8015267175572696 84
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.8206106870229188 100
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725518> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.09541984732824638 6
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.20992366412214203 12
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.26717557251908985 23
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.4007633587786348 33
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.49618320610688116 43
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.6679389312977246 55
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.7251908396946725 63
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.8206106870229188 85
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.8396946564885681 101
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5048> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.09541984732824638 7
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.20992366412214203 13
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.26717557251908985 24
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.4007633587786348 34
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.49618320610688116 44
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.6679389312977246 56
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.7251908396946725 64
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.8206106870229188 86
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.8396946564885681 102
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.09541984732824638 8
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.20992366412214203 14
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.26717557251908985 25
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.4007633587786348 35
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.49618320610688116 45
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.6679389312977246 57
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.7251908396946725 65
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.8206106870229188 87
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.8396946564885681 103
Completed Iteration #9
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fca90> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5048> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.11450381679389565 9
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.2290076335877913 15
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.28625954198473913 26
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.41984732824428406 36
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.5152671755725304 46
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.6870229007633739 58
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.7442748091603217 66
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.8396946564885681 88
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.8587786259542174 104
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcf60> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5048> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.13358778625954493 10
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.24809160305344058 16
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.3053435114503884 27
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.43893129770993333 37
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.5343511450381797 47
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.7061068702290232 59
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.763358778625971 67
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.8587786259542174 89
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.8778625954198667 105
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd720080b38> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8160> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.1526717557251942 11
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.26717557251908985 17
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.3244274809160377 28
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.4580152671755826 38
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.553435114503829 48
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.7251908396946725 60
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.7824427480916203 68
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.8778625954198667 90
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.8969465648855159 106
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e57f0> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.1526717557251942 12
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.26717557251908985 18
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.3244274809160377 29
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.4580152671755826 39
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.553435114503829 49
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.7251908396946725 61
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.7824427480916203 69
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.8778625954198667 91
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.8969465648855159 107
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc828> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8160> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.17175572519084348 13
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3668> 0.28625954198473913 19
backprop <src.mcts.MCTS_Node object at 0x7fd72019a748> 0.34351145038168696 30
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.4770992366412319 40
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.5725190839694783 50
backprop <src.mcts.MCTS_Node object at 0x7fd720140da0> 0.7442748091603217 62
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea4a8> 0.8015267175572696 70
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.8969465648855159 92
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1630> 0.9160305343511652 108
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #8
root->8->14->5->0->5->18->8->1
Best Reward: 0.019083969465649275
iteration: 51
found coverage increase 0.019083969465649275
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcfd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 2500
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018cd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7630> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69baba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69baba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69baba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69baba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bab38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725b00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69046d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69169b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201409b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7201a60b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720080da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720080a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200800f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200806a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200444e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004eb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f54cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004eb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72002a2b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f54080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201cbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720044588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201bec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72004ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e7dcc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201409b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd72005b9b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720140390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e92208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e920f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720fdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7986caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e92710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72008c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7986caa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7963131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd796313438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7963136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7963136a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7963136a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e92160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7986caa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720044f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f8bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f8bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f5e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f8bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec480da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f8bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f8bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f32fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f5eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7986ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f48f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720f480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e5b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7963e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f48ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720ec1828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72008c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720f32f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201a67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72019ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ff6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72017eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72005bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0190839694656475 13
Completed Iteration #14
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201409b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201a69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0190839694656475 14
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72004ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72019ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0190839694656475 15
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd72017e710> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7df28> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.038167938931295 16
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72002af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72017eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.038167938931295 17
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.038167938931295 18
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e476d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.038167938931295 19
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720080208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.038167938931295 20
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #0
root
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
coverage_call_count 2800
Completed Iteration #1
Best Reward: 0.0190839694656475
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e92a58> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0572519083969425 21
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd72017e4e0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e477b8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.07633587786259 22
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720140c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92a58> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.0572519083969425 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.07633587786259 23
Completed Iteration #6
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.0572519083969425 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.07633587786259 24
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720eece80> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.07633587786259 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.0954198473282375 25
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d320> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.0954198473282375 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.114503816793885 26
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720eeca58> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e477b8> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.114503816793885 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.1335877862595325 27
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.114503816793885 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.1335877862595325 28
Completed Iteration #13
Best Reward: 0.0190839694656475
Completed Iteration #14
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.114503816793885 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.1335877862595325 29
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471630> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.1335877862595325 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.15267175572518 30
Completed Iteration #16
Best Reward: 0.0190839694656475
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471470> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.15267175572518 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.1717557251908275 31
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419828> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.1717557251908275 14
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.190839694656475 32
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424940> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.07633587786259 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.190839694656475 15
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.2099236641221225 33
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464be0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424eb8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.0954198473282375 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.2099236641221225 16
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.22900763358777 34
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424128> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464f28> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.114503816793885 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.22900763358777 17
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.2480916030534175 35
Completed Iteration #2
Best Reward: 0.0190839694656475
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464080> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.1335877862595325 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.2480916030534175 18
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.267175572519065 36
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Completed Iteration #6
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.1335877862595325 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.2480916030534175 19
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.267175572519065 37
Completed Iteration #7
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.1335877862595325 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.2480916030534175 20
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.267175572519065 38
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785a20> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.15267175572518 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.267175572519065 21
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.2862595419847125 39
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e47080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7986caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.15267175572518 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.267175572519065 22
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.2862595419847125 40
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7986caa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.15267175572518 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.267175572519065 23
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.2862595419847125 41
Completed Iteration #13
Best Reward: 0.0190839694656475
Completed Iteration #14
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720eec6d8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424eb8> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.1717557251908275 14
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.2862595419847125 24
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.30534351145036 42
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.1717557251908275 15
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.2862595419847125 25
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.30534351145036 43
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720eec3c8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dc18> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.190839694656475 16
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.30534351145036 26
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.3244274809160075 44
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.190839694656475 17
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.30534351145036 27
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.3244274809160075 45
Completed Iteration #21
Best Reward: 0.0190839694656475
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419e10> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419908> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785a20> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.07633587786259 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.2099236641221225 18
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.3244274809160075 28
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.343511450381655 46
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424b70> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424eb8> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.22900763358777 19
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.343511450381655 29
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.3625954198473025 47
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #2
root->5->11
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464b38> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.0954198473282375 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.2480916030534175 20
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.3625954198473025 30
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.38167938931295 48
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.114503816793885 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.267175572519065 21
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.38167938931295 31
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.4007633587785975 49
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1c18> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d10f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424940> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.1335877862595325 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.2862595419847125 22
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.4007633587785975 32
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.419847328244245 50
Completed Iteration #6
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2898> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.15267175572518 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.30534351145036 23
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.419847328244245 33
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.4389312977098925 51
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1a90> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.1717557251908275 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.3244274809160075 24
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.4389312977098925 34
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.45801526717554 52
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d8d0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720780> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1a90> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.190839694656475 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.343511450381655 25
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.45801526717554 35
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.4770992366411875 53
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4715c0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e92160> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.2099236641221225 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.3625954198473025 26
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.4770992366411875 36
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.496183206106835 54
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47854e0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.22900763358777 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.38167938931295 27
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.496183206106835 37
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.5152671755724825 55
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #3
root->5->11->5
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424860> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.2480916030534175 14
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.4007633587785975 28
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.5152671755724825 38
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.53435114503813 56
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.0572519083969425 5
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.2480916030534175 15
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.4007633587785975 29
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.5152671755724825 39
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.53435114503813 57
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd720e9d470> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47202b0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.07633587786259 6
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.267175572519065 16
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.419847328244245 30
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.53435114503813 40
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.5534351145037775 58
Completed Iteration #2
Best Reward: 0.0190839694656475
Completed Iteration #3
Best Reward: 0.0190839694656475
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464470> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c50> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.0954198473282375 7
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.2862595419847125 17
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.4389312977098925 31
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.5534351145037775 41
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.572519083969425 59
Completed Iteration #5
Best Reward: 0.0190839694656475
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2160> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d16d8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.114503816793885 8
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.30534351145036 18
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.45801526717554 32
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.572519083969425 42
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.5916030534350725 60
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9978> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4647f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.1335877862595325 9
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.3244274809160075 19
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.4770992366411875 33
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.5916030534350725 43
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.61068702290072 61
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9f60> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47f6c50> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.15267175572518 10
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.343511450381655 20
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.496183206106835 34
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.61068702290072 44
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.6297709923663675 62
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1898> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.1717557251908275 11
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.3625954198473025 21
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.5152671755724825 35
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.6297709923663675 45
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.648854961832015 63
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709400> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464c18> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.190839694656475 12
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.38167938931295 22
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.53435114503813 36
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.648854961832015 46
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.6679389312976625 64
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709c88> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464c18> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.2099236641221225 13
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.4007633587785975 23
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.5534351145037775 37
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.6679389312976625 47
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.68702290076331 65
Completed Iteration #17
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709978> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.22900763358777 14
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.419847328244245 24
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.572519083969425 38
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.68702290076331 48
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.7061068702289575 66
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6916f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47202b0> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.22900763358777 15
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.419847328244245 25
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.572519083969425 39
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.68702290076331 49
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.7061068702289575 67
Completed Iteration #21
Best Reward: 0.0190839694656475
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720eecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4647f0> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.22900763358777 16
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.419847328244245 26
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.572519083969425 40
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.68702290076331 50
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.7061068702289575 68
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9128> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464c18> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.2480916030534175 17
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.4389312977098925 27
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.5916030534350725 41
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.7061068702289575 51
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.725190839694605 69
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2f28> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4647f0> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.267175572519065 18
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.45801526717554 28
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.61068702290072 42
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.725190839694605 52
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.7442748091602525 70
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #4
root->5->11->5->11
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Completed Iteration #2
Best Reward: 0.0190839694656475
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.07633587786259 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.2862595419847125 19
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.4770992366411875 29
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.6297709923663675 43
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.7442748091602525 53
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.7633587786259 71
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709278> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.0954198473282375 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.30534351145036 20
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.496183206106835 30
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.648854961832015 44
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.7633587786259 54
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.7824427480915475 72
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709278> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.0954198473282375 7
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.30534351145036 21
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.496183206106835 31
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.648854961832015 45
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.7633587786259 55
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.7824427480915475 73
Completed Iteration #13
Best Reward: 0.0190839694656475
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e46417b8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.114503816793885 8
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.3244274809160075 22
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.5152671755724825 32
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.6679389312976625 46
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.7824427480915475 56
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.801526717557195 74
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #5
root->5->11->5->11->3
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b777cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.114503816793885 9
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.3244274809160075 23
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.5152671755724825 33
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.6679389312976625 47
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.7824427480915475 57
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.801526717557195 75
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.114503816793885 10
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.3244274809160075 24
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.5152671755724825 34
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.6679389312976625 48
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.7824427480915475 58
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.801526717557195 76
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ed7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.0190839694656475 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.114503816793885 11
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.3244274809160075 25
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.5152671755724825 35
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.6679389312976625 49
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.7824427480915475 59
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.801526717557195 77
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9be0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b92b0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.038167938931295 6
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.1335877862595325 12
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.343511450381655 26
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.53435114503813 36
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.68702290076331 50
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.801526717557195 60
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.8206106870228425 78
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424080> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.0572519083969425 7
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.15267175572518 13
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.3625954198473025 27
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.5534351145037775 37
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.7061068702289575 51
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.8206106870228425 61
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.83969465648849 79
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1748> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709588> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.07633587786259 8
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.1717557251908275 14
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.38167938931295 28
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.572519083969425 38
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.725190839694605 52
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.83969465648849 62
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.8587786259541375 80
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b92b0> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.07633587786259 9
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.1717557251908275 15
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.38167938931295 29
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.572519083969425 39
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.725190839694605 53
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.83969465648849 63
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.8587786259541375 81
Completed Iteration #6
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c160> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e390> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.0954198473282375 10
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.190839694656475 16
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.4007633587785975 30
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.5916030534350725 40
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.7442748091602525 54
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.8587786259541375 64
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.877862595419785 82
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f438> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c8d0> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.114503816793885 11
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.2099236641221225 17
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.419847328244245 31
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.61068702290072 41
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.7633587786259 55
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.877862595419785 65
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.8969465648854325 83
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b92b0> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.114503816793885 12
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.2099236641221225 18
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.419847328244245 32
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.61068702290072 42
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.7633587786259 56
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.877862595419785 66
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.8969465648854325 84
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.114503816793885 13
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.2099236641221225 19
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.419847328244245 33
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.61068702290072 43
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.7633587786259 57
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.877862595419785 67
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.8969465648854325 85
Completed Iteration #16
Best Reward: 0.0190839694656475
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b777cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.114503816793885 14
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.2099236641221225 20
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.419847328244245 34
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.61068702290072 44
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.7633587786259 58
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.877862595419785 68
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.8969465648854325 86
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424e10> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b92b0> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.1335877862595325 15
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.22900763358777 21
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.4389312977098925 35
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.6297709923663675 45
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.7824427480915475 59
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.8969465648854325 69
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.91603053435108 87
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f198> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c5f8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.15267175572518 16
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.2480916030534175 22
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.45801526717554 36
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.648854961832015 46
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.801526717557195 60
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.91603053435108 70
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.9351145038167274 88
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #6
root->5->11->5->11->3->1
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641080> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.1717557251908275 17
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.267175572519065 23
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.4770992366411875 37
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.6679389312976625 47
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.8206106870228425 61
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.9351145038167274 71
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.954198473282375 89
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e469ae80> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.190839694656475 18
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.2862595419847125 24
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.496183206106835 38
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.68702290076331 48
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.83969465648849 62
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.954198473282375 72
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.9732824427480224 90
Completed Iteration #2
Best Reward: 0.0190839694656475
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.0572519083969425 5
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.190839694656475 19
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.2862595419847125 25
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.496183206106835 39
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.68702290076331 49
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.83969465648849 63
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.954198473282375 73
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.9732824427480224 91
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.0572519083969425 6
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.190839694656475 20
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.2862595419847125 26
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.496183206106835 40
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.68702290076331 50
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.83969465648849 64
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.954198473282375 74
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.9732824427480224 92
Completed Iteration #5
Best Reward: 0.0190839694656475
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.0572519083969425 7
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.190839694656475 21
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.2862595419847125 27
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.496183206106835 41
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.68702290076331 51
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.83969465648849 65
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.954198473282375 75
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.9732824427480224 93
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.0572519083969425 8
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.190839694656475 22
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.2862595419847125 28
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.496183206106835 42
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.68702290076331 52
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.83969465648849 66
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.954198473282375 76
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.9732824427480224 94
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a0b8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.07633587786259 9
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.2099236641221225 23
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.30534351145036 29
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.5152671755724825 43
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.7061068702289575 53
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.8587786259541375 67
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.9732824427480224 77
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.99236641221367 95
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.07633587786259 10
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.2099236641221225 24
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.30534351145036 30
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.5152671755724825 44
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.7061068702289575 54
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.8587786259541375 68
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.9732824427480224 78
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.99236641221367 96
Completed Iteration #14
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec471390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.07633587786259 11
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.2099236641221225 25
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.30534351145036 31
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.5152671755724825 45
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.7061068702289575 55
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.8587786259541375 69
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.9732824427480224 79
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 0.99236641221367 97
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae160> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.0954198473282375 12
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.22900763358777 26
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.3244274809160075 32
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.53435114503813 46
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.725190839694605 56
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.877862595419785 70
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 0.99236641221367 80
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.0114503816793174 98
Completed Iteration #17
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.114503816793885 13
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.2480916030534175 27
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.343511450381655 33
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.5534351145037775 47
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.7442748091602525 57
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.8969465648854325 71
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.0114503816793174 81
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.030534351144965 99
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641550> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469ab70> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469ae80> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.1335877862595325 14
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.267175572519065 28
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.3625954198473025 34
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.572519083969425 48
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.7633587786259 58
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.91603053435108 72
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.030534351144965 82
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.0496183206106124 100
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ee48> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.15267175572518 15
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.2862595419847125 29
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.38167938931295 35
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.5916030534350725 49
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.7824427480915475 59
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.9351145038167274 73
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.0496183206106124 83
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.06870229007626 101
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469ab70> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e469ae80> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.15267175572518 16
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.2862595419847125 30
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.38167938931295 36
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.5916030534350725 50
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.7824427480915475 60
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.9351145038167274 74
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.0496183206106124 84
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.06870229007626 102
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.15267175572518 17
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.2862595419847125 31
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.38167938931295 37
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.5916030534350725 51
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.7824427480915475 61
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.9351145038167274 75
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.0496183206106124 85
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.06870229007626 103
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #7
root->5->11->5->11->3->1->2
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec668> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec588> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.1717557251908275 18
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.30534351145036 32
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.4007633587785975 38
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.61068702290072 52
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.801526717557195 62
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.954198473282375 76
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.06870229007626 86
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.0877862595419074 104
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae048> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9748> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.190839694656475 19
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.3244274809160075 33
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.419847328244245 39
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.6297709923663675 53
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.8206106870228425 63
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.9732824427480224 77
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.0877862595419074 87
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.106870229007555 105
Completed Iteration #3
Best Reward: 0.0190839694656475
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.0572519083969425 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.190839694656475 20
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.3244274809160075 34
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.419847328244245 40
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.6297709923663675 54
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.8206106870228425 64
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.9732824427480224 78
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.0877862595419074 88
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.106870229007555 106
Completed Iteration #5
Best Reward: 0.0190839694656475
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec464940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.0572519083969425 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.190839694656475 21
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.3244274809160075 35
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.419847328244245 41
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.6297709923663675 55
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.8206106870228425 65
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.9732824427480224 79
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.0877862595419074 89
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.106870229007555 107
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d15c0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e668> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.07633587786259 7
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.2099236641221225 22
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.343511450381655 36
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.4389312977098925 42
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.648854961832015 56
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.83969465648849 66
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 0.99236641221367 80
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.106870229007555 90
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.1259541984732024 108
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeac8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec588> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.0954198473282375 8
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.22900763358777 23
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.3625954198473025 37
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.45801526717554 43
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.6679389312976625 57
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.8587786259541375 67
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 1.0114503816793174 81
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.1259541984732024 91
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.14503816793885 109
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4720860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9748> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.0954198473282375 9
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.22900763358777 24
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.3625954198473025 38
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.45801526717554 44
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.6679389312976625 58
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.8587786259541375 68
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 1.0114503816793174 82
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.1259541984732024 92
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.14503816793885 110
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772b38> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e668> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.114503816793885 10
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.2480916030534175 25
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.38167938931295 39
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.4770992366411875 45
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.68702290076331 59
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.877862595419785 69
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 1.030534351144965 83
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.14503816793885 93
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.1641221374044974 111
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772710> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77725f8> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.1335877862595325 11
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.267175572519065 26
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.4007633587785975 40
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.496183206106835 46
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.7061068702289575 60
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.8969465648854325 70
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 1.0496183206106124 84
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.1641221374044974 94
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.183206106870145 112
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b77400b8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec588> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.15267175572518 12
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.2862595419847125 27
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.419847328244245 41
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.5152671755724825 47
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.725190839694605 61
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.91603053435108 71
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 1.06870229007626 85
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.183206106870145 95
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.2022900763357924 113
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740c50> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.1717557251908275 13
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.30534351145036 28
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.4389312977098925 42
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.53435114503813 48
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.7442748091602525 62
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.9351145038167274 72
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 1.0877862595419074 86
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.2022900763357924 96
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.22137404580144 114
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1cc0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77725f8> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.190839694656475 14
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.3244274809160075 29
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.45801526717554 43
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.5534351145037775 49
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.7633587786259 63
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.954198473282375 73
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 1.106870229007555 87
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.22137404580144 97
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.2404580152670874 115
Completed Iteration #19
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aecc0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9748> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.2099236641221225 15
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.343511450381655 30
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.4770992366411875 44
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.572519083969425 50
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.7824427480915475 64
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.9732824427480224 74
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 1.1259541984732024 88
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.2404580152670874 98
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.259541984732735 116
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec780> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772dd8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.22900763358777 16
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.3625954198473025 31
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.496183206106835 45
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.5916030534350725 51
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.801526717557195 65
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 0.99236641221367 75
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 1.14503816793885 89
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.259541984732735 99
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.2786259541983824 117
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740828> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772f28> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeda0> 0.2480916030534175 17
backprop <src.mcts.MCTS_Node object at 0x7fd6e4785b70> 0.38167938931295 32
backprop <src.mcts.MCTS_Node object at 0x7fd6ec4246d8> 0.5152671755724825 46
backprop <src.mcts.MCTS_Node object at 0x7fd6ec424a20> 0.61068702290072 52
backprop <src.mcts.MCTS_Node object at 0x7fd6e47d1080> 0.8206106870228425 66
backprop <src.mcts.MCTS_Node object at 0x7fd720e9dcc0> 1.0114503816793174 76
backprop <src.mcts.MCTS_Node object at 0x7fd720e7d0b8> 1.1641221374044974 90
backprop <src.mcts.MCTS_Node object at 0x7fd720e47550> 1.2786259541983824 100
backprop <src.mcts.MCTS_Node object at 0x7fd720e929e8> 1.29770992366403 118
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #8
root->5->11->5->11->3->1->2->0
Best Reward: 0.0190839694656475
iteration: 64
found coverage increase 0.0190839694656475
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77980f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec419ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dde48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77726d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77864e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77864e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77864e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46827f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47712e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77983c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77983c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46caf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77983c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69575f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967c88> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201006d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201007f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201007f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201006d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967a90> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69baba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201002e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201002e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201002e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69baba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bad30> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69674e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46cab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69576a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69576a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69674e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69baf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69baf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69baf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bafd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69bafd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6904be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69570f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77259e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77259e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77259e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77259e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682c50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 3400
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69967f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69967f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b77258d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b38d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3e10> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 3500
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4676630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200eab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72018c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b601ae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601ae80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5668> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa320> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 8.81679389312977
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72018c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd55f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd72012a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b886a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b882e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b882e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b500b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6925748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b500b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b882e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 3700
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbee80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd72012a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ba748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b106a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10198> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbeb70> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b105c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7798390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b777c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6967e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200b3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b105c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b314a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b314a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b314a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b314a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b20b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7725d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e469a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bd5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7740a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bbe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b601a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b602ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5bfa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69fceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b7d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0c50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b31c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b50d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5afa4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b10e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b602aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5af0080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8dcf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a6e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a6e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab88d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a6e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a6e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a8d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5b88898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5ab88d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dac8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a6e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a6e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a6e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a6e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a6e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dc50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a6e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5cf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4dfd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201589b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb7f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957cc0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957cc0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200a3da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720100860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69962e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7200d80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69962e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5c400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200ea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7201005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 4100
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ddfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a20> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47717f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77dd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a44e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47a4668> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a5ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b6957a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7772358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5be4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46dd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4682dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7786f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720ea7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77cc588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e4771588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6ec43c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69967b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720158f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720100cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e5b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b69e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69967b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e470ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720158f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd720e4f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e47ece48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b6996908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e470f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e47b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b77ae550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 7
Completed Iteration #12
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b5a4d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e4641c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6b77aeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b7709a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6b69eb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd6e475ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd6e46b9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd7200eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd7201005c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd6e46a9f28> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 8.81679389312977
initial coverage: 8.58779
time passed (minutes): 60.0149
iterations: 113
number of new inputs: 448
final coverage: 8.81679
total coverage increase: 0.229008
