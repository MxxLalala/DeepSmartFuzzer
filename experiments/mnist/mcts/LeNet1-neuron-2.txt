Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f5b7db84f28>, tc2=<function tc2 at 0x7f5b7db93048>, tc3=<function tc3 at 0x7f5b7db93158>, tfc_threshold=33000000, time_period=3600, verbose=True)
initial coverage: 41.6667
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fa90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fa90> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2463fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24646400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2463fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2463fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24646400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7984a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2463fc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7482e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7481d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7481d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7481d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2463f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7980b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7982b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7983c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2463f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc73add8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7234a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7234a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 200
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7353c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d16d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6954a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6954a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6954a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 300
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cdd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7355f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7180f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6953c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d86a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d86a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7900f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7906d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7900f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7906d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7182e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7182e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2463fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d19e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7986d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7641d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7640f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770160> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7019b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b4c169f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5adc701a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 600
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ade48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246a38d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24685be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246b7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b24685da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246b7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6730f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc701240> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246adef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b8d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b4c0bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 700
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246eda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7645f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7645f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7489b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d83c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7489b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d83c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24685cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7180b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7357b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7180b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2463f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7357b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7180b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7180b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7180b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc673a20> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24646908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b74e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7189b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7180b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7180b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7180b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6953c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6953c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ac8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246a39b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7184e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 1000
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f05f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f05f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d17f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7352b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c00b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c00b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c05f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7188d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40123c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40125c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40123c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40125c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40812b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40295f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40811d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40811d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 16
Completed Iteration #16
Best Reward: 0
coverage_call_count 1200
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784048> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05054a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05054a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa05124a8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04755f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04755f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04755f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40126a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05052b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05052b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 1400
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05052b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04597f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bf28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40126a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40126a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04754e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40126a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40126a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 1500
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7887f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d22e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c52b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7886d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7887f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40126a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40126a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40126a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7889e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7889e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7889e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 1600
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7780b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7842e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7842e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7847f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6cf8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a9e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718278> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718278> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2463f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1208> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7cc0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24685b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2463f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b24685da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6736d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc784d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784d68> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7489e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 1900
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246eda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b4c0846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b4c0846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af0b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7019e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05122b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a35c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 15
Completed Iteration #21
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a35c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7019b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a34e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a34e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7016d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc701160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7909b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7909b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ada90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc790b70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ada90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b42b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ada90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459eb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04add30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04947b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04add30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7886a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6958d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7887f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7887f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa05055f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05055f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d22b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05053c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40813c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e511d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cda58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723840f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 13
Completed Iteration #11
Best Reward: 0
coverage_call_count 2500
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e637f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e510b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ef60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029748> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7882e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd4e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723767f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723765c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723765c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723767f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723765c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723600f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723600f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723600f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723600f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723764a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376080> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723242e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723242e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723242e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722fff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722fff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722abbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722abbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722fff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b320> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723769e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723766d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723766d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722005c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72274208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bca20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722150b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722150b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722150b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722150b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72215278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2900
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40128d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05123c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71cb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b4c0fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7019e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7019e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 3000
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7013c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7013c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40816d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 11
Completed Iteration #18
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246adba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0550> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b4c0846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722003c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722003c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722003c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7708d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24646748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24646748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5c0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723e37b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04596d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722745f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722745f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04946a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04946a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04946a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7887f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722745f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72274be0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0080> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b4c0846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05122b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723246d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723246d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c95c0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2463f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04599b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04594e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4208> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e418d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630f0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7581d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7581d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723241d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723241d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723241d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723241d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723764e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723764e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722abc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e518d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2463f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723602e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7844e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ed68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ed68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723602e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723601d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 3600
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e630b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047ff60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722fff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722fffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ada0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ada0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffc88> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7585f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7585f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04add30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7585f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a7f0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723602e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7018d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7018d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722152e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715504e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715504e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b8d0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723842b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723842b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723842b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715390b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715394a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715397b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ad68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db00> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1748> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715505f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715505f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e32b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71560668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723842b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723842b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3198> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 4000
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca58> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714127b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e3c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5a71471eb8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714715c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714715c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714715c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71471518> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714128d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714129b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714126a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714129b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714121d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd160> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714129b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723842b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb080> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e710> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d464e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d464e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714129b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714126a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 4300
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25470> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ed68> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc790eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df02b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df02b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7902b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71420b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7902b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714126a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714712e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714712e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 4400
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a80b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8390> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71539780> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152aa90> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715394a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71539358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 16
Completed Iteration #18
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157dc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723764a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723764a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157dc50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714128d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714128d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714128d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbe80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 4600
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc784cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723bda58> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722abe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dcef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715508d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 8
Completed Iteration #14
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d68> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715602e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5a72e635f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d28d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788438> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc695828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc65ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac403cc18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24685da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5adc764320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7482e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7482e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c860> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c05f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0978> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722fff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722fff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7012e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b2469f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05122b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc673550> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6a6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 21
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c7b8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722005c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722159b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc358> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 5100
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d460f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d467f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d460f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d462e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d467f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722749b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc79a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722000b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215f60> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723605c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722151d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ec18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e2e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc673cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1908> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bcfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d302e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bcfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d302e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bcfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d302e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d252e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722157b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc764e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e198> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf488d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf482e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf482e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 19
Completed Iteration #21
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf488d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5c18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf486a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf486a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf486a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf486a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5160> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722157b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722157b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf312e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf312e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf317b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe93c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef65c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef65c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf314a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf315f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf315f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf315f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc1d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be493c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be751d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be751d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d19b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d19b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c34a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be280b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 7
Completed Iteration #10
Best Reward: 0
coverage_call_count 5800
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be280b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28630> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebce10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60e10> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be280b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7cc0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9729b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9000b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9009e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9729b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9004a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9004a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9000b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9004e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9004a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9116d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be835f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 6000
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d04e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d04e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9118d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d08d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9729e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9729e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9729e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9729e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911ba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cda0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8528d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8528d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7234a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7234aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c2b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be600f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be600f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf319e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf319e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be604e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc735860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be499b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be497f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 6300
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be604a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf0f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf487f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b49d9a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b99c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebc390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60fd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be604e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc735f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b852668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d304e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d304e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d304e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d30080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25588> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa05122b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe92e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72200d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc79acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e9b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be49a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 6500
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf489b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723e34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d469b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d460f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72324ac8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc695550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723249b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc71c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac405f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc673358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70ddbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04755c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72274f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246cb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246cb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246cb5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b246cb5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 6600
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722005c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc73a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc7981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc65bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc718c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b98ab2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b24646860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24646908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5b24646908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b246a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4012ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc748b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc770e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5aa047f278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc75bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc798518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d25390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf31a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc798978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc73ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff860> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bef6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72200ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bebca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72324320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c778518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72324908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d5e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7147eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf48f28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b42b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d46748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d6e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0505080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b42b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c79ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be60320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72360470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0512710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc764cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723246d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72360e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0475dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723246d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b53c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c758dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 10
Completed Iteration #8
Best Reward: 0
coverage_call_count 6800
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7147eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf9b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa047fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722c9b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc695eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722bc128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715609b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71560198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac405fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7c59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a72384e10> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc701ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70db7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72274320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7233ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1588> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c76b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5aa04941d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0459ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c788d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a715605f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc723470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715391d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e51048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715391d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a715391d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e632b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e632b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b4a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac4081eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5b4c0846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7af828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc748fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40814a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7149bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7157d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a87f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc7b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa0494a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71550ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722fffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c7b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72376048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfb5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc770f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5adc701ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722fffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a7152a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72376c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a723760b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7149b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71539358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1b70> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa05122b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722155c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722157b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a722155c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722155c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5898> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf1f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5ac403c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc6952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e7b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722153c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a723cd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ac18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71420a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72384080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be759b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be759b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be759b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be759b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e41cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be831d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7233c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ceb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bfe9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b91d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5afc67c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b91d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be755f8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc7016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a722153c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf905c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf905c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf905c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf905c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714a89e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee56a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa044bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714a8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a723f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf905c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf905c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a715399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a72215080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a714bc6a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5afc723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee56d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 16
Completed Iteration #23
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9118d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0cf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9112b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9114a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9110f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9114a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71539358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be83dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9114a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70cc5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9729b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71420828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71471c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be288d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be288d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71412940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be1ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8665c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 7400
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8665c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa789e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa789b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa789b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa789b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa789b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78278> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7229beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9729b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70dcdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa666d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a71471c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5aa20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a714d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa664a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9003c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9b9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 7
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 7500
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 8
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c29b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2208> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b88c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5be75ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70d8a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b900b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf57c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72e63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08780> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa666d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a89e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a81d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa5a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a7152ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5994a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71560cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a72215080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71550860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a70df0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5994a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9003c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5994a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a8c70e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5997b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8665c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5994a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5adc790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5767f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 11
Completed Iteration #14
Best Reward: 0
coverage_call_count 7700
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5767f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5699e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2518> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5ac40c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576da0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5be28a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a722ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b99e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8e0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 302
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9112b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 303
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 13
Completed Iteration #12
Best Reward: 0
coverage_call_count 7800
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 304
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa78198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 305
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b99e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 306
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb00> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 307
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 7900
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b866f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 308
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b972e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a71412358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 309
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4767b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4761d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4769e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4769e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b9c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4769e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4767b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 310
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 311
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 8000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4761d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa08dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4761d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4761d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 312
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4641d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4641d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 313
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f880b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5b911128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a464908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f979b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff31d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 314
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59faadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 5
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 6
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59faad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 7
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 8
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 9
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 10
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59faad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97be0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 315
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 8100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bee5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 316
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa084e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a599940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d41d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa084e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a523e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d41d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 317
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f038d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 318
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5bf902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a569198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03be0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 319
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 8200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a50a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59faa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a576f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4ef470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4642e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a476588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48aeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f761d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f761d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5aa04bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb208> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 320
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f888d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f888d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f888d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f035f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5aa66b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 321
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecaa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecaa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecaa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecacf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca9e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 322
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f885f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 18
Completed Iteration #23
Best Reward: 0
coverage_call_count 8300
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a59eddbe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 323
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f039e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a43a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecaef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5b8d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a44c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59faada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59ff3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59ecafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4763c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a48a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59eca630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59edd898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4bc8d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 324
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a4d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f97a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a5a423588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59fbbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f76828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a59f88a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59f03828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f5a5a5e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f5a59efc7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f5a59fcd5c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 325
found coverage increase 0
Current Total Coverage 41.66666666666667
initial coverage: 41.6667
time passed (minutes): 60.0236
iterations: 326
number of new inputs: 0
final coverage: 41.6667
total coverage increase: 0
