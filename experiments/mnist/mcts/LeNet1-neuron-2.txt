Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fa1c5ea2f28>, tc2=<function tc2 at 0x7fa1c5eb3048>, tc3=<function tc3 at 0x7fa1c5eb3158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 41.6667
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747306a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174748a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174748a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174748a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174748a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174748a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa174730a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17473f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bf28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174783d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17473f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746697f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174669438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7240> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf98> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7961d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174748898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7961d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7961d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174748898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b00> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 400
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f72b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b97f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f72b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eada0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723080> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7413c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7410f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6462b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6464e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b518> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b518> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6464e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b518> 0.0 9
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be10> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa19214e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17c1487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174783dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1921c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c668240> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 600
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479da58> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747b7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747b7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7627b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7627b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1e477aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7628d0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174783ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b908> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7418d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7418d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17479d358> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c45c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aeba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174748588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174748588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174748588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1e477a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac400> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747489e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aeda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aedd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730c88> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746694a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746695c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746695c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746694a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746694a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746694a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b38> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746693c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746693c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 6
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174748588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 7
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 8
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 11
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 12
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7230f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7230f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7230f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7230f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7230f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174783ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67def0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6682e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7da0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0365f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0365f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0365f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0365f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c043b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7743c8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1e477a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6685c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6685c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f78d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b94a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1e477a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0436d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0436d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 14
Completed Iteration #24
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1951d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1273c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c183828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6685c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1832e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1832e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1954a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6469b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1274e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1274e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1274e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 21
Completed Iteration #22
Best Reward: 0
coverage_call_count 1300
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1115f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1517f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1044e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1044e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1117f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1110f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0aba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0aba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0aba58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c111278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1115f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1115f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 12
Completed Iteration #18
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127748> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05ff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0897b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c089908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1113c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc18> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc18> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abe10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1510f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1957f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0074e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0197b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0073c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0073c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1515c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0073c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82335f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82481d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82587b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82587b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82587b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82580b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0479e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82487f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82487f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82487f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6466a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6466a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6466a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6466a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6468d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 1700
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d49e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7c88> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1e477aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ace10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ace10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7d30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7962b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 2
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174783e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7235f8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747cb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7840f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 8
Completed Iteration #12
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7840f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1e477aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747eeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa17463be48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82332b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82332b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82337b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82337b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c762320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174783e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa19214eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82337b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6464a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0597f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0596a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0597f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c059978> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be80> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1921be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174783e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c723550> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1111d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c111b38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1277b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6685c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6685c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aefd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747303c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0439b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c67da58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1921c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1839b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0079e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 2200
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7413c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7413c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c0367b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c036240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7416d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7416d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7416d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1921c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa19214e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0073c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1839b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7962b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174730400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4c88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0479e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c0431d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82587f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82587f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258550> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07420f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07420f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ba8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
coverage_call_count 2400
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07504e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07504e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07653c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07653c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07653c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07504e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1516d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07504a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 20
Completed Iteration #22
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ead68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479dd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d470> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07506a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07506a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07506a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c06a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b908> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37880b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7416d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7416d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7416d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 2800
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747309b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17473f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747309b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747309b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1837f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c183438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1837f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1921be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c64e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1830b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c655668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7626d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0908> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82330b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7960b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17468bdd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1e477aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746699b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1e477aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1e477aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1e477aac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1e477aac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82332b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82332b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7749b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7749b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 3100
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0194e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0194e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0194e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0194e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f1d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ead68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37880b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82336a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37887b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f4e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07428d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07422e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07422e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07422e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788780> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37886a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37886a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dd30> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747aec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82487f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9eb8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1953c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1953c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1953c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c41d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37883c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37883c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0363c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0365c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 8
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 9
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 10
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 11
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 12
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c07f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c07f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c07f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcc50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0075c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0075c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa14c007b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc9e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071df28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c974e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c974a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c974a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37420f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c774b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 17
Completed Iteration #22
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c488d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c488d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c488d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c730b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c026d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c026d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c022e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c022e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c022e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c026d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c026d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d87b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d87b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c369b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c027b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c027b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 19
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c365f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36208> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c978d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c978d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c026d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17872b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17879e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17879e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17879e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17875f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37429e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17877b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37429e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17949e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 7
Completed Iteration #13
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17baac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794dd8> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17777f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17026a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17023c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17026a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17023c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17023c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17baba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17023c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17023c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777b38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17162e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17162e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17026a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c026d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17771d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17771d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17024a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17024a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17024a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777940> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16844e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16844e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b16847f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17028d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 12
Completed Iteration #10
Best Reward: 0
coverage_call_count 4100
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258d30> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dd68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 4200
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16154e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c9b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73128> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007208> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07659e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07659e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07509e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a5f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c589b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c589b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b048> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1119b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0473c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c111da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c587b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0473c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d7b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c737b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c111f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c734a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c737b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0895f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0895f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c582e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c582e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c582e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c582e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c582e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17473f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c582e8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746690b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa17468b828> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6680f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1277b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37885c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1277f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c089d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 10
Completed Iteration #15
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0197b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0195c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37426d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c762630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37426d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17463bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1275f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1275f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37428d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1042b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1042b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c898> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c104860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c50> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37425f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37425f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37425f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777a90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c059f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072ca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17024e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16842b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16842b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17027f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17027f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f09b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c019550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0f60> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17162b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17162b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c0079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16849e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17946d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 5100
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694358> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1e7df3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddcc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794048> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c360f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c029b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c029b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c029b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c029b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08867f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b08862b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17468b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c024a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08869b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16944e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08520f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08520f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08864a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08520f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08864a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 6
Completed Iteration #8
Best Reward: 0
coverage_call_count 5300
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08632b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08632b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08635f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08998d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c151978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08997b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f470> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c360f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36908> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb38> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 5400
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa20> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ac18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c360f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c2b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa174669160> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03496d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03772b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b03fff98> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03211d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03212e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cf60> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03775f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03775f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03775f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03775f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03779b0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b35c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03776a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e6d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 4
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 5
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 16
Completed Iteration #24
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03219b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02868d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377358> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e1d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02417b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03770b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02866a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03214e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03214e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8eb8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02217f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02217b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02217b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02311d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02311d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02216a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231320> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e4a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e04e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17463ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0828> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c0597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01949e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01949e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01949e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea1d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17468b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f98> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c367f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c367f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17948d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c367f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36278> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c362e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 16
Completed Iteration #14
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c362e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a02b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a02b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c059f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a02b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c104160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a748> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a048> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c762b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c019550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37db7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c151588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1787160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747b71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0da0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37c0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17029e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16f0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17029e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b083c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa1746c46a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c655860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c774518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e065b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c48a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b04a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c668c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37dba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c019fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742358> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17028d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 6300
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0194358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37884a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0fd0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1794978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1694780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c70fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b087fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa174730cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c646c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c0890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c68bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1115f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1e477aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c646208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c089358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c68be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17469d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c05f128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c70f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c195208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233b00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1830b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1830b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c13bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747309b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa15c0ab0f0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c127b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c67dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b087f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c668e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c183c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c784dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c796be0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0478d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c0077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1702f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c047518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07509e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06bb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa14c007ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c036fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7418d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7418d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0750ba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c723e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c195cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c36ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c0432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b165c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0475c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1746f77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174669588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0475c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c0475c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e07659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fe0b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dcf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17774a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1777c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e6a0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c036cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c73240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c741a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c047dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b083cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b37a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241ef0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58588> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c15a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03490f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8233710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3742a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c13b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349c88> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0742320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17469dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02415f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1746f7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e072cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e066aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0899f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e07656a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81fef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c02630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8258b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08638d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa14c007898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08638d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 6800
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17baa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17161d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17baa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba278> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a5c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8248320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038aa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c019518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716be0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c58668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17160f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa1747ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 17
Completed Iteration #24
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c741240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e82483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852748> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e0be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e8268dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260898> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b164d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e066acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b162bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa18c4d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b08523c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0349978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08632b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 7000
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a208> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b082e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f65c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c40b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1615668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b032eda0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e80b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e80b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377dd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e81feb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c043898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e84e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f948d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f948d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f948d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f948d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f948d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b163c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e80> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f729b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f722e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f725f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f725f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b166ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72240> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f609b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f609b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f948d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0886f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f609b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03778d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01b4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03778d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03778d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06be0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f069e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f066d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f727f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f474a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e969e8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0241b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea69e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6748> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea66a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6a20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e767b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e764a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e506a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 7500
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e506a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e506a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e506a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e10> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c1c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e505c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e963c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e963c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e343c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e343c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e342e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e963c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04e48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f066d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f066d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f066d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1710> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f13c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f13c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f13c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f72b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e763c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e503c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e763c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69571d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69571d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 17
Completed Iteration #24
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a4e0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e176a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e17b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b160> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 302
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697aac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697ac18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e345f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 303
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 7800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d15c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c40f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 304
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69303c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f94fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 305
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e760b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e760b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 306
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68919b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e41d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 307
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69630f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 7900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69630f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69630f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3208> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 308
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e0765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ea66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68910b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e760b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e760b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6fbac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 309
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69304e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a69304e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a697aba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4278> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 310
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a680ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e96be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f1d0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 311
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a680ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a680cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 12
Completed Iteration #17
Best Reward: 0
coverage_call_count 8000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845320> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 312
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6edd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6963dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a680cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68457f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a69f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e34eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f2e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 313
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6930978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a697a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68d14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6957fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e76ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 314
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68e4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6845f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a699b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61eab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a680c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a687fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a687f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 315
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a618a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a618a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a618a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a618a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61eab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61eaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6821518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c796f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a618a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa174730160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa17479d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 12
Completed Iteration #17
Best Reward: 0
coverage_call_count 8100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c97710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a618a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61eacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c67d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a618a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a618a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 316
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa15c06af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa15c06af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b039ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa17479dcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa16c6d4b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 317
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e504e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0e068d4a8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 318
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 319
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f065c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f066d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f066d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 8200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f066d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f066d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f065c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06518> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 320
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1c975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e049e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e068dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b039a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 321
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f47ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f600f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b039aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb32e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60550> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 322
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37880b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b37880b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b3788908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221940> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 323
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e071dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 8300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0221780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f605c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 324
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02312e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c6eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0377160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231438> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 325
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16dd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08526d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 326
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b038a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17bab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03d3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0852d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b17ba710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 327
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 8400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c7aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e50828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b172deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa16c723e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a61ea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b172d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0231278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b01c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b020f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b16ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b1716940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b1684320> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 328
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6e04eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a68917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6eb3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b030c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a698ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6891dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0e071d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f06d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f60a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6ecc860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02605f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a698af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b02e8710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 329
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0260198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b02868d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b02869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b11d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b024ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0a6f3cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b08636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0286a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b17d8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b08631d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0e06f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa0b03212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa0b0321128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa0b0863ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 330
found coverage increase 0
Current Total Coverage 41.66666666666667
initial coverage: 41.6667
time passed (minutes): 60.1981
iterations: 331
number of new inputs: 0
final coverage: 41.6667
total coverage increase: 0
